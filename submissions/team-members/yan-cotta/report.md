# ðŸ“„ MLPayGrade â€“ Project Report - ðŸ”´ **Advanced Track**

**Team Member**: Yan Cotta  
**Project**: MLPayGrade Advanced Deep Learning Track  
**Completion Date**: July 24, 2025  
**Status**: Week 1 & 2 Complete âœ…

---

## âœ… Week 1: Setup & Exploratory Data Analysis (EDA)

### ðŸ”‘ Question 1: What roles or experience levels yield the highest average salary?

**Answer**: Our comprehensive EDA revealed a clear salary hierarchy based on experience levels:

- **Executive Level (EX)**: $195,346 average salary - highest compensation tier
- **Senior Level (SE)**: $163,694 average salary - represents 64.6% of dataset
- **Mid-Level (MI)**: $125,846 average salary - strong career progression
- **Entry Level (EN)**: $92,363 average salary - starting tier

**Role-Specific Findings**:
- **Data Engineering roles** show highest average salaries within each experience level
- **Management positions** command premium compensation (+15-20% vs individual contributor roles)  
- **Specialized roles** (Research Scientists, ML Engineers) in niche domains achieve top-tier salaries
- **Geographic premium**: Roles in Switzerland, Luxembourg, and Denmark show 40-60% salary premiums

**Statistical Significance**: ANOVA testing confirmed experience level has highly significant impact on salary (p < 0.001), explaining ~35% of salary variance.

### ðŸ”‘ Question 2: Does remote work correlate with higher or lower salaries?

**Answer**: Remote work impact varies significantly by experience level and company characteristics:

**Overall Pattern**: 
- **Fully Remote (100%)**: $145,479 average (31.3% of dataset)
- **Hybrid/On-site**: $151,642 average (68.7% of dataset)
- **Slight premium for on-site work** overall, but with important nuances

**Experience-Level Breakdown**:
- **Executive Level**: Remote work shows +15.9% premium ($211K vs $182K on-site)
- **Senior Level**: On-site slightly favored (+3.2% premium)
- **Mid-Level**: On-site moderately favored (+8.7% premium)
- **Entry Level**: Strong on-site premium (+76% vs remote: $88K vs $50K)

**Key Insight**: Remote work benefit increases with seniority, suggesting senior professionals can leverage remote flexibility for higher compensation, while junior roles benefit from on-site mentorship and structure.

### ðŸ”‘ Question 3: Are there differences in salary based on company size or location?

**Answer**: Both company size and location show significant salary impacts:

**Company Size Analysis**:
- **Medium Companies (M)**: $153,127 average salary - optimal balance (85.4% of data)
- **Large Companies (L)**: $151,890 average salary - stable but not premium
- **Small Companies (S)**: $108,645 average salary - lower but higher variance

**Geographic Insights**:
- **Extreme geographic bias**: 90.6% of data from North America (primarily US)
- **Premium markets**: Switzerland ($180K+), Luxembourg ($175K+), Denmark ($170K+)
- **Established markets**: US/Canada show consistent $140-160K averages
- **Emerging markets**: Asia-Pacific and other regions show $80-120K ranges

**Experience-Company Interaction**:
- **Executive-Medium**: $196,583 (highest combination)
- **Senior-Medium**: $164,040 (volume leader with 10,033 records)
- **Entry-Small**: $73,793 (challenging combination)

**Statistical Finding**: Company size and geography together explain ~22% of salary variance, with medium-sized companies consistently outperforming across all experience levels.

### ðŸ”‘ Question 4: How consistent are salaries across similar job titles?

**Answer**: Job title consistency varies dramatically due to market fragmentation:

**High Variance Roles** (CV > 0.5):
- **Machine Learning Engineer**: $45K-$400K range (CV: 0.67)
- **Data Scientist**: $35K-$350K range (CV: 0.58)  
- **Research Scientist**: $50K-$300K range (CV: 0.52)

**Moderate Consistency** (CV: 0.3-0.5):
- **Data Engineer**: More consistent within experience levels
- **Analytics Engineer**: Emerging role with stabilizing compensation
- **Data Analyst**: Entry-to-mid level roles with clear progression

**Driving Factors for Inconsistency**:
1. **Experience Level**: Same title spans EN to EX levels (300%+ salary difference)
2. **Company Size**: 2x salary difference between small and medium companies
3. **Geographic Location**: 3x difference between markets
4. **Employment Type**: Contract roles show extreme variance ($20K-$400K)

**Consolidation Strategy**: We addressed this by grouping 155 specific job titles into 6 semantic categories (DATA_SCIENCE, DATA_ENGINEERING, DATA_ANALYSIS, MACHINE_LEARNING, MANAGEMENT, SPECIALIZED) to reduce noise while preserving signal.

---

## âœ… Week 2: Feature Engineering & Data Preprocessing

### ðŸ”‘ Question 1: Which categorical features are high-cardinality, and how will you encode them for use with embedding layers?

**Answer**: We identified and successfully consolidated high-cardinality features for optimal embedding performance:

**Original High-Cardinality Features**:
- **job_title**: 155 unique values â†’ Consolidated to 6 categories
- **company_location**: 77 unique values â†’ Consolidated to 4 continents  
- **employee_residence**: 88 unique values â†’ (Dropped due to redundancy with company_location)

**Consolidation Strategy Implemented**:

**Job Title Consolidation (155 â†’ 6)**:
```python
DATA_ENGINEERING: 5,840 records (35.4%)
DATA_SCIENCE: 4,533 records (27.5%)  
DATA_ANALYSIS: 3,398 records (20.6%)
SPECIALIZED: 1,826 records (11.1%)
MANAGEMENT: 642 records (3.9%)
MACHINE_LEARNING: 255 records (1.5%)
```

**Geographic Consolidation (77 â†’ 4)**:
```python
NORTH_AMERICA: 14,948 records (90.6%)
EUROPE: 1,227 records (7.4%)
ASIA_PACIFIC: 163 records (1.0%)
OTHER: 156 records (0.9%)
```

**Encoding Method**: Used **LabelEncoder** to convert categorical strings to integers (0, 1, 2, ...) required by TensorFlow embedding layers.

**Embedding Dimension Strategy**: Applied rule `embed_dim = min(50, max(1, cardinality // 2))`:
- job_category: 6 categories â†’ 3D embedding
- continent: 4 categories â†’ 2D embedding
- experience_level: 4 categories â†’ 2D embedding  
- company_size: 3 categories â†’ 2D embedding

### ðŸ”‘ Question 2: What numerical features in the dataset needed to be scaled before being input into a neural network, and what scaling method did you choose?

**Answer**: We identified 4 numerical features requiring scaling and applied StandardScaler:

**Numerical Features Requiring Scaling**:
1. **work_year**: Range 2020-2024, different magnitudes than other features
2. **remote_ratio**: Range 0-100, percentage scale needs normalization  
3. **seniority_score**: Our engineered feature, range 0-3
4. **company_size_numeric**: Our engineered feature, range 1-3

**Scaling Method: StandardScaler**

**Justification for StandardScaler over MinMaxScaler**:
- **Outlier Robustness**: Our salary data contains legitimate high-value outliers ($400K+)
- **Distribution Preservation**: Maintains the shape of feature distributions
- **Neural Network Optimization**: Mean=0, std=1 is optimal for gradient descent convergence
- **Feature Relationships**: Preserves relative distances between data points

**Scaling Results Validation**:
- âœ… All scaled features achieve mean â‰ˆ 0.00 (perfect centering)
- âœ… All scaled features achieve std = 1.00 (perfect standardization)
- âœ… Original relationships preserved after transformation

**Technical Implementation**: Created separate `_scaled` versions of numerical features while preserving originals for interpretability.

### ðŸ”‘ Question 3: Did you create any new features based on domain knowledge or data relationships? If yes, what are they and why might they help the model predict salary more accurately?

**Answer**: We engineered 5 domain-driven features with strong business logic:

**1. `is_remote` (Binary Feature)**:
- **Logic**: Captures the distinct signal of fully remote work (100% remote ratio)
- **Distribution**: 31.3% fully remote vs 68.7% hybrid/on-site
- **Predictive Value**: Remote premium varies by seniority, providing interaction signal

**2. `experience_company_interaction` (Categorical)**:
- **Logic**: Captures compound effect of seniority and company scale
- **Top Combinations**: EX_M ($196,583), EX_L ($179,270), SE_M ($164,040)
- **Predictive Value**: Different experience levels thrive in different company environments

**3. `seniority_score` (Ordinal Numerical)**:
- **Logic**: Converts experience_level to ordered integers (EN:0, MI:1, SE:2, EX:3)
- **Salary Correlation**: Perfect ordinality with 110% salary increase from entry to executive
- **Model Benefit**: Provides explicit ordinal relationship for neural networks

**4. `company_size_numeric` (Ordinal Numerical)**:
- **Logic**: Converts company_size to ordered integers (S:1, M:2, L:3)
- **Usage**: Enables mathematical operations with seniority for interaction features

**5. `career_trajectory_score` (Interaction Feature)**:
- **Logic**: Multiplicative combination of seniority_score Ã— company_size_numeric
- **Range**: 0-9, capturing career progression stages
- **Top Performance**: Score 9 ($179,270), Score 6 ($178,443)

**Predictive Impact**: These features capture non-linear relationships and interaction effects that traditional features miss, providing richer signals for neural network pattern recognition.

### ðŸ”‘ Question 4: Which features, if any, did you choose to drop or simplify before modeling, and what was your justification?

**Answer**: We strategically dropped and consolidated features based on redundancy, noise, and modeling efficiency:

**Dropped Features**:

**1. Original High-Cardinality Features**:
- **job_title** (155 unique) â†’ Replaced with **job_category** (6 categories)
- **company_location** (77 unique) â†’ Replaced with **continent** (4 categories)
- **Justification**: Severe sparsity, many categories with <10 samples, high embedding dimension requirements

**2. employee_residence** (88 unique):
- **Justification**: 94% correlation with company_location, redundant information
- **Decision**: Dropped entirely to reduce multicollinearity

**3. Original salary_in_usd**:
- **Justification**: Highly right-skewed (skewness: 1.49)
- **Replacement**: log_salary with improved normality (skewness: -0.67)

**4. Redundant Categorical Originals**:
- Kept encoded versions (*_encoded) for neural network compatibility
- Preserved originals for interpretability but excluded from model training

**Consolidation Strategy Benefits**:
- **Reduced embedding dimensions**: From 155+77=232 to 6+4=10 embedding inputs
- **Eliminated sparse categories**: Removed categories with <10 samples
- **Maintained semantic meaning**: Grouped similar job functions logically  
- **Improved training stability**: Fewer parameters, better convergence

**Features Retained**: All other features provided unique predictive signal without severe imbalance or redundancy issues.

### ðŸ”‘ Question 5: After preprocessing, what does your final input schema look like (i.e., how many numerical features and how many categorical features)? Are there any imbalance or sparsity issues to be aware of?

**Answer**: Our final preprocessing pipeline produced a neural network-ready dataset with controlled complexity:

**Final Input Schema**:
- **Total Features**: 10+ engineered features
- **Numerical Features**: 4 scaled features (all with Î¼â‰ˆ0, Ïƒ=1)
  - work_year_scaled
  - remote_ratio_scaled  
  - seniority_score_scaled
  - company_size_numeric_scaled
- **Categorical Features**: 6+ integer-encoded features
  - job_category_encoded (6 categories)
  - continent_encoded (4 categories)
  - experience_level_encoded (4 categories)
  - employment_type_encoded (4 categories)
  - company_size_encoded (3 categories)
  - experience_company_interaction_encoded (12 categories)
- **Target Variable**: log_salary (log-transformed, near-normal distribution)

**Dataset Characteristics**:
- **Sample Size**: 16,494 records (excellent for deep learning)
- **Memory Usage**: ~15 MB (efficiently processed)
- **Data Quality**: Zero missing values, all features properly typed

**Critical Imbalance Issues Identified**:

**Severe Imbalances** (>80% in one category):
1. **Employment Type**: 99.5% Full-time, 0.5% other types
2. **Geographic Distribution**: 90.6% North America, 9.4% other regions

**Moderate Imbalances** (60-80% in dominant category):
3. **Company Size**: 85.4% Medium companies, 14.6% Small/Large
4. **Experience Level**: 64.6% Senior level, 35.4% other levels

**Sparsity Analysis**: No high sparsity issues in numerical features (all <20% zeros)

**Modeling Implications**:
- **Risk**: Model may struggle with minority classes (contract workers, international roles)
- **Mitigation Strategies**:
  - Class weighting in loss function for imbalanced categories
  - Stratified validation to ensure minority class representation
  - Temporal splits to account for time-based bias (88% from 2023-2024)

**Deep Learning Readiness Score: 7/7 (100%)**:
- âœ… Data completeness, feature scaling, categorical encoding
- âœ… Target transformation, optimal feature count, sufficient sample size
- âœ… Embedding-compatible categorical cardinalities

---

## ðŸŽ¯ Technical Implementation Summary

### **Feature Engineering Pipeline**:
1. **Consolidation**: Reduced 155+77 high-cardinality features to 6+4 manageable categories
2. **Domain Engineering**: Created 5 interaction and ordinal features with business logic
3. **Scaling**: StandardScaler for numerical features (mean=0, std=1)
4. **Encoding**: LabelEncoder for categorical features (embedding-ready integers)
5. **Target Transformation**: Log transformation for near-normal distribution

### **Data Splitting Strategy**: 
- **Recommended**: Temporal split (2020-2022 train, 2023 validation, 2024 test)
- **Justification**: Accounts for temporal bias, realistic future prediction scenario
- **Alternative**: Stratified random split available for comparison

### **Neural Network Readiness**:
- **Architecture**: Mixed input types requiring Functional API
- **Embedding Strategy**: Calculated optimal dimensions for each categorical feature
- **Memory Efficiency**: Integer encoding vs one-hot encoding reduces dimensionality
- **Training Data**: 16K+ samples with balanced feature engineering

### **Next Steps for Week 3**: 
1. Design feedforward neural network with embedding layers
2. Implement MLflow experiment tracking
3. Compare with traditional ML baselines (Random Forest, XGBoost)
4. Hyperparameter tuning and model selection
5. Feature importance analysis using SHAP

---

**Status**: âœ… **Week 1 & 2 Complete - Ready for Deep Learning Model Development**

**Key Deliverables**:
- âœ… Comprehensive EDA with statistical validation
- âœ… Strategic feature engineering with domain knowledge
- âœ… Complete preprocessing pipeline for neural networks  
- âœ… Data quality assessment and imbalance analysis
- âœ… Train/validation/test splits with temporal considerations
- âœ… Preprocessed dataset saved for model development

**Project Repository**: [SDS-CP032-mlpaygrade](https://github.com/YanCotta/SDS-CP032-mlpaygrade)  
**Contact**: Yan Cotta (yanpcotta@gmail.com)  
**Last Updated**: July 24, 2025
