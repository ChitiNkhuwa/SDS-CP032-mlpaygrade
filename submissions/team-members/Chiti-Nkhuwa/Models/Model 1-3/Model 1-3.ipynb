{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib # For saving the scaler\n",
        "\n",
        "df = pd.read_csv('salaries.csv')\n",
        "\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 1 ---\")\n",
        "\n",
        "# --- 1. Data Loading and Initial Cleaning ---\n",
        "# Assuming 'df' DataFrame is already loaded from your CSV.\n",
        "# If not, uncomment and update the line below with your data path:\n",
        "# df = pd.read_csv('your_data.csv') # Make sure this points to your cleaned dataset\n",
        "\n",
        "print(\"\\n1. Initial Data Loading and Cleaning...\")\n",
        "# Remove duplicate rows\n",
        "initial_rows = df.shape[0]\n",
        "df.drop_duplicates(inplace=True)\n",
        "print(f\"Removed {initial_rows - df.shape[0]} duplicate rows. Remaining rows: {df.shape[0]}\")\n",
        "\n",
        "# Ensure 'remote_work_type' column exists or is created if needed\n",
        "if 'remote_ratio' in df.columns and 'remote_work_type' not in df.columns:\n",
        "    df['remote_work_type'] = df['remote_ratio'].apply(lambda x: 'Remote' if x == 1 else ('Hybrid' if x == 0.5 else 'On-site'))\n",
        "    print(\"Created 'remote_work_type' based on 'remote_ratio'.\")\n",
        "elif 'remote_work_type' not in df.columns:\n",
        "    print(\"Warning: 'remote_work_type' column not found. Please ensure it's created or exists in your dataset.\")\n",
        "    # Add explicit handling or pre-processing steps here if this warning appears unexpectedly.\n",
        "\n",
        "print(\"\\nStage 1: Imports and Initial Data Preparation Complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isb21KHAxY7w",
        "outputId": "db6391d0-6eeb-43e5-efcb-f5960ccaea75"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 1 ---\n",
            "\n",
            "1. Initial Data Loading and Cleaning...\n",
            "Removed 6401 duplicate rows. Remaining rows: 10093\n",
            "Created 'remote_work_type' based on 'remote_ratio'.\n",
            "\n",
            "Stage 1: Imports and Initial Data Preparation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# --- 2. Feature Engineering and Data Splitting ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 2 ---\")\n",
        "\n",
        "# Assuming 'df' DataFrame is ready from Stage 1\n",
        "# For this example, let's re-create a similar dataframe as if Stage 1 was run\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.drop_duplicates(inplace=True)\n",
        "if 'remote_ratio' in df.columns and 'remote_work_type' not in df.columns:\n",
        "    df['remote_work_type'] = df['remote_ratio'].apply(lambda x: 'Remote' if x == 1 else ('Hybrid' if x == 0.5 else 'On-site'))\n",
        "\n",
        "print(\"\\n2. Preprocessing and Splitting Data...\")\n",
        "\n",
        "# Define features and target.\n",
        "# Note: 'remote_ratio' is now replaced by the new 'remote_work_type'\n",
        "# We drop 'salary' and 'salary_currency' as 'salary_in_usd' is our target.\n",
        "features_to_drop = ['salary', 'salary_currency', 'remote_ratio']\n",
        "df.drop(columns=features_to_drop, errors='ignore', inplace=True)\n",
        "\n",
        "# Separate features (X) from the target variable (y)\n",
        "X = df.drop('salary_in_usd', axis=1)\n",
        "y = df['salary_in_usd']\n",
        "\n",
        "# Log-transform the target variable to handle its right-skewed distribution.\n",
        "# We'll need to reverse this transformation later for evaluation.\n",
        "y_log = np.log1p(y)\n",
        "\n",
        "# Identify categorical features for one-hot encoding.\n",
        "# The `_get_numeric_data()` method is helpful for this.\n",
        "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
        "\n",
        "# Apply one-hot encoding to the categorical features.\n",
        "# 'drop_first=True' prevents multicollinearity and reduces the number of features.\n",
        "X_encoded = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
        "\n",
        "print(\"Categorical features one-hot encoded.\")\n",
        "print(f\"Original feature count: {len(X.columns)}\")\n",
        "print(f\"Encoded feature count: {len(X_encoded.columns)}\")\n",
        "print(\"Data is now ready for model training.\")\n",
        "\n",
        "# Split the data into training and testing sets.\n",
        "# We use a 80/20 split, which is a common practice.\n",
        "X_train, X_test, y_train_log, y_test_log = train_test_split(X_encoded, y_log, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"\\nData has been successfully split into training and testing sets.\")\n",
        "print(f\"Training set size: {X_train.shape[0]} samples\")\n",
        "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
        "\n",
        "print(\"\\nStage 2: Feature Engineering and Data Splitting Complete.\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 2 ---\n",
            "\n",
            "2. Preprocessing and Splitting Data...\n",
            "Categorical features one-hot encoded.\n",
            "Original feature count: 8\n",
            "Encoded feature count: 326\n",
            "Data is now ready for model training.\n",
            "\n",
            "Data has been successfully split into training and testing sets.\n",
            "Training set size: 8074 samples\n",
            "Testing set size: 2019 samples\n",
            "\n",
            "Stage 2: Feature Engineering and Data Splitting Complete.\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9cylkhdxIHZ",
        "outputId": "b16b8cd0-0633-45c2-fbf3-e8ab4fe14c31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "# Assuming 'X_train', 'X_test', 'y_train_log', 'y_test_log' are available from Stage 2.\n",
        "\n",
        "# --- 3. Model Training and Evaluation ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 3 ---\")\n",
        "print(\"\\n3. Training the XGBoost Model...\")\n",
        "\n",
        "# Initialize the XGBoost Regressor model.\n",
        "# These hyperparameters are a good starting point. For a real project,\n",
        "# you would tune these to optimize performance.\n",
        "xgbr = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',  # Objective function for regression\n",
        "    n_estimators=100,             # Number of boosting rounds (trees)\n",
        "    learning_rate=0.1,            # Step size shrinkage\n",
        "    max_depth=5,                  # Maximum depth of a tree\n",
        "    random_state=42,\n",
        "    n_jobs=-1                     # Use all available CPU cores\n",
        ")\n",
        "\n",
        "# Train the model on the training data.\n",
        "# The model learns to predict the log-transformed salary.\n",
        "xgbr.fit(X_train, y_train_log)\n",
        "print(\"XGBoost model training complete.\")\n",
        "\n",
        "print(\"\\n4. Making predictions and evaluating the model...\")\n",
        "# Make predictions on the unseen test data.\n",
        "y_pred_log = xgbr.predict(X_test)\n",
        "\n",
        "# Inverse-transform the predictions and the true values to the original USD scale.\n",
        "# This makes the error metrics more interpretable.\n",
        "y_pred = np.expm1(y_pred_log)\n",
        "y_test = np.expm1(y_test_log)\n",
        "\n",
        "# Calculate key regression metrics.\n",
        "# MAE is calculated on the original scale, while R2 is calculated on the log scale\n",
        "# to maintain consistency with the model's training objective.\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test_log, y_pred_log)\n",
        "\n",
        "print(\"\\n--- Model Performance ---\")\n",
        "print(f\"Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
        "print(f\"R-squared (RÂ²): {r2:.4f}\")\n",
        "\n",
        "# Get and display the feature importance scores.\n",
        "# This provides valuable insight into which features are most influential\n",
        "# in the model's predictions.\n",
        "print(\"\\n5. Analyzing Feature Importance...\")\n",
        "feature_importances = pd.Series(xgbr.feature_importances_, index=X_test.columns)\n",
        "print(\"Top 10 Feature Importances:\")\n",
        "print(feature_importances.nlargest(10))\n",
        "\n",
        "print(\"\\nStage 3: Model Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lz3Lr1o1yV9d",
        "outputId": "bcfd7df1-3f5d-425e-95b6-9ce18d57062e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 3 ---\n",
            "\n",
            "3. Training the XGBoost Model...\n",
            "XGBoost model training complete.\n",
            "\n",
            "4. Making predictions and evaluating the model...\n",
            "\n",
            "--- Model Performance ---\n",
            "Mean Absolute Error (MAE): $43,318.56\n",
            "R-squared (RÂ²): 0.4587\n",
            "\n",
            "5. Analyzing Feature Importance...\n",
            "Top 10 Feature Importances:\n",
            "employee_residence_US        0.214299\n",
            "employee_residence_CA        0.075715\n",
            "job_title_Data Analyst       0.060546\n",
            "experience_level_SE          0.029433\n",
            "company_location_IN          0.028841\n",
            "company_location_US          0.022738\n",
            "experience_level_EX          0.020179\n",
            "company_location_DE          0.018491\n",
            "employee_residence_MX        0.013683\n",
            "job_title_Data Specialist    0.012417\n",
            "dtype: float32\n",
            "\n",
            "Stage 3: Model Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "# Re-create the data preparation steps from Stage 2 and 3 for a self-contained example\n",
        "# In a full notebook, these would be run in previous cells.\n",
        "def load_and_preprocess_data():\n",
        "    df = pd.read_csv('salaries.csv')\n",
        "    df.dropna(inplace=True)\n",
        "    df.drop_duplicates(inplace=True)\n",
        "\n",
        "    features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                'company_location', 'company_size', 'remote_ratio', 'work_year']\n",
        "    X = df[features]\n",
        "    y_original = df['salary_in_usd']\n",
        "    y_log = np.log1p(y_original)\n",
        "\n",
        "    X_encoded = pd.get_dummies(X, columns=X.select_dtypes(include='object').columns, drop_first=True)\n",
        "\n",
        "    X_train, X_test, y_train_log, y_test_log = train_test_split(\n",
        "        X_encoded, y_log, test_size=0.2, random_state=42\n",
        "    )\n",
        "    return X_train, X_test, y_train_log, y_test_log\n",
        "\n",
        "# --- 5. Hyperparameter Tuning with Randomized Search ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 5 ---\")\n",
        "print(\"\\n1. Starting Hyperparameter Tuning with Randomized Search...\")\n",
        "\n",
        "# Get the prepared data\n",
        "X_train, X_test, y_train_log, y_test_log = load_and_preprocess_data()\n",
        "\n",
        "# Define the XGBoost Regressor\n",
        "xgbr = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)\n",
        "\n",
        "# Define the parameter distributions to sample from.\n",
        "# We're trying a range of values for key hyperparameters.\n",
        "param_dist = {\n",
        "    'n_estimators': randint(100, 1000),      # Number of trees\n",
        "    'learning_rate': uniform(0.01, 0.2),      # Step size shrinkage\n",
        "    'max_depth': randint(3, 10),              # Maximum depth of a tree\n",
        "    'min_child_weight': randint(1, 10),       # Minimum sum of instance weight needed in a child\n",
        "    'gamma': uniform(0, 0.5),                 # Minimum loss reduction required to make a further partition\n",
        "    'subsample': uniform(0.6, 0.4),           # Subsample ratio of the training instance\n",
        "    'colsample_bytree': uniform(0.6, 0.4)     # Subsample ratio of columns when constructing each tree\n",
        "}\n",
        "\n",
        "# Set up RandomizedSearchCV\n",
        "# n_iter=100 means we will try 100 different combinations of hyperparameters\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=xgbr,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=100, # Number of parameter settings that are sampled\n",
        "    scoring='neg_mean_absolute_error', # Use MAE as the scoring metric to minimize\n",
        "    cv=5,       # 5-fold cross-validation\n",
        "    verbose=1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1   # Use all available CPU cores\n",
        ")\n",
        "\n",
        "# Run the search\n",
        "random_search.fit(X_train, y_train_log)\n",
        "\n",
        "print(\"\\nHyperparameter tuning complete.\")\n",
        "print(f\"Best parameters found: {random_search.best_params_}\")\n",
        "print(f\"Best cross-validation score (MAE): {-random_search.best_score_:.2f}\")\n",
        "\n",
        "# 2. Training the final model with the best parameters\n",
        "print(\"\\n2. Training final model with best parameters...\")\n",
        "best_xgbr = random_search.best_estimator_\n",
        "best_xgbr.fit(X_train, y_train_log)\n",
        "\n",
        "# 3. Evaluating the tuned model\n",
        "print(\"\\n3. Making predictions and evaluating the tuned model...\")\n",
        "y_pred_log_tuned = best_xgbr.predict(X_test)\n",
        "y_pred_tuned = np.expm1(y_pred_log_tuned)\n",
        "y_test_original = np.expm1(y_test_log)\n",
        "\n",
        "mae_tuned = mean_absolute_error(y_test_original, y_pred_tuned)\n",
        "r2_tuned = r2_score(y_test_log, y_pred_log_tuned)\n",
        "\n",
        "print(\"\\n--- Tuned Model Performance ---\")\n",
        "print(f\"Mean Absolute Error (MAE): ${mae_tuned:,.2f}\")\n",
        "print(f\"R-squared (RÂ²): {r2_tuned:.4f}\")\n",
        "\n",
        "print(\"\\nStage 5: Hyperparameter Tuning Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPptqYXwzf41",
        "outputId": "bea70257-6696-4702-f831-abf5482b89e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 5 ---\n",
            "\n",
            "1. Starting Hyperparameter Tuning with Randomized Search...\n",
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
            "\n",
            "Hyperparameter tuning complete.\n",
            "Best parameters found: {'colsample_bytree': np.float64(0.7704365900187764), 'gamma': np.float64(0.11128820878551526), 'learning_rate': np.float64(0.08933032039085037), 'max_depth': 5, 'min_child_weight': 2, 'n_estimators': 616, 'subsample': np.float64(0.8053304674769571)}\n",
            "Best cross-validation score (MAE): 0.29\n",
            "\n",
            "2. Training final model with best parameters...\n",
            "\n",
            "3. Making predictions and evaluating the tuned model...\n",
            "\n",
            "--- Tuned Model Performance ---\n",
            "Mean Absolute Error (MAE): $43,077.81\n",
            "R-squared (RÂ²): 0.4636\n",
            "\n",
            "Stage 5: Hyperparameter Tuning Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "def load_and_preprocess_data():\n",
        "    \"\"\"\n",
        "    Loads and preprocesses the data, including a new feature engineering step.\n",
        "    \"\"\"\n",
        "    print(\"Step 1: Loading and initial cleaning of the dataset...\")\n",
        "    df = pd.read_csv('salaries.csv')\n",
        "    df.dropna(inplace=True)\n",
        "    df.drop_duplicates(inplace=True)\n",
        "    print(\"Dataset loaded and cleaned.\")\n",
        "\n",
        "    # --- New Feature Engineering Step ---\n",
        "    print(\"\\nStep 2: Grouping high-cardinality features like job_title...\")\n",
        "\n",
        "    # We will create a new, simplified job title column.\n",
        "    # Grouping logic: if a job title appears less than 20 times,\n",
        "    # we'll categorize it as 'Other'.\n",
        "    job_title_counts = df['job_title'].value_counts()\n",
        "    rare_job_titles = job_title_counts[job_title_counts < 20].index\n",
        "\n",
        "    df['job_title_grouped'] = df['job_title'].apply(\n",
        "        lambda x: 'Other' if x in rare_job_titles else x\n",
        "    )\n",
        "\n",
        "    # We'll also do the same for company location.\n",
        "    company_location_counts = df['company_location'].value_counts()\n",
        "    rare_locations = company_location_counts[company_location_counts < 10].index\n",
        "    df['company_location_grouped'] = df['company_location'].apply(\n",
        "        lambda x: 'Other' if x in rare_locations else x\n",
        "    )\n",
        "\n",
        "    print(f\"Original unique job titles: {len(df['job_title'].unique())}\")\n",
        "    print(f\"Grouped unique job titles: {len(df['job_title_grouped'].unique())}\")\n",
        "    print(f\"Original unique company locations: {len(df['company_location'].unique())}\")\n",
        "    print(f\"Grouped unique company locations: {len(df['company_location_grouped'].unique())}\")\n",
        "\n",
        "    # Define features for the model using the new grouped columns\n",
        "    features = ['experience_level', 'employment_type', 'job_title_grouped',\n",
        "                'employee_residence', 'company_location_grouped',\n",
        "                'company_size', 'remote_ratio', 'work_year']\n",
        "\n",
        "    X = df[features]\n",
        "    y_original = df['salary_in_usd']\n",
        "    y_log = np.log1p(y_original)\n",
        "\n",
        "    # One-hot encode the categorical features\n",
        "    X_encoded = pd.get_dummies(X, columns=X.select_dtypes(include='object').columns, drop_first=True)\n",
        "\n",
        "    # Splitting the data\n",
        "    X_train, X_test, y_train_log, y_test_log = train_test_split(\n",
        "        X_encoded, y_log, test_size=0.2, random_state=42\n",
        "    )\n",
        "    return X_train, X_test, y_train_log, y_test_log, y_original, df\n",
        "\n",
        "# --- 6. Feature Engineering, Retraining and Evaluation ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 6 ---\")\n",
        "print(\"\\n1. Running new feature engineering and preparing data...\")\n",
        "\n",
        "X_train, X_test, y_train_log, y_test_log, y_original, df = load_and_preprocess_data()\n",
        "\n",
        "print(\"\\n2. Training the XGBoost Model with engineered features...\")\n",
        "xgbr = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    n_estimators=616, # Using a good value from our tuning in Stage 5\n",
        "    learning_rate=0.089,\n",
        "    max_depth=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "xgbr.fit(X_train, y_train_log)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the new model...\")\n",
        "y_pred_log = xgbr.predict(X_test)\n",
        "y_pred = np.expm1(y_pred_log)\n",
        "y_test_original = np.expm1(y_test_log)\n",
        "\n",
        "mae = mean_absolute_error(y_test_original, y_pred)\n",
        "r2 = r2_score(y_test_log, y_pred_log)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with engineered features) ---\")\n",
        "print(f\"Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
        "print(f\"R-squared (RÂ²): {r2:.4f}\")\n",
        "\n",
        "print(\"\\nStage 6: Feature Engineering, Retraining and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PzTYqG6g3LLj",
        "outputId": "32c332b1-fd9a-4b13-d9d2-a5f94ade0157"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 6 ---\n",
            "\n",
            "1. Running new feature engineering and preparing data...\n",
            "Step 1: Loading and initial cleaning of the dataset...\n",
            "Dataset loaded and cleaned.\n",
            "\n",
            "Step 2: Grouping high-cardinality features like job_title...\n",
            "Original unique job titles: 155\n",
            "Grouped unique job titles: 47\n",
            "Original unique company locations: 77\n",
            "Grouped unique company locations: 25\n",
            "\n",
            "2. Training the XGBoost Model with engineered features...\n",
            "Training complete.\n",
            "\n",
            "3. Making predictions and evaluating the new model...\n",
            "\n",
            "--- New Model Performance (with engineered features) ---\n",
            "Mean Absolute Error (MAE): $43,208.77\n",
            "R-squared (RÂ²): 0.4639\n",
            "\n",
            "Stage 6: Feature Engineering, Retraining and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "def target_encode(X, y, categorical_cols):\n",
        "    \"\"\"\n",
        "    Performs K-fold target encoding on specified categorical columns.\n",
        "\n",
        "    Args:\n",
        "        X (pd.DataFrame): The feature DataFrame.\n",
        "        y (pd.Series): The target Series.\n",
        "        categorical_cols (list): List of column names to target encode.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The DataFrame with target-encoded columns.\n",
        "    \"\"\"\n",
        "    X_encoded = X.copy()\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "    for col in categorical_cols:\n",
        "        # Check if the column exists before trying to encode it\n",
        "        if col not in X_encoded.columns:\n",
        "            print(f\"Warning: Column '{col}' not found in DataFrame. Skipping target encoding for this column.\")\n",
        "            continue\n",
        "\n",
        "        X_encoded[f'{col}_encoded'] = np.nan\n",
        "\n",
        "        for train_index, val_index in kf.split(X):\n",
        "            X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
        "            y_train = y.iloc[train_index]\n",
        "\n",
        "            # Calculate the mean target for each category in the training fold\n",
        "            encoding_map = y_train.groupby(X_train[col]).mean()\n",
        "\n",
        "            # Map these means to the validation fold\n",
        "            X_encoded.loc[val_index, f'{col}_encoded'] = X_val[col].map(encoding_map)\n",
        "\n",
        "        # Handle new categories in the test set by filling NaNs with the global mean\n",
        "        global_mean = y.mean()\n",
        "        X_encoded[f'{col}_encoded'].fillna(global_mean, inplace=True)\n",
        "\n",
        "    return X_encoded.drop(columns=categorical_cols)\n",
        "\n",
        "\n",
        "# --- 7. Target Encoding, Retraining, and Evaluation ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 7 ---\")\n",
        "print(\"\\n1. Running new encoding strategy: Target Encoding...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "# In a full notebook, these would be run in previous cells.\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Explicitly convert 'remote_ratio' to a numeric type to ensure it's not treated as a categorical column\n",
        "df['remote_ratio'] = pd.to_numeric(df['remote_ratio'], errors='coerce')\n",
        "df.dropna(subset=['remote_ratio'], inplace=True)\n",
        "\n",
        "# Define all features and target\n",
        "features = ['work_year', 'experience_level', 'employment_type', 'job_title',\n",
        "            'employee_residence', 'company_location', 'company_size', 'remote_ratio']\n",
        "X = df[features]\n",
        "y_original = df['salary_in_usd']\n",
        "y_log = np.log1p(y_original)\n",
        "\n",
        "# Identify high-cardinality categorical features for target encoding\n",
        "high_cardinality_features = ['job_title', 'employee_residence', 'company_location']\n",
        "\n",
        "# Target encode the high-cardinality features first\n",
        "X_target_encoded = target_encode(X, y_log, high_cardinality_features)\n",
        "\n",
        "# One-hot encode the remaining categorical features\n",
        "# We get the list of remaining object type columns\n",
        "remaining_categorical_features = X_target_encoded.select_dtypes(include='object').columns.tolist()\n",
        "X_final = pd.get_dummies(X_target_encoded, columns=remaining_categorical_features, drop_first=True)\n",
        "\n",
        "print(\"Features processed with Target and One-Hot Encoding.\")\n",
        "print(f\"Shape of the final feature matrix: {X_final.shape}\")\n",
        "\n",
        "# Splitting the data\n",
        "X_train, X_test, y_train_log, y_test_log = train_test_split(\n",
        "    X_final, y_log, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"\\n2. Training the XGBoost Model with encoded features...\")\n",
        "xgbr = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    n_estimators=616,\n",
        "    learning_rate=0.089,\n",
        "    max_depth=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "xgbr.fit(X_train, y_train_log)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the new model...\")\n",
        "y_pred_log = xgbr.predict(X_test)\n",
        "y_pred = np.expm1(y_pred_log)\n",
        "y_test_original = np.expm1(y_test_log)\n",
        "\n",
        "mae = mean_absolute_error(y_test_original, y_pred)\n",
        "r2 = r2_score(y_test_log, y_pred_log)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with Target Encoding) ---\")\n",
        "print(f\"Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
        "print(f\"R-squared (RÂ²): {r2:.4f}\")\n",
        "\n",
        "print(\"\\nStage 7: Advanced Encoding, Retraining and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        },
        "id": "KGqdm15-5Vaf",
        "outputId": "807f98c6-4327-4d91-9ee5-2fd444766a78"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 7 ---\n",
            "\n",
            "1. Running new encoding strategy: Target Encoding...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'[263, 267, 286, 290, 360, 416, 510, 511, 518, 533, 542, 586, 594, 647, 648, 653, 668, 683, 700, 735, 782, 872, 921, 952, 965, 994, 1010, 1084, 1087, 1111, 1144, 1149, 1195, 1224, 1247, 1254, 1261, 1277, 1315, 1328, 1339, 1346, 1347, 1393, 1406, 1472, 1479, 1554, 1562, 1563, 1626, 1631, 1650, 1658, 1691, 1713, 1730, 1765, 1793, 1803, 1805, 1807, 1825, 1851, 1880, 1891, 1897, 1901, 1921, 1963, 1964, 1965, 2020, 2025, 2045, 2088, 2122, 2147, 2184, 2189, 2210, 2213, 2254, 2260, 2275, 2286, 2287, 2291, 2301, 2316, 2335, 2337, 2344, 2348, 2360, 2362, 2391, 2406, 2407, 2423, 2457, 2465, 2474, 2483, 2487, 2564, 2602, 2620, 2650, 2664, 2673, 2680, 2684, 2737, 2748, 2753, 2754, 2758, 2794, 2807, 2833, 2835, 2840, 2848, 2882, 2885, 2886, 2927, 2995, 2996, 3000, 3006, 3014, 3016, 3023, 3038, 3039, 3043, 3045, 3050, 3053, 3057, 3060, 3061, 3070, 3080, 3095, 3111, 3126, 3139, 3143, 3187, 3204, 3208, 3235, 3238, 3244, 3274, 3288, 3297, 3299, 3309, 3328, 3333, 3337, 3352, 3353, 3355, 3381, 3382, 3383, 3393, 3396, 3412, 3422, 3433, 3458, 3459, 3460, 3463, 3464, 3465, 3501, 3519, 3522, 3528, 3533, 3540, 3543, 3544, 3602, 3614, 3643, 3649, 3660, 3668, 3684, 3685, 3721, 3724, 3768, 3772, 3776, 3777, 3780, 3790, 3834, 3837, 3844, 3846, 3852, 3853, 3855, 3857, 3880, 3909, 3914, 3934, 3937, 3949, 4002, 4012, 4024, 4038, 4052, 4067, 4074, 4076, 4080, 4081, 4087, 4091, 4111, 4119, 4140, 4162, 4165, 4174, 4187, 4192, 4201, 4226, 4250, 4262, 4264, 4271, 4284, 4301, 4304, 4326, 4328, 4332, 4335, 4337, 4338, 4344, 4367, 4379, 4382, 4401, 4417, 4423, 4466, 4474, 4480, 4506, 4528, 4537, 4549, 4575, 4598, 4613, 4618, 4619, 4635, 4638, 4639, 4640, 4641, 4656, 4657, 4661, 4681, 4689, 4692, 4695, 4708, 4725, 4731, 4734, 4740, 4747, 4791, 4793, 4794, 4800, 4813, 4824, 4825, 4827, 4829, 4833, 4838, 4844, 4845, 4877, 4879, 4884, 4885, 4894, 4899, 4901, 4906, 4908, 4913, 4921, 4929, 4932, 4972, 4984, 5006, 5007, 5026, 5033, 5034, 5082, 5092, 5094, 5100, 5121, 5133, 5138, 5143, 5151, 5153, 5180, 5181, 5186, 5196, 5202, 5205, 5211, 5221, 5244, 5245, 5259, 5270, 5271, 5281, 5282, 5306, 5321, 5323, 5332, 5340, 5344, 5356, 5357, 5359, 5362, 5381, 5426, 5452, 5464, 5550, 5561, 5564, 5608, 5613, 5614, 5638, 5657, 5663, 5665, 5676, 5689, 5695, 5697, 5705, 5714, 5719, 5737, 5748, 5768, 5775, 5804, 5817, 5822, 5840, 5843, 5861, 5868, 5876, 5882, 5896, 5908, 5920, 5931, 5938, 5956, 5957, 5967, 5980, 6018, 6025, 6055, 6195, 6240, 6263, 6351, 6369, 6425, 6464, 6523, 6543, 6558, 6611, 6634, 6663, 6726, 6853, 6858, 6871, 6915, 6919, 6923, 6931, 6945, 6983, 7012, 7073, 7089, 7103, 7113, 7180, 7200, 7201, 7226, 7236, 7237, 7238, 7244, 7263, 7299, 7315, 7338, 7344, 7352, 7362, 7387, 7389, 7391, 7410, 7423, 7432, 7459, 7470, 7497, 7516, 7523, 7535, 7556, 7566, 7571, 7584, 7585, 7593, 7600, 7627, 7649, 7691, 7699, 7701, 7703, 7708, 7732, 7733, 7736, 7752, 7765, 7766, 7774, 7779, 7831, 7835, 7841, 7844, 7854, 7864, 7888, 7894, 7895, 7896, 7905, 7910, 7911, 7913, 7983, 8000, 8035, 8069, 8086, 8099, 8112, 8117, 8119, 8126, 8161, 8197, 8215, 8222, 8243, 8278, 8292, 8294, 8295, 8325, 8341, 8345, 8359, 8362, 8364, 8397, 8400, 8401, 8402, 8408, 8439, 8443, 8444, 8446, 8447, 8452, 8513, 8518, 8521, 8531, 8543, 8553, 8582, 8584, 8602, 8610, 8621, 8622, 8641, 8660, 8683, 8692, 8725, 8735, 8737, 8742, 8744, 8745, 8748, 8751, 8756, 8765, 8794, 8797, 8807, 8814, 8821, 8828, 8841, 8872, 8882, 8896, 8922, 8926, 8940, 8941, 8944, 8984, 8991, 9008, 9015, 9019, 9045, 9052, 9060, 9078, 9079, 9101, 9106, 9118, 9130, 9141, 9144, 9172, 9190, 9217, 9232, 9249, 9253, 9290, 9293, 9302, 9303, 9305, 9306, 9311, 9365, 9378, 9391, 9405, 9426, 9441, 9454, 9466, 9488, 9491, 9501, 9503, 9505, 9508, 9517, 9521, 9524, 9557, 9558, 9563, 9573, 9588, 9589, 9599, 9618, 9619, 9621, 9630, 9636, 9664, 9669, 9673, 9697, 9698, 9706, 9714, 9734, 9739, 9746, 9765, 9766, 9797, 9801, 9813, 9822, 9834, 9836, 9856, 9857, 9863, 9865, 9870, 9899, 9917, 9918, 9919, 9920, 9925, 9948, 9954, 9964, 9980, 9990, 9992, 9995, 9997, 10009, 10013, 10016, 10017, 10027, 10034, 10037, 10054, 10056, 10057, 10067, 10070, 10078, 10082, 10083, 10086, 10091, 10092] not in index'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1972905201.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;31m# Target encode the high-cardinality features first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m \u001b[0mX_target_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_encode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_log\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhigh_cardinality_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;31m# One-hot encode the remaining categorical features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1972905201.py\u001b[0m in \u001b[0;36mtarget_encode\u001b[0;34m(X, y, categorical_cols)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;31m# Map these means to the validation fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mX_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{col}_encoded'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# Handle new categories in the test set by filling NaNs with the global mean\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    905\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_deprecated_callable_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaybe_callable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_setitem_indexer\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIndexingError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m                 \u001b[0;31m# suppress \"Too many indexers\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;31m# Note: we assume _tupleize_axis_indexer has been called, if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0mkeyidx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    987\u001b[0m         \u001b[0;31m# Note: we assume _tupleize_axis_indexer has been called, if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0mkeyidx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyidx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1520\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1521\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1522\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1523\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1524\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1556\u001b[0m         \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1558\u001b[0;31m         \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1560\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: '[263, 267, 286, 290, 360, 416, 510, 511, 518, 533, 542, 586, 594, 647, 648, 653, 668, 683, 700, 735, 782, 872, 921, 952, 965, 994, 1010, 1084, 1087, 1111, 1144, 1149, 1195, 1224, 1247, 1254, 1261, 1277, 1315, 1328, 1339, 1346, 1347, 1393, 1406, 1472, 1479, 1554, 1562, 1563, 1626, 1631, 1650, 1658, 1691, 1713, 1730, 1765, 1793, 1803, 1805, 1807, 1825, 1851, 1880, 1891, 1897, 1901, 1921, 1963, 1964, 1965, 2020, 2025, 2045, 2088, 2122, 2147, 2184, 2189, 2210, 2213, 2254, 2260, 2275, 2286, 2287, 2291, 2301, 2316, 2335, 2337, 2344, 2348, 2360, 2362, 2391, 2406, 2407, 2423, 2457, 2465, 2474, 2483, 2487, 2564, 2602, 2620, 2650, 2664, 2673, 2680, 2684, 2737, 2748, 2753, 2754, 2758, 2794, 2807, 2833, 2835, 2840, 2848, 2882, 2885, 2886, 2927, 2995, 2996, 3000, 3006, 3014, 3016, 3023, 3038, 3039, 3043, 3045, 3050, 3053, 3057, 3060, 3061, 3070, 3080, 3095, 3111, 3126, 3139, 3143, 3187, 3204, 3208, 3235, 3238, 3244, 3274, 3288, 3297, 3299, 3309, 3328, 3333, 3337, 3352, 3353, 3355, 3381, 3382, 3383, 3393, 3396, 3412, 3422, 3433, 3458, 3459, 3460, 3463, 3464, 3465, 3501, 3519, 3522, 3528, 3533, 3540, 3543, 3544, 3602, 3614, 3643, 3649, 3660, 3668, 3684, 3685, 3721, 3724, 3768, 3772, 3776, 3777, 3780, 3790, 3834, 3837, 3844, 3846, 3852, 3853, 3855, 3857, 3880, 3909, 3914, 3934, 3937, 3949, 4002, 4012, 4024, 4038, 4052, 4067, 4074, 4076, 4080, 4081, 4087, 4091, 4111, 4119, 4140, 4162, 4165, 4174, 4187, 4192, 4201, 4226, 4250, 4262, 4264, 4271, 4284, 4301, 4304, 4326, ..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# --- Custom Feature Engineering Function ---\n",
        "def categorize_job_title(title):\n",
        "    \"\"\"\n",
        "    Categorizes job titles into broader, more manageable groups based on keywords.\n",
        "    \"\"\"\n",
        "    title = title.lower()\n",
        "    if 'data scientist' in title:\n",
        "        return 'Data Scientist'\n",
        "    elif 'data engineer' in title:\n",
        "        return 'Data Engineer'\n",
        "    elif 'machine learning' in title or 'ml ' in title:\n",
        "        return 'ML Engineer/Scientist'\n",
        "    elif 'data analyst' in title:\n",
        "        return 'Data Analyst'\n",
        "    elif 'analytics' in title or 'bi ' in title:\n",
        "        return 'BI/Analytics'\n",
        "    elif 'data architect' in title:\n",
        "        return 'Data Architect'\n",
        "    elif 'manager' in title or 'lead' in title or 'head' in title or 'director' in title:\n",
        "        return 'Managerial'\n",
        "    else:\n",
        "        return 'Other'\n",
        "\n",
        "# --- 8. Robust Feature Engineering, Retraining, and Evaluation ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 8 ---\")\n",
        "print(\"\\n1. Applying robust feature engineering...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Explicitly convert 'remote_ratio' to a numeric type\n",
        "df['remote_ratio'] = pd.to_numeric(df['remote_ratio'], errors='coerce')\n",
        "df.dropna(subset=['remote_ratio'], inplace=True)\n",
        "\n",
        "# Apply the new job title categorization\n",
        "df['job_category'] = df['job_title'].apply(categorize_job_title)\n",
        "\n",
        "# Define all features and target, using the new 'job_category' column\n",
        "features = ['work_year', 'experience_level', 'employment_type', 'job_category',\n",
        "            'employee_residence', 'company_location', 'company_size', 'remote_ratio']\n",
        "\n",
        "# --- Validation Step ---\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "missing_features = [col for col in features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    # Raise an error to stop execution\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "# --- End of Validation Step ---\n",
        "\n",
        "X = df[features]\n",
        "y_original = df['salary_in_usd']\n",
        "y_log = np.log1p(y_original)\n",
        "\n",
        "# One-hot encode all categorical features, including the new 'job_category'\n",
        "categorical_features = X.select_dtypes(include='object').columns.tolist()\n",
        "X_encoded = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
        "\n",
        "print(f\"Features processed. Shape of the final feature matrix: {X_encoded.shape}\")\n",
        "\n",
        "# Splitting the data\n",
        "X_train, X_test, y_train_log, y_test_log = train_test_split(\n",
        "    X_encoded, y_log, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"\\n2. Training the XGBoost Model with engineered features...\")\n",
        "# Using the best parameters from our tuning in Stage 5\n",
        "xgbr = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    n_estimators=616,\n",
        "    learning_rate=0.089,\n",
        "    max_depth=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "xgbr.fit(X_train, y_train_log)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the new model...\")\n",
        "y_pred_log = xgbr.predict(X_test)\n",
        "y_pred = np.expm1(y_pred_log)\n",
        "y_test_original = np.expm1(y_test_log)\n",
        "\n",
        "mae = mean_absolute_error(y_test_original, y_pred)\n",
        "r2 = r2_score(y_test_log, y_pred_log)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with Robust Feature Engineering) ---\")\n",
        "print(f\"Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
        "print(f\"R-squared (RÂ²): {r2:.4f}\")\n",
        "\n",
        "print(\"\\nStage 8: Robust Feature Engineering, Retraining and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAcRmGmm5sIb",
        "outputId": "ebe4b250-2de5-4403-c3f6-f599b1d842d6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 8 ---\n",
            "\n",
            "1. Applying robust feature engineering...\n",
            "Features processed. Shape of the final feature matrix: (10093, 180)\n",
            "\n",
            "2. Training the XGBoost Model with engineered features...\n",
            "Training complete.\n",
            "\n",
            "3. Making predictions and evaluating the new model...\n",
            "\n",
            "--- New Model Performance (with Robust Feature Engineering) ---\n",
            "Mean Absolute Error (MAE): $43,856.90\n",
            "R-squared (RÂ²): 0.4393\n",
            "\n",
            "Stage 8: Robust Feature Engineering, Retraining and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, concatenate, Embedding, Flatten\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# --- 9. Deep Learning with a Feedforward Neural Network (FFNN) ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 9 ---\")\n",
        "print(\"\\n1. Preparing data for a deep learning model...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define all features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence', 'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "X = df[categorical_features + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Create a dictionary to map each categorical feature to an integer index\n",
        "for col in categorical_features:\n",
        "    X[col] = pd.Categorical(X[col])\n",
        "    X[col] = X[col].cat.codes\n",
        "\n",
        "# Log-transform the target variable\n",
        "y_log = np.log1p(y)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train_log, y_test_log = train_test_split(\n",
        "    X, y_log, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 2. Building the FFNN model with embedding layers\n",
        "print(\"\\n2. Building the Feedforward Neural Network...\")\n",
        "\n",
        "# Determine the embedding size for each categorical feature\n",
        "embedding_sizes = []\n",
        "for col in categorical_features:\n",
        "    num_unique_values = len(df[col].unique())\n",
        "    embedding_size = min(50, (num_unique_values // 2) + 1)\n",
        "    embedding_sizes.append((num_unique_values, embedding_size))\n",
        "\n",
        "# Build the model\n",
        "input_layers = []\n",
        "embedding_layers = []\n",
        "\n",
        "# Create an input and embedding layer for each categorical feature\n",
        "for i, col in enumerate(categorical_features):\n",
        "    input_layer = Input(shape=(1,), name=f'input_{col}')\n",
        "    embedding_layer = Embedding(input_dim=embedding_sizes[i][0],\n",
        "                                output_dim=embedding_sizes[i][1],\n",
        "                                name=f'embedding_{col}')(input_layer)\n",
        "    flatten_layer = Flatten(name=f'flatten_{col}')(embedding_layer)\n",
        "    input_layers.append(input_layer)\n",
        "    embedding_layers.append(flatten_layer)\n",
        "\n",
        "# Create an input layer for numeric features\n",
        "numeric_input = Input(shape=(len(numeric_features),), name='numeric_input')\n",
        "input_layers.append(numeric_input)\n",
        "\n",
        "# Concatenate all embedding and numeric inputs\n",
        "all_layers = concatenate(embedding_layers + [numeric_input])\n",
        "\n",
        "# Add dense layers for the main part of the network\n",
        "dense1 = Dense(128, activation='relu')(all_layers)\n",
        "dense2 = Dense(64, activation='relu')(dense1)\n",
        "output = Dense(1, activation='linear')(dense2)\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=input_layers, outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])\n",
        "print(\"Model built and compiled.\")\n",
        "model.summary()\n",
        "\n",
        "# 3. Training the FFNN model\n",
        "print(\"\\n3. Training the FFNN model...\")\n",
        "# Prepare data for the model inputs\n",
        "X_train_inputs = {f'input_{col}': X_train[col].values for col in categorical_features}\n",
        "X_train_inputs['numeric_input'] = X_train[numeric_features].values\n",
        "\n",
        "X_test_inputs = {f'input_{col}': X_test[col].values for col in categorical_features}\n",
        "X_test_inputs['numeric_input'] = X_test[numeric_features].values\n",
        "\n",
        "# Use Early Stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_inputs,\n",
        "    y_train_log,\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# 4. Evaluating the FFNN model\n",
        "print(\"\\n4. Making predictions and evaluating the new model...\")\n",
        "y_pred_log = model.predict(X_test_inputs).flatten()\n",
        "y_pred = np.expm1(y_pred_log)\n",
        "y_test_original = np.expm1(y_test_log)\n",
        "\n",
        "mae = mean_absolute_error(y_test_original, y_pred)\n",
        "r2 = r2_score(y_test_log, y_pred_log)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with FFNN) ---\")\n",
        "print(f\"Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
        "print(f\"R-squared (RÂ²): {r2:.4f}\")\n",
        "\n",
        "print(\"\\nStage 9: Deep Learning with FFNN, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HDzKLAjE5-93",
        "outputId": "0d25332c-b281-4dff-f1da-b8ee5afe3226"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 9 ---\n",
            "\n",
            "1. Preparing data for a deep learning model...\n",
            "\n",
            "2. Building the Feedforward Neural Network...\n",
            "Model built and compiled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1282700153.py:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = pd.Categorical(X[col])\n",
            "/tmp/ipython-input-1282700153.py:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = X[col].cat.codes\n",
            "/tmp/ipython-input-1282700153.py:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = pd.Categorical(X[col])\n",
            "/tmp/ipython-input-1282700153.py:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = X[col].cat.codes\n",
            "/tmp/ipython-input-1282700153.py:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = pd.Categorical(X[col])\n",
            "/tmp/ipython-input-1282700153.py:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = X[col].cat.codes\n",
            "/tmp/ipython-input-1282700153.py:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = pd.Categorical(X[col])\n",
            "/tmp/ipython-input-1282700153.py:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = X[col].cat.codes\n",
            "/tmp/ipython-input-1282700153.py:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = pd.Categorical(X[col])\n",
            "/tmp/ipython-input-1282700153.py:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = X[col].cat.codes\n",
            "/tmp/ipython-input-1282700153.py:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = pd.Categorical(X[col])\n",
            "/tmp/ipython-input-1282700153.py:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = X[col].cat.codes\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "âââââââââââââââââââââââ³ââââââââââââââââââââ³âââââââââââââ³ââââââââââââââââââââ\n",
              "â\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ\n",
              "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
              "â input_experience_lâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_employment_tâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_job_title     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_employee_resâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_company_locaâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_company_size  â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_experienâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)      â         \u001b[38;5;34m12\u001b[0m â input_experienceâ¦ â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_employmeâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)      â         \u001b[38;5;34m12\u001b[0m â input_employmentâ¦ â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_job_title â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m50\u001b[0m)     â      \u001b[38;5;34m7,750\u001b[0m â input_job_title[\u001b[38;5;34mâ¦\u001b[0m â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_employeeâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m45\u001b[0m)     â      \u001b[38;5;34m3,960\u001b[0m â input_employee_râ¦ â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_company_â¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m39\u001b[0m)     â      \u001b[38;5;34m3,003\u001b[0m â input_company_loâ¦ â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_company_â¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m)      â          \u001b[38;5;34m6\u001b[0m â input_company_siâ¦ â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_experienceâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â embedding_experiâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_employmentâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â embedding_employâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_job_title   â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â embedding_job_tiâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_employee_râ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â embedding_employâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_company_loâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â embedding_companâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_company_siâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â embedding_companâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â numeric_input       â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â concatenate         â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m)       â          \u001b[38;5;34m0\u001b[0m â flatten_experienâ¦ â\n",
              "â (\u001b[38;5;33mConcatenate\u001b[0m)       â                   â            â flatten_employmeâ¦ â\n",
              "â                     â                   â            â flatten_job_titlâ¦ â\n",
              "â                     â                   â            â flatten_employeeâ¦ â\n",
              "â                     â                   â            â flatten_company_â¦ â\n",
              "â                     â                   â            â flatten_company_â¦ â\n",
              "â                     â                   â            â numeric_input[\u001b[38;5;34m0\u001b[0m]â¦ â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense (\u001b[38;5;33mDense\u001b[0m)       â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â     \u001b[38;5;34m18,560\u001b[0m â concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_1 (\u001b[38;5;33mDense\u001b[0m)     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â      \u001b[38;5;34m8,256\u001b[0m â dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_2 (\u001b[38;5;33mDense\u001b[0m)     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â         \u001b[38;5;34m65\u001b[0m â dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â\n",
              "âââââââââââââââââââââââ´ââââââââââââââââââââ´âââââââââââââ´ââââââââââââââââââââ\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âââââââââââââââââââââââ³ââââââââââââââââââââ³âââââââââââââ³ââââââââââââââââââââ\n",
              "â<span style=\"font-weight: bold\"> Layer (type)        </span>â<span style=\"font-weight: bold\"> Output Shape      </span>â<span style=\"font-weight: bold\">    Param # </span>â<span style=\"font-weight: bold\"> Connected to      </span>â\n",
              "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
              "â input_experience_lâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_employment_tâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_job_title     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_employee_resâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_company_locaâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_company_size  â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_experienâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      â         <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> â input_experienceâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_employmeâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      â         <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> â input_employmentâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_job_title â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)     â      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,750</span> â input_job_title[<span style=\"color: #00af00; text-decoration-color: #00af00\">â¦</span> â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_employeeâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)     â      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,960</span> â input_employee_râ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_company_â¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)     â      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,003</span> â input_company_loâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_company_â¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      â          <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> â input_company_siâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_experienceâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_experiâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_employmentâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_employâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_job_title   â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_job_tiâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_employee_râ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_employâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_company_loâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_companâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_company_siâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_companâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â numeric_input       â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â concatenate         â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)       â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â flatten_experienâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â                   â            â flatten_employmeâ¦ â\n",
              "â                     â                   â            â flatten_job_titlâ¦ â\n",
              "â                     â                   â            â flatten_employeeâ¦ â\n",
              "â                     â                   â            â flatten_company_â¦ â\n",
              "â                     â                   â            â flatten_company_â¦ â\n",
              "â                     â                   â            â numeric_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â¦ â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,560</span> â concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â\n",
              "âââââââââââââââââââââââ´ââââââââââââââââââââ´âââââââââââââ´ââââââââââââââââââââ\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m41,624\u001b[0m (162.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,624</span> (162.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m41,624\u001b[0m (162.59 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">41,624</span> (162.59 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. Training the FFNN model...\n",
            "Epoch 1/100\n",
            "\u001b[1m202/202\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 143.9102 - mae: 7.2321 - val_loss: 0.2673 - val_mae: 0.4044\n",
            "Epoch 2/100\n",
            "\u001b[1m202/202\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2988 - mae: 0.4294 - val_loss: 0.2519 - val_mae: 0.3855\n",
            "Epoch 3/100\n",
            "\u001b[1m202/202\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2454 - mae: 0.3903 - val_loss: 0.2317 - val_mae: 0.3842\n",
            "Epoch 4/100\n",
            "\u001b[1m202/202\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2546 - mae: 0.4013 - val_loss: 0.5109 - val_mae: 0.6247\n",
            "Epoch 5/100\n",
            "\u001b[1m202/202\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2959 - mae: 0.4358 - val_loss: 0.1952 - val_mae: 0.3468\n",
            "Epoch 6/100\n",
            "\u001b[1m202/202\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3158 - mae: 0.4355 - val_loss: 0.1903 - val_mae: 0.3418\n",
            "Epoch 7/100\n",
            "\u001b[1m202/202\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.8520 - mae: 0.7250 - val_loss: 4.3231 - val_mae: 2.0434\n",
            "Epoch 8/100\n",
            "\u001b[1m202/202\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 7.7813 - mae: 1.8635 - val_loss: 0.5227 - val_mae: 0.6299\n",
            "Epoch 9/100\n",
            "\u001b[1m202/202\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.4978 - mae: 0.5549 - val_loss: 0.3395 - val_mae: 0.4815\n",
            "Epoch 10/100\n",
            "\u001b[1m202/202\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.9797 - mae: 0.7995 - val_loss: 7.7638 - val_mae: 2.7596\n",
            "Epoch 11/100\n",
            "\u001b[1m202/202\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 2.0953 - mae: 1.2053 - val_loss: 0.2658 - val_mae: 0.4139\n",
            "Epoch 12/100\n",
            "\u001b[1m202/202\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 1.6869 - mae: 1.0623 - val_loss: 2.1746 - val_mae: 1.4243\n",
            "Epoch 13/100\n",
            "\u001b[1m202/202\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.7376 - mae: 1.3976 - val_loss: 4.5530 - val_mae: 2.0997\n",
            "Epoch 14/100\n",
            "\u001b[1m202/202\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7751 - mae: 1.1228 - val_loss: 0.4940 - val_mae: 0.6128\n",
            "Epoch 15/100\n",
            "\u001b[1m202/202\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3349 - mae: 0.9395 - val_loss: 0.8699 - val_mae: 0.8516\n",
            "Epoch 16/100\n",
            "\u001b[1m202/202\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 2.1121 - mae: 1.1247 - val_loss: 1.8671 - val_mae: 1.3163\n",
            "Training complete.\n",
            "\n",
            "4. Making predictions and evaluating the new model...\n",
            "\u001b[1m64/64\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "--- New Model Performance (with FFNN) ---\n",
            "Mean Absolute Error (MAE): $55,129.76\n",
            "R-squared (RÂ²): 0.2222\n",
            "\n",
            "Stage 9: Deep Learning with FFNN, Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, concatenate, Embedding, Flatten, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# --- 9. Deep Learning with a Feedforward Neural Network (FFNN) (v2) ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 9 (v2) ---\")\n",
        "print(\"\\n1. Preparing data for a deep learning model...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define all features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence', 'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "X = df[categorical_features + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Create a dictionary to map each categorical feature to an integer index\n",
        "for col in categorical_features:\n",
        "    X[col] = pd.Categorical(X[col])\n",
        "    X[col] = X[col].cat.codes\n",
        "\n",
        "# Log-transform the target variable\n",
        "y_log = np.log1p(y)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train_log, y_test_log = train_test_split(\n",
        "    X, y_log, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 2. Building a more robust FFNN model with embedding layers\n",
        "print(\"\\n2. Building a more robust Feedforward Neural Network...\")\n",
        "\n",
        "# Determine the embedding size for each categorical feature\n",
        "embedding_sizes = []\n",
        "for col in categorical_features:\n",
        "    num_unique_values = len(df[col].unique())\n",
        "    # Slightly larger embedding size to allow for more complex representations\n",
        "    embedding_size = min(75, (num_unique_values // 2) + 1)\n",
        "    embedding_sizes.append((num_unique_values, embedding_size))\n",
        "\n",
        "# Build the model\n",
        "input_layers = []\n",
        "embedding_layers = []\n",
        "\n",
        "# Create an input and embedding layer for each categorical feature\n",
        "for i, col in enumerate(categorical_features):\n",
        "    input_layer = Input(shape=(1,), name=f'input_{col}')\n",
        "    embedding_layer = Embedding(input_dim=embedding_sizes[i][0],\n",
        "                                output_dim=embedding_sizes[i][1],\n",
        "                                name=f'embedding_{col}')(input_layer)\n",
        "    flatten_layer = Flatten(name=f'flatten_{col}')(embedding_layer)\n",
        "    input_layers.append(input_layer)\n",
        "    embedding_layers.append(flatten_layer)\n",
        "\n",
        "# Create an input layer for numeric features\n",
        "numeric_input = Input(shape=(len(numeric_features),), name='numeric_input')\n",
        "input_layers.append(numeric_input)\n",
        "\n",
        "# Concatenate all embedding and numeric inputs\n",
        "all_layers = concatenate(embedding_layers + [numeric_input])\n",
        "\n",
        "# Add a deeper stack of dense layers for the main part of the network\n",
        "dense1 = Dense(256, activation='relu')(all_layers)\n",
        "# Add a dropout layer to prevent overfitting\n",
        "dropout1 = Dropout(0.3)(dense1)\n",
        "dense2 = Dense(128, activation='relu')(dropout1)\n",
        "dropout2 = Dropout(0.3)(dense2)\n",
        "dense3 = Dense(64, activation='relu')(dropout2)\n",
        "output = Dense(1, activation='linear')(dense3)\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=input_layers, outputs=output)\n",
        "\n",
        "# Compile the model with a slightly adjusted learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])\n",
        "print(\"Model built and compiled.\")\n",
        "model.summary()\n",
        "\n",
        "# 3. Training the FFNN model\n",
        "print(\"\\n3. Training the FFNN model...\")\n",
        "# Prepare data for the model inputs\n",
        "X_train_inputs = {f'input_{col}': X_train[col].values for col in categorical_features}\n",
        "X_train_inputs['numeric_input'] = X_train[numeric_features].values\n",
        "\n",
        "X_test_inputs = {f'input_{col}': X_test[col].values for col in categorical_features}\n",
        "X_test_inputs['numeric_input'] = X_test[numeric_features].values\n",
        "\n",
        "# Use Early Stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_inputs,\n",
        "    y_train_log,\n",
        "    epochs=100,\n",
        "    batch_size=64, # Increased batch size for potentially faster training\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# 4. Evaluating the FFNN model\n",
        "print(\"\\n4. Making predictions and evaluating the new model...\")\n",
        "y_pred_log = model.predict(X_test_inputs).flatten()\n",
        "y_pred = np.expm1(y_pred_log)\n",
        "y_test_original = np.expm1(y_test_log)\n",
        "\n",
        "mae = mean_absolute_error(y_test_original, y_pred)\n",
        "r2 = r2_score(y_test_log, y_pred_log)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with FFNN) ---\")\n",
        "print(f\"Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
        "print(f\"R-squared (RÂ²): {r2:.4f}\")\n",
        "\n",
        "print(\"\\nStage 9: Deep Learning with FFNN, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BbY78aPO6Y83",
        "outputId": "0188e1c5-cc44-4d2d-a40f-b221c0a621d7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 9 (v2) ---\n",
            "\n",
            "1. Preparing data for a deep learning model...\n",
            "\n",
            "2. Building a more robust Feedforward Neural Network...\n",
            "Model built and compiled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3481756398.py:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = pd.Categorical(X[col])\n",
            "/tmp/ipython-input-3481756398.py:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = X[col].cat.codes\n",
            "/tmp/ipython-input-3481756398.py:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = pd.Categorical(X[col])\n",
            "/tmp/ipython-input-3481756398.py:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = X[col].cat.codes\n",
            "/tmp/ipython-input-3481756398.py:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = pd.Categorical(X[col])\n",
            "/tmp/ipython-input-3481756398.py:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = X[col].cat.codes\n",
            "/tmp/ipython-input-3481756398.py:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = pd.Categorical(X[col])\n",
            "/tmp/ipython-input-3481756398.py:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = X[col].cat.codes\n",
            "/tmp/ipython-input-3481756398.py:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = pd.Categorical(X[col])\n",
            "/tmp/ipython-input-3481756398.py:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = X[col].cat.codes\n",
            "/tmp/ipython-input-3481756398.py:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = pd.Categorical(X[col])\n",
            "/tmp/ipython-input-3481756398.py:41: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = X[col].cat.codes\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "âââââââââââââââââââââââ³ââââââââââââââââââââ³âââââââââââââ³ââââââââââââââââââââ\n",
              "â\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ\n",
              "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
              "â input_experience_lâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_employment_tâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_job_title     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_employee_resâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_company_locaâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_company_size  â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_experienâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)      â         \u001b[38;5;34m12\u001b[0m â input_experienceâ¦ â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_employmeâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)      â         \u001b[38;5;34m12\u001b[0m â input_employmentâ¦ â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_job_title â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m75\u001b[0m)     â     \u001b[38;5;34m11,625\u001b[0m â input_job_title[\u001b[38;5;34mâ¦\u001b[0m â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_employeeâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m45\u001b[0m)     â      \u001b[38;5;34m3,960\u001b[0m â input_employee_râ¦ â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_company_â¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m39\u001b[0m)     â      \u001b[38;5;34m3,003\u001b[0m â input_company_loâ¦ â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_company_â¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2\u001b[0m)      â          \u001b[38;5;34m6\u001b[0m â input_company_siâ¦ â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_experienceâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â embedding_experiâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_employmentâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â embedding_employâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_job_title   â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â embedding_job_tiâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_employee_râ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â embedding_employâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_company_loâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m39\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â embedding_companâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_company_siâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â embedding_companâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â numeric_input       â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â concatenate_1       â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m169\u001b[0m)       â          \u001b[38;5;34m0\u001b[0m â flatten_experienâ¦ â\n",
              "â (\u001b[38;5;33mConcatenate\u001b[0m)       â                   â            â flatten_employmeâ¦ â\n",
              "â                     â                   â            â flatten_job_titlâ¦ â\n",
              "â                     â                   â            â flatten_employeeâ¦ â\n",
              "â                     â                   â            â flatten_company_â¦ â\n",
              "â                     â                   â            â flatten_company_â¦ â\n",
              "â                     â                   â            â numeric_input[\u001b[38;5;34m0\u001b[0m]â¦ â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_3 (\u001b[38;5;33mDense\u001b[0m)     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â     \u001b[38;5;34m43,520\u001b[0m â concatenate_1[\u001b[38;5;34m0\u001b[0m]â¦ â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dropout (\u001b[38;5;33mDropout\u001b[0m)   â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â          \u001b[38;5;34m0\u001b[0m â dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_4 (\u001b[38;5;33mDense\u001b[0m)     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â     \u001b[38;5;34m32,896\u001b[0m â dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â          \u001b[38;5;34m0\u001b[0m â dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_5 (\u001b[38;5;33mDense\u001b[0m)     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â      \u001b[38;5;34m8,256\u001b[0m â dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_6 (\u001b[38;5;33mDense\u001b[0m)     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â         \u001b[38;5;34m65\u001b[0m â dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â\n",
              "âââââââââââââââââââââââ´ââââââââââââââââââââ´âââââââââââââ´ââââââââââââââââââââ\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âââââââââââââââââââââââ³ââââââââââââââââââââ³âââââââââââââ³ââââââââââââââââââââ\n",
              "â<span style=\"font-weight: bold\"> Layer (type)        </span>â<span style=\"font-weight: bold\"> Output Shape      </span>â<span style=\"font-weight: bold\">    Param # </span>â<span style=\"font-weight: bold\"> Connected to      </span>â\n",
              "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
              "â input_experience_lâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_employment_tâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_job_title     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_employee_resâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_company_locaâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_company_size  â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_experienâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      â         <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> â input_experienceâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_employmeâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      â         <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> â input_employmentâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_job_title â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)     â     <span style=\"color: #00af00; text-decoration-color: #00af00\">11,625</span> â input_job_title[<span style=\"color: #00af00; text-decoration-color: #00af00\">â¦</span> â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_employeeâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)     â      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,960</span> â input_employee_râ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_company_â¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)     â      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,003</span> â input_company_loâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_company_â¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)      â          <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> â input_company_siâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_experienceâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_experiâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_employmentâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_employâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_job_title   â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_job_tiâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_employee_râ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_employâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_company_loâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_companâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_company_siâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_companâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â numeric_input       â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â concatenate_1       â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">169</span>)       â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â flatten_experienâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â                   â            â flatten_employmeâ¦ â\n",
              "â                     â                   â            â flatten_job_titlâ¦ â\n",
              "â                     â                   â            â flatten_employeeâ¦ â\n",
              "â                     â                   â            â flatten_company_â¦ â\n",
              "â                     â                   â            â flatten_company_â¦ â\n",
              "â                     â                   â            â numeric_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â¦ â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â     <span style=\"color: #00af00; text-decoration-color: #00af00\">43,520</span> â concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â¦ â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â\n",
              "âââââââââââââââââââââââ´ââââââââââââââââââââ´âââââââââââââ´ââââââââââââââââââââ\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m103,355\u001b[0m (403.73 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,355</span> (403.73 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m103,355\u001b[0m (403.73 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">103,355</span> (403.73 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. Training the FFNN model...\n",
            "Epoch 1/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 1918.3317 - mae: 31.4022 - val_loss: 49.1664 - val_mae: 6.9824\n",
            "Epoch 2/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 144.8699 - mae: 9.4492 - val_loss: 40.5122 - val_mae: 6.3436\n",
            "Epoch 3/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 62.9369 - mae: 6.1734 - val_loss: 15.4604 - val_mae: 3.8976\n",
            "Epoch 4/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 36.5425 - mae: 4.7219 - val_loss: 19.7428 - val_mae: 4.4125\n",
            "Epoch 5/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 24.6124 - mae: 3.8827 - val_loss: 23.7074 - val_mae: 4.8412\n",
            "Epoch 6/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 18.4567 - mae: 3.3225 - val_loss: 19.1245 - val_mae: 4.3420\n",
            "Epoch 7/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 14.4716 - mae: 2.9044 - val_loss: 13.5820 - val_mae: 3.6484\n",
            "Epoch 8/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 11.6749 - mae: 2.5821 - val_loss: 12.0831 - val_mae: 3.4366\n",
            "Epoch 9/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.6445 - mae: 2.3551 - val_loss: 12.8618 - val_mae: 3.5486\n",
            "Epoch 10/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 8.7756 - mae: 2.2694 - val_loss: 14.8881 - val_mae: 3.8233\n",
            "Epoch 11/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 7.6077 - mae: 2.0938 - val_loss: 9.8159 - val_mae: 3.0897\n",
            "Epoch 12/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 7.1585 - mae: 2.0227 - val_loss: 11.8512 - val_mae: 3.4033\n",
            "Epoch 13/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.2531 - mae: 1.8530 - val_loss: 13.6204 - val_mae: 3.6540\n",
            "Epoch 14/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 5.1713 - mae: 1.7063 - val_loss: 17.1270 - val_mae: 4.1061\n",
            "Epoch 15/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.8065 - mae: 1.6637 - val_loss: 13.2899 - val_mae: 3.6086\n",
            "Epoch 16/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 4.4667 - mae: 1.5913 - val_loss: 12.2749 - val_mae: 3.4651\n",
            "Epoch 17/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 3.8836 - mae: 1.4895 - val_loss: 14.5266 - val_mae: 3.7761\n",
            "Epoch 18/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 4.0517 - mae: 1.5079 - val_loss: 12.0885 - val_mae: 3.4381\n",
            "Epoch 19/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 3.3996 - mae: 1.3790 - val_loss: 11.7520 - val_mae: 3.3888\n",
            "Epoch 20/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.3993 - mae: 1.3871 - val_loss: 12.8985 - val_mae: 3.5540\n",
            "Epoch 21/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 3.3440 - mae: 1.3769 - val_loss: 14.1325 - val_mae: 3.7236\n",
            "Training complete.\n",
            "\n",
            "4. Making predictions and evaluating the new model...\n",
            "\u001b[1m64/64\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "--- New Model Performance (with FFNN) ---\n",
            "Mean Absolute Error (MAE): $139,809.87\n",
            "R-squared (RÂ²): -33.0992\n",
            "\n",
            "Stage 9: Deep Learning with FFNN, Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, concatenate, Embedding, Flatten, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# --- 9. Deep Learning with a Feedforward Neural Network (FFNN) (v3) ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 9 (v3) ---\")\n",
        "print(\"\\n1. Preparing data for a deep learning model...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define all features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence', 'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "X = df[categorical_features + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Create consistent integer codes for all categorical features before splitting\n",
        "for col in categorical_features:\n",
        "    unique_values = df[col].unique()\n",
        "    value_to_int = {value: i for i, value in enumerate(unique_values)}\n",
        "    # Add a code for unseen values\n",
        "    value_to_int['<unseen>'] = len(unique_values)\n",
        "    X[col] = X[col].apply(lambda x: value_to_int.get(x, value_to_int['<unseen>']))\n",
        "\n",
        "# Log-transform the target variable\n",
        "y_log = np.log1p(y)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train_log, y_test_log = train_test_split(\n",
        "    X, y_log, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 2. Building a more robust FFNN model with embedding layers\n",
        "print(\"\\n2. Building a more robust Feedforward Neural Network...\")\n",
        "\n",
        "# Determine the embedding size for each categorical feature\n",
        "embedding_sizes = []\n",
        "for col in categorical_features:\n",
        "    num_unique_values = len(df[col].unique()) + 1  # +1 for the unseen category\n",
        "    embedding_size = min(75, (num_unique_values // 2) + 1)\n",
        "    embedding_sizes.append((num_unique_values, embedding_size))\n",
        "\n",
        "# Build the model\n",
        "input_layers = []\n",
        "embedding_layers = []\n",
        "\n",
        "# Create an input and embedding layer for each categorical feature\n",
        "for i, col in enumerate(categorical_features):\n",
        "    input_layer = Input(shape=(1,), name=f'input_{col}')\n",
        "    embedding_layer = Embedding(input_dim=embedding_sizes[i][0],\n",
        "                                output_dim=embedding_sizes[i][1],\n",
        "                                name=f'embedding_{col}')(input_layer)\n",
        "    flatten_layer = Flatten(name=f'flatten_{col}')(embedding_layer)\n",
        "    input_layers.append(input_layer)\n",
        "    embedding_layers.append(flatten_layer)\n",
        "\n",
        "# Create an input layer for numeric features\n",
        "numeric_input = Input(shape=(len(numeric_features),), name='numeric_input')\n",
        "input_layers.append(numeric_input)\n",
        "\n",
        "# Concatenate all embedding and numeric inputs\n",
        "all_layers = concatenate(embedding_layers + [numeric_input])\n",
        "\n",
        "# Add a deeper stack of dense layers for the main part of the network\n",
        "dense1 = Dense(256, activation='relu')(all_layers)\n",
        "# Add a dropout layer to prevent overfitting\n",
        "dropout1 = Dropout(0.3)(dense1)\n",
        "dense2 = Dense(128, activation='relu')(dropout1)\n",
        "dropout2 = Dropout(0.3)(dense2)\n",
        "dense3 = Dense(64, activation='relu')(dropout2)\n",
        "output = Dense(1, activation='linear')(dense3)\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=input_layers, outputs=output)\n",
        "\n",
        "# Compile the model with a slightly adjusted learning rate\n",
        "optimizer = Adam(learning_rate=0.0005)\n",
        "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])\n",
        "print(\"Model built and compiled.\")\n",
        "model.summary()\n",
        "\n",
        "# 3. Training the FFNN model\n",
        "print(\"\\n3. Training the FFNN model...\")\n",
        "# Prepare data for the model inputs\n",
        "X_train_inputs = {f'input_{col}': X_train[col].values for col in categorical_features}\n",
        "X_train_inputs['numeric_input'] = X_train[numeric_features].values\n",
        "\n",
        "X_test_inputs = {f'input_{col}': X_test[col].values for col in categorical_features}\n",
        "X_test_inputs['numeric_input'] = X_test[numeric_features].values\n",
        "\n",
        "# Use Early Stopping to prevent overfitting\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_inputs,\n",
        "    y_train_log,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# 4. Evaluating the FFNN model\n",
        "print(\"\\n4. Making predictions and evaluating the new model...\")\n",
        "y_pred_log = model.predict(X_test_inputs).flatten()\n",
        "y_pred = np.expm1(y_pred_log)\n",
        "y_test_original = np.expm1(y_test_log)\n",
        "\n",
        "mae = mean_absolute_error(y_test_original, y_pred)\n",
        "r2 = r2_score(y_test_log, y_pred_log)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with FFNN) ---\")\n",
        "print(f\"Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
        "print(f\"R-squared (RÂ²): {r2:.4f}\")\n",
        "\n",
        "print(\"\\nStage 9: Deep Learning with FFNN, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CofInajj6pFs",
        "outputId": "6aeb1f9d-2251-4a35-944a-f1248a8e10ce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 9 (v3) ---\n",
            "\n",
            "1. Preparing data for a deep learning model...\n",
            "\n",
            "2. Building a more robust Feedforward Neural Network...\n",
            "Model built and compiled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3345908809.py:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = X[col].apply(lambda x: value_to_int.get(x, value_to_int['<unseen>']))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "âââââââââââââââââââââââ³ââââââââââââââââââââ³âââââââââââââ³ââââââââââââââââââââ\n",
              "â\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ\n",
              "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
              "â input_experience_lâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_employment_tâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_job_title     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_employee_resâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_company_locaâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_company_size  â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_experienâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)      â         \u001b[38;5;34m15\u001b[0m â input_experienceâ¦ â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_employmeâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)      â         \u001b[38;5;34m15\u001b[0m â input_employmentâ¦ â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_job_title â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m75\u001b[0m)     â     \u001b[38;5;34m11,700\u001b[0m â input_job_title[\u001b[38;5;34mâ¦\u001b[0m â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_employeeâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m45\u001b[0m)     â      \u001b[38;5;34m4,005\u001b[0m â input_employee_râ¦ â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_company_â¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m40\u001b[0m)     â      \u001b[38;5;34m3,120\u001b[0m â input_company_loâ¦ â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_company_â¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)      â         \u001b[38;5;34m12\u001b[0m â input_company_siâ¦ â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_experienceâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â embedding_experiâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_employmentâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â embedding_employâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_job_title   â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â embedding_job_tiâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_employee_râ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â embedding_employâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_company_loâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â embedding_companâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_company_siâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â embedding_companâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â numeric_input       â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â concatenate_2       â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m171\u001b[0m)       â          \u001b[38;5;34m0\u001b[0m â flatten_experienâ¦ â\n",
              "â (\u001b[38;5;33mConcatenate\u001b[0m)       â                   â            â flatten_employmeâ¦ â\n",
              "â                     â                   â            â flatten_job_titlâ¦ â\n",
              "â                     â                   â            â flatten_employeeâ¦ â\n",
              "â                     â                   â            â flatten_company_â¦ â\n",
              "â                     â                   â            â flatten_company_â¦ â\n",
              "â                     â                   â            â numeric_input[\u001b[38;5;34m0\u001b[0m]â¦ â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_7 (\u001b[38;5;33mDense\u001b[0m)     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â     \u001b[38;5;34m44,032\u001b[0m â concatenate_2[\u001b[38;5;34m0\u001b[0m]â¦ â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dropout_2 (\u001b[38;5;33mDropout\u001b[0m) â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â          \u001b[38;5;34m0\u001b[0m â dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_8 (\u001b[38;5;33mDense\u001b[0m)     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â     \u001b[38;5;34m32,896\u001b[0m â dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dropout_3 (\u001b[38;5;33mDropout\u001b[0m) â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â          \u001b[38;5;34m0\u001b[0m â dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_9 (\u001b[38;5;33mDense\u001b[0m)     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â      \u001b[38;5;34m8,256\u001b[0m â dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_10 (\u001b[38;5;33mDense\u001b[0m)    â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â         \u001b[38;5;34m65\u001b[0m â dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â\n",
              "âââââââââââââââââââââââ´ââââââââââââââââââââ´âââââââââââââ´ââââââââââââââââââââ\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âââââââââââââââââââââââ³ââââââââââââââââââââ³âââââââââââââ³ââââââââââââââââââââ\n",
              "â<span style=\"font-weight: bold\"> Layer (type)        </span>â<span style=\"font-weight: bold\"> Output Shape      </span>â<span style=\"font-weight: bold\">    Param # </span>â<span style=\"font-weight: bold\"> Connected to      </span>â\n",
              "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
              "â input_experience_lâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_employment_tâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_job_title     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_employee_resâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_company_locaâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_company_size  â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_experienâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      â         <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span> â input_experienceâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_employmeâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      â         <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span> â input_employmentâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_job_title â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)     â     <span style=\"color: #00af00; text-decoration-color: #00af00\">11,700</span> â input_job_title[<span style=\"color: #00af00; text-decoration-color: #00af00\">â¦</span> â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_employeeâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)     â      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,005</span> â input_employee_râ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_company_â¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)     â      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,120</span> â input_company_loâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_company_â¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      â         <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> â input_company_siâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_experienceâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_experiâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_employmentâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_employâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_job_title   â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_job_tiâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_employee_râ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_employâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_company_loâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_companâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_company_siâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_companâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â numeric_input       â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â concatenate_2       â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">171</span>)       â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â flatten_experienâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â                   â            â flatten_employmeâ¦ â\n",
              "â                     â                   â            â flatten_job_titlâ¦ â\n",
              "â                     â                   â            â flatten_employeeâ¦ â\n",
              "â                     â                   â            â flatten_company_â¦ â\n",
              "â                     â                   â            â flatten_company_â¦ â\n",
              "â                     â                   â            â numeric_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â¦ â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â     <span style=\"color: #00af00; text-decoration-color: #00af00\">44,032</span> â concatenate_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â¦ â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â\n",
              "âââââââââââââââââââââââ´ââââââââââââââââââââ´âââââââââââââ´ââââââââââââââââââââ\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m104,116\u001b[0m (406.70 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,116</span> (406.70 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m104,116\u001b[0m (406.70 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,116</span> (406.70 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. Training the FFNN model...\n",
            "Epoch 1/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 4067.0151 - mae: 46.4185 - val_loss: 61.8068 - val_mae: 7.8333\n",
            "Epoch 2/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 334.1782 - mae: 14.2502 - val_loss: 0.2876 - val_mae: 0.4194\n",
            "Epoch 3/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 145.6368 - mae: 9.3501 - val_loss: 5.7157 - val_mae: 2.3269\n",
            "Epoch 4/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 80.4981 - mae: 6.9631 - val_loss: 8.9504 - val_mae: 2.9422\n",
            "Epoch 5/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 52.6705 - mae: 5.5463 - val_loss: 10.6289 - val_mae: 3.2176\n",
            "Epoch 6/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36.3701 - mae: 4.5229 - val_loss: 10.0181 - val_mae: 3.1217\n",
            "Epoch 7/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 28.1579 - mae: 3.9435 - val_loss: 12.7273 - val_mae: 3.5298\n",
            "Epoch 8/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 21.9085 - mae: 3.4321 - val_loss: 12.3644 - val_mae: 3.4780\n",
            "Epoch 9/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 18.2978 - mae: 3.1036 - val_loss: 15.7467 - val_mae: 3.9344\n",
            "Epoch 10/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 16.6134 - mae: 2.9307 - val_loss: 16.5852 - val_mae: 4.0395\n",
            "Epoch 11/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 14.1128 - mae: 2.6284 - val_loss: 18.4457 - val_mae: 4.2636\n",
            "Epoch 12/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 12.4996 - mae: 2.4934 - val_loss: 12.3516 - val_mae: 3.4762\n",
            "Training complete.\n",
            "\n",
            "4. Making predictions and evaluating the new model...\n",
            "\u001b[1m64/64\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "--- New Model Performance (with FFNN) ---\n",
            "Mean Absolute Error (MAE): $57,642.13\n",
            "R-squared (RÂ²): -0.0619\n",
            "\n",
            "Stage 9: Deep Learning with FFNN, Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, concatenate, Embedding, Flatten, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# --- 9. Deep Learning with a Feedforward Neural Network (FFNN) (v4) ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 9 (v4) ---\")\n",
        "print(\"\\n1. Preparing data for a deep learning model...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define all features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence', 'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "X = df[categorical_features + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Create consistent integer codes for all categorical features before splitting\n",
        "for col in categorical_features:\n",
        "    unique_values = df[col].unique()\n",
        "    value_to_int = {value: i for i, value in enumerate(unique_values)}\n",
        "    # Add a code for unseen values\n",
        "    value_to_int['<unseen>'] = len(unique_values)\n",
        "    X[col] = X[col].apply(lambda x: value_to_int.get(x, value_to_int['<unseen>']))\n",
        "\n",
        "# Log-transform the target variable\n",
        "y_log = np.log1p(y)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train_log, y_test_log = train_test_split(\n",
        "    X, y_log, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# 2. Building a more robust FFNN model with embedding layers\n",
        "print(\"\\n2. Building a more robust Feedforward Neural Network...\")\n",
        "\n",
        "# Determine the embedding size for each categorical feature\n",
        "embedding_sizes = []\n",
        "for col in categorical_features:\n",
        "    num_unique_values = len(df[col].unique()) + 1  # +1 for the unseen category\n",
        "    embedding_size = min(75, (num_unique_values // 2) + 1)\n",
        "    embedding_sizes.append((num_unique_values, embedding_size))\n",
        "\n",
        "# Build the model\n",
        "input_layers = []\n",
        "embedding_layers = []\n",
        "\n",
        "# Create an input and embedding layer for each categorical feature\n",
        "for i, col in enumerate(categorical_features):\n",
        "    input_layer = Input(shape=(1,), name=f'input_{col}')\n",
        "    embedding_layer = Embedding(input_dim=embedding_sizes[i][0],\n",
        "                                output_dim=embedding_sizes[i][1],\n",
        "                                name=f'embedding_{col}')(input_layer)\n",
        "    flatten_layer = Flatten(name=f'flatten_{col}')(embedding_layer)\n",
        "    input_layers.append(input_layer)\n",
        "    embedding_layers.append(flatten_layer)\n",
        "\n",
        "# Create an input layer for numeric features\n",
        "numeric_input = Input(shape=(len(numeric_features),), name='numeric_input')\n",
        "input_layers.append(numeric_input)\n",
        "\n",
        "# Concatenate all embedding and numeric inputs\n",
        "all_layers = concatenate(embedding_layers + [numeric_input])\n",
        "\n",
        "# Add a deeper stack of dense layers for the main part of the network\n",
        "dense1 = Dense(256, activation='relu')(all_layers)\n",
        "# Add a dropout layer to prevent overfitting\n",
        "dropout1 = Dropout(0.3)(dense1)\n",
        "dense2 = Dense(128, activation='relu')(dropout1)\n",
        "dropout2 = Dropout(0.3)(dense2)\n",
        "dense3 = Dense(64, activation='relu')(dropout2)\n",
        "output = Dense(1, activation='linear')(dense3)\n",
        "\n",
        "# Create the final model\n",
        "model = Model(inputs=input_layers, outputs=output)\n",
        "\n",
        "# Compile the model with a smaller learning rate\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(loss='mean_squared_error', optimizer=optimizer, metrics=['mae'])\n",
        "print(\"Model built and compiled.\")\n",
        "model.summary()\n",
        "\n",
        "# 3. Training the FFNN model\n",
        "print(\"\\n3. Training the FFNN model...\")\n",
        "# Prepare data for the model inputs\n",
        "X_train_inputs = {f'input_{col}': X_train[col].values for col in categorical_features}\n",
        "X_train_inputs['numeric_input'] = X_train[numeric_features].values\n",
        "\n",
        "X_test_inputs = {f'input_{col}': X_test[col].values for col in categorical_features}\n",
        "X_test_inputs['numeric_input'] = X_test[numeric_features].values\n",
        "\n",
        "# Use Early Stopping to prevent overfitting and give the model more time to converge\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=20,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_inputs,\n",
        "    y_train_log,\n",
        "    epochs=100,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# 4. Evaluating the FFNN model\n",
        "print(\"\\n4. Making predictions and evaluating the new model...\")\n",
        "y_pred_log = model.predict(X_test_inputs).flatten()\n",
        "y_pred = np.expm1(y_pred_log)\n",
        "y_test_original = np.expm1(y_test_log)\n",
        "\n",
        "mae = mean_absolute_error(y_test_original, y_pred)\n",
        "r2 = r2_score(y_test_log, y_pred_log)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with FFNN) ---\")\n",
        "print(f\"Mean Absolute Error (MAE): ${mae:,.2f}\")\n",
        "print(f\"R-squared (RÂ²): {r2:.4f}\")\n",
        "\n",
        "print(\"\\nStage 9: Deep Learning with FFNN, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uHtkgev262nS",
        "outputId": "8b9b54ca-44bb-4536-f2d6-4e1dfeab8793"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 9 (v4) ---\n",
            "\n",
            "1. Preparing data for a deep learning model...\n",
            "\n",
            "2. Building a more robust Feedforward Neural Network...\n",
            "Model built and compiled.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3652623627.py:44: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  X[col] = X[col].apply(lambda x: value_to_int.get(x, value_to_int['<unseen>']))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "âââââââââââââââââââââââ³ââââââââââââââââââââ³âââââââââââââ³ââââââââââââââââââââ\n",
              "â\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ\n",
              "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
              "â input_experience_lâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_employment_tâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_job_title     â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_employee_resâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_company_locaâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_company_size  â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_experienâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)      â         \u001b[38;5;34m15\u001b[0m â input_experienceâ¦ â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_employmeâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)      â         \u001b[38;5;34m15\u001b[0m â input_employmentâ¦ â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_job_title â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m75\u001b[0m)     â     \u001b[38;5;34m11,700\u001b[0m â input_job_title[\u001b[38;5;34mâ¦\u001b[0m â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_employeeâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m45\u001b[0m)     â      \u001b[38;5;34m4,005\u001b[0m â input_employee_râ¦ â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_company_â¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m40\u001b[0m)     â      \u001b[38;5;34m3,120\u001b[0m â input_company_loâ¦ â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_company_â¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m3\u001b[0m)      â         \u001b[38;5;34m12\u001b[0m â input_company_siâ¦ â\n",
              "â (\u001b[38;5;33mEmbedding\u001b[0m)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_experienceâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â embedding_experiâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_employmentâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â embedding_employâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_job_title   â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m75\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â embedding_job_tiâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_employee_râ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m45\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â embedding_employâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_company_loâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        â          \u001b[38;5;34m0\u001b[0m â embedding_companâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_company_siâ¦ â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â embedding_companâ¦ â\n",
              "â (\u001b[38;5;33mFlatten\u001b[0m)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â numeric_input       â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         â          \u001b[38;5;34m0\u001b[0m â -                 â\n",
              "â (\u001b[38;5;33mInputLayer\u001b[0m)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â concatenate_3       â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m171\u001b[0m)       â          \u001b[38;5;34m0\u001b[0m â flatten_experienâ¦ â\n",
              "â (\u001b[38;5;33mConcatenate\u001b[0m)       â                   â            â flatten_employmeâ¦ â\n",
              "â                     â                   â            â flatten_job_titlâ¦ â\n",
              "â                     â                   â            â flatten_employeeâ¦ â\n",
              "â                     â                   â            â flatten_company_â¦ â\n",
              "â                     â                   â            â flatten_company_â¦ â\n",
              "â                     â                   â            â numeric_input[\u001b[38;5;34m0\u001b[0m]â¦ â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_11 (\u001b[38;5;33mDense\u001b[0m)    â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â     \u001b[38;5;34m44,032\u001b[0m â concatenate_3[\u001b[38;5;34m0\u001b[0m]â¦ â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dropout_4 (\u001b[38;5;33mDropout\u001b[0m) â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       â          \u001b[38;5;34m0\u001b[0m â dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_12 (\u001b[38;5;33mDense\u001b[0m)    â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â     \u001b[38;5;34m32,896\u001b[0m â dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dropout_5 (\u001b[38;5;33mDropout\u001b[0m) â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â          \u001b[38;5;34m0\u001b[0m â dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_13 (\u001b[38;5;33mDense\u001b[0m)    â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â      \u001b[38;5;34m8,256\u001b[0m â dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_14 (\u001b[38;5;33mDense\u001b[0m)    â (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â         \u001b[38;5;34m65\u001b[0m â dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â\n",
              "âââââââââââââââââââââââ´ââââââââââââââââââââ´âââââââââââââ´ââââââââââââââââââââ\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">âââââââââââââââââââââââ³ââââââââââââââââââââ³âââââââââââââ³ââââââââââââââââââââ\n",
              "â<span style=\"font-weight: bold\"> Layer (type)        </span>â<span style=\"font-weight: bold\"> Output Shape      </span>â<span style=\"font-weight: bold\">    Param # </span>â<span style=\"font-weight: bold\"> Connected to      </span>â\n",
              "â¡âââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââââ©\n",
              "â input_experience_lâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_employment_tâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_job_title     â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_employee_resâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_company_locaâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â input_company_size  â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_experienâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      â         <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span> â input_experienceâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_employmeâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      â         <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span> â input_employmentâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_job_title â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)     â     <span style=\"color: #00af00; text-decoration-color: #00af00\">11,700</span> â input_job_title[<span style=\"color: #00af00; text-decoration-color: #00af00\">â¦</span> â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_employeeâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)     â      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,005</span> â input_employee_râ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_company_â¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)     â      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,120</span> â input_company_loâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â embedding_company_â¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      â         <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> â input_company_siâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_experienceâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_experiâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_employmentâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_employâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_job_title   â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">75</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_job_tiâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_employee_râ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">45</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_employâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_company_loâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_companâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â flatten_company_siâ¦ â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â embedding_companâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â numeric_input       â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â -                 â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â                   â            â                   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â concatenate_3       â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">171</span>)       â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â flatten_experienâ¦ â\n",
              "â (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â                   â            â flatten_employmeâ¦ â\n",
              "â                     â                   â            â flatten_job_titlâ¦ â\n",
              "â                     â                   â            â flatten_employeeâ¦ â\n",
              "â                     â                   â            â flatten_company_â¦ â\n",
              "â                     â                   â            â flatten_company_â¦ â\n",
              "â                     â                   â            â numeric_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â¦ â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â     <span style=\"color: #00af00; text-decoration-color: #00af00\">44,032</span> â concatenate_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â¦ â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â\n",
              "âââââââââââââââââââââââ¼ââââââââââââââââââââ¼âââââââââââââ¼ââââââââââââââââââââ¤\n",
              "â dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> â dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â\n",
              "âââââââââââââââââââââââ´ââââââââââââââââââââ´âââââââââââââ´ââââââââââââââââââââ\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m104,116\u001b[0m (406.70 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,116</span> (406.70 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m104,116\u001b[0m (406.70 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">104,116</span> (406.70 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "3. Training the FFNN model...\n",
            "Epoch 1/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 5448.3696 - mae: 57.5944 - val_loss: 1.4144 - val_mae: 1.0089\n",
            "Epoch 2/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 1347.2443 - mae: 28.9655 - val_loss: 3.4390 - val_mae: 1.7814\n",
            "Epoch 3/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 807.3432 - mae: 22.3979 - val_loss: 10.1750 - val_mae: 3.0940\n",
            "Epoch 4/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 492.0014 - mae: 17.5209 - val_loss: 0.3482 - val_mae: 0.4528\n",
            "Epoch 5/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 366.9929 - mae: 15.1039 - val_loss: 8.5291 - val_mae: 2.8656\n",
            "Epoch 6/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 268.9146 - mae: 12.8903 - val_loss: 18.1614 - val_mae: 4.2259\n",
            "Epoch 7/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 213.1105 - mae: 11.4481 - val_loss: 24.4091 - val_mae: 4.9114\n",
            "Epoch 8/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 185.7491 - mae: 10.5581 - val_loss: 40.4650 - val_mae: 6.3401\n",
            "Epoch 9/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 153.6708 - mae: 9.6892 - val_loss: 47.9723 - val_mae: 6.9035\n",
            "Epoch 10/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 122.2238 - mae: 8.5236 - val_loss: 48.9605 - val_mae: 6.9721\n",
            "Epoch 11/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 104.1613 - mae: 7.8146 - val_loss: 62.6119 - val_mae: 7.8902\n",
            "Epoch 12/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 90.1311 - mae: 7.3475 - val_loss: 64.7538 - val_mae: 8.0251\n",
            "Epoch 13/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 79.9065 - mae: 7.0107 - val_loss: 55.1982 - val_mae: 7.4106\n",
            "Epoch 14/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 69.9691 - mae: 6.5002 - val_loss: 46.5626 - val_mae: 6.8034\n",
            "Epoch 15/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 60.5821 - mae: 6.0257 - val_loss: 51.9265 - val_mae: 7.1873\n",
            "Epoch 16/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 57.3827 - mae: 5.8811 - val_loss: 43.3633 - val_mae: 6.5646\n",
            "Epoch 17/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 49.5031 - mae: 5.4043 - val_loss: 42.2168 - val_mae: 6.4767\n",
            "Epoch 18/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 44.5124 - mae: 5.1596 - val_loss: 42.4153 - val_mae: 6.4920\n",
            "Epoch 19/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 40.5872 - mae: 4.9424 - val_loss: 38.0494 - val_mae: 6.1466\n",
            "Epoch 20/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 38.4527 - mae: 4.7610 - val_loss: 30.4320 - val_mae: 5.4921\n",
            "Epoch 21/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 36.8647 - mae: 4.6905 - val_loss: 32.9150 - val_mae: 5.7137\n",
            "Epoch 22/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 33.1735 - mae: 4.4187 - val_loss: 27.1978 - val_mae: 5.1893\n",
            "Epoch 23/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 30.8782 - mae: 4.2745 - val_loss: 25.3270 - val_mae: 5.0058\n",
            "Epoch 24/100\n",
            "\u001b[1m101/101\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 27.7150 - mae: 3.9957 - val_loss: 22.4897 - val_mae: 4.7139\n",
            "Training complete.\n",
            "\n",
            "4. Making predictions and evaluating the new model...\n",
            "\u001b[1m64/64\u001b[0m \u001b[32mââââââââââââââââââââ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\n",
            "--- New Model Performance (with FFNN) ---\n",
            "Mean Absolute Error (MAE): $65,717.03\n",
            "R-squared (RÂ²): -0.3377\n",
            "\n",
            "Stage 9: Deep Learning with FFNN, Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# --- 10. Classification with XGBoost ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 10 ---\")\n",
        "print(\"\\n1. Preparing data for a classification model...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                        'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "X = df[categorical_features + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Define salary bins and create a new target variable\n",
        "# These bins are chosen to create a reasonably balanced set of classes\n",
        "bins = [0, 60000, 120000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['salary_tier'] = pd.cut(df['salary_in_usd'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# One-hot encode the categorical features\n",
        "X_encoded = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
        "\n",
        "# Use LabelEncoder to convert the new salary tiers into integers for XGBoost\n",
        "le = LabelEncoder()\n",
        "y_tier_encoded = le.fit_transform(df['salary_tier'])\n",
        "\n",
        "print(\"Features processed and new target variable created.\")\n",
        "print(f\"Shape of the final feature matrix: {X_encoded.shape}\")\n",
        "\n",
        "# Splitting the data\n",
        "X_train, X_test, y_train_tier, y_test_tier = train_test_split(\n",
        "    X_encoded, y_tier_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"\\n2. Training the XGBoost Classifier Model...\")\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    objective='multi:softprob',\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "\n",
        "xgb_clf.fit(X_train, y_train_tier)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the new classification model...\")\n",
        "y_pred_tier = xgb_clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test_tier, y_pred_tier)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with XGBoost Classifier) ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tier, y_pred_tier, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nStage 10: Classification, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ri5p9YWN7SXT",
        "outputId": "25a086f7-f370-4e80-84f4-b3d98eea5e68"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 10 ---\n",
            "\n",
            "1. Preparing data for a classification model...\n",
            "Features processed and new target variable created.\n",
            "Shape of the final feature matrix: (10093, 327)\n",
            "\n",
            "2. Training the XGBoost Classifier Model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/training.py:183: UserWarning: [12:34:33] WARNING: /workspace/src/learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete.\n",
            "\n",
            "3. Making predictions and evaluating the new classification model...\n",
            "\n",
            "--- New Model Performance (with XGBoost Classifier) ---\n",
            "Accuracy: 0.6949\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.73      0.89      0.80      1210\n",
            "         Low       0.71      0.51      0.59       167\n",
            "      Medium       0.56      0.37      0.45       642\n",
            "\n",
            "    accuracy                           0.69      2019\n",
            "   macro avg       0.67      0.59      0.61      2019\n",
            "weighted avg       0.68      0.69      0.67      2019\n",
            "\n",
            "\n",
            "Stage 10: Classification, Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# --- 11. Addressing Class Imbalance with SMOTE ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 11 ---\")\n",
        "print(\"\\n1. Preparing data for a classification model with SMOTE...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                        'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "X = df[categorical_features + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Define salary bins and create a new target variable\n",
        "bins = [0, 60000, 120000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['salary_tier'] = pd.cut(df['salary_in_usd'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# One-hot encode the categorical features\n",
        "X_encoded = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
        "\n",
        "# Use LabelEncoder to convert the new salary tiers into integers for XGBoost\n",
        "le = LabelEncoder()\n",
        "y_tier_encoded = le.fit_transform(df['salary_tier'])\n",
        "\n",
        "print(\"Features processed and new target variable created.\")\n",
        "print(f\"Shape of the initial feature matrix: {X_encoded.shape}\")\n",
        "\n",
        "# Splitting the data\n",
        "X_train, X_test, y_train_tier, y_test_tier = train_test_split(\n",
        "    X_encoded, y_tier_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Apply SMOTE to the training data to handle class imbalance\n",
        "print(\"\\nApplying SMOTE to balance the training data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train_tier)\n",
        "\n",
        "print(\"SMOTE applied. Resampled training data shapes:\")\n",
        "print(f\"Features: {X_train_resampled.shape}\")\n",
        "print(f\"Target: {y_train_resampled.shape}\")\n",
        "\n",
        "print(\"\\n2. Training the XGBoost Classifier Model with balanced data...\")\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    objective='multi:softprob',\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "\n",
        "xgb_clf.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the new classification model...\")\n",
        "y_pred_tier = xgb_clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test_tier, y_pred_tier)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with XGBoost Classifier and SMOTE) ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tier, y_pred_tier, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nStage 11: Classification with SMOTE, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1952_dkW7ikD",
        "outputId": "97d63ff8-0e38-4841-e89b-2761d25aa8e7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 11 ---\n",
            "\n",
            "1. Preparing data for a classification model with SMOTE...\n",
            "Features processed and new target variable created.\n",
            "Shape of the initial feature matrix: (10093, 327)\n",
            "\n",
            "Applying SMOTE to balance the training data...\n",
            "SMOTE applied. Resampled training data shapes:\n",
            "Features: (14994, 327)\n",
            "Target: (14994,)\n",
            "\n",
            "2. Training the XGBoost Classifier Model with balanced data...\n",
            "Training complete.\n",
            "\n",
            "3. Making predictions and evaluating the new classification model...\n",
            "\n",
            "--- New Model Performance (with XGBoost Classifier and SMOTE) ---\n",
            "Accuracy: 0.6424\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.81      0.70      0.75      1210\n",
            "         Low       0.42      0.66      0.51       167\n",
            "      Medium       0.48      0.52      0.50       642\n",
            "\n",
            "    accuracy                           0.64      2019\n",
            "   macro avg       0.57      0.63      0.59      2019\n",
            "weighted avg       0.67      0.64      0.65      2019\n",
            "\n",
            "\n",
            "Stage 11: Classification with SMOTE, Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# --- 12. Hyperparameter Tuning for Classification ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 12 ---\")\n",
        "print(\"\\n1. Preparing data for a classification model with SMOTE...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                        'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "X = df[categorical_features + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Define salary bins and create a new target variable\n",
        "bins = [0, 60000, 120000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['salary_tier'] = pd.cut(df['salary_in_usd'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# One-hot encode the categorical features\n",
        "X_encoded = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
        "\n",
        "# Use LabelEncoder to convert the new salary tiers into integers for XGBoost\n",
        "le = LabelEncoder()\n",
        "y_tier_encoded = le.fit_transform(df['salary_tier'])\n",
        "\n",
        "print(\"Features processed and new target variable created.\")\n",
        "print(f\"Shape of the initial feature matrix: {X_encoded.shape}\")\n",
        "\n",
        "# Splitting the data\n",
        "X_train, X_test, y_train_tier, y_test_tier = train_test_split(\n",
        "    X_encoded, y_tier_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Apply SMOTE to the training data to handle class imbalance\n",
        "print(\"\\nApplying SMOTE to balance the training data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train_tier)\n",
        "\n",
        "print(\"SMOTE applied. Resampled training data shapes:\")\n",
        "print(f\"Features: {X_train_resampled.shape}\")\n",
        "print(f\"Target: {y_train_resampled.shape}\")\n",
        "\n",
        "print(\"\\n2. Hyperparameter tuning the XGBoost Classifier Model...\")\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 300, 500],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'max_depth': [3, 5, 7]\n",
        "}\n",
        "\n",
        "# Initialize the XGBoost Classifier\n",
        "xgb_clf = xgb.XGBClassifier(\n",
        "    objective='multi:softprob',\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    eval_metric='mlogloss'\n",
        ")\n",
        "\n",
        "# Use GridSearchCV to find the best parameters\n",
        "grid_search = GridSearchCV(estimator=xgb_clf, param_grid=param_grid,\n",
        "                           cv=3, n_jobs=-1, verbose=1, scoring='accuracy')\n",
        "\n",
        "# Fit the grid search to the resampled training data\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Hyperparameter tuning complete.\")\n",
        "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
        "\n",
        "# 3. Making predictions and evaluating the new classification model with best parameters...\n",
        "best_xgb_clf = grid_search.best_estimator_\n",
        "y_pred_tier = best_xgb_clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test_tier, y_pred_tier)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with Tuned XGBoost Classifier and SMOTE) ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tier, y_pred_tier, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nStage 12: Hyperparameter Tuning, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw1nTuT-71Vn",
        "outputId": "5d3e7902-113f-48b2-a3ba-1905e57297bc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 12 ---\n",
            "\n",
            "1. Preparing data for a classification model with SMOTE...\n",
            "Features processed and new target variable created.\n",
            "Shape of the initial feature matrix: (10093, 327)\n",
            "\n",
            "Applying SMOTE to balance the training data...\n",
            "SMOTE applied. Resampled training data shapes:\n",
            "Features: (14994, 327)\n",
            "Target: (14994,)\n",
            "\n",
            "2. Hyperparameter tuning the XGBoost Classifier Model...\n",
            "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
            "Hyperparameter tuning complete.\n",
            "Best parameters found: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 500}\n",
            "\n",
            "--- New Model Performance (with Tuned XGBoost Classifier and SMOTE) ---\n",
            "Accuracy: 0.6399\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.80      0.71      0.75      1210\n",
            "         Low       0.41      0.57      0.48       167\n",
            "      Medium       0.47      0.53      0.50       642\n",
            "\n",
            "    accuracy                           0.64      2019\n",
            "   macro avg       0.56      0.60      0.58      2019\n",
            "weighted avg       0.66      0.64      0.65      2019\n",
            "\n",
            "\n",
            "Stage 12: Hyperparameter Tuning, Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# --- 13. Classification with LightGBM ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 13 ---\")\n",
        "print(\"\\n1. Preparing data for a classification model with SMOTE...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                        'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "X = df[categorical_features + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Define salary bins and create a new target variable\n",
        "bins = [0, 60000, 120000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['salary_tier'] = pd.cut(df['salary_in_usd'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# One-hot encode the categorical features\n",
        "X_encoded = pd.get_dummies(X, columns=categorical_features, drop_first=True)\n",
        "\n",
        "# Use LabelEncoder to convert the new salary tiers into integers for LightGBM\n",
        "le = LabelEncoder()\n",
        "y_tier_encoded = le.fit_transform(df['salary_tier'])\n",
        "\n",
        "print(\"Features processed and new target variable created.\")\n",
        "print(f\"Shape of the initial feature matrix: {X_encoded.shape}\")\n",
        "\n",
        "# Splitting the data\n",
        "X_train, X_test, y_train_tier, y_test_tier = train_test_split(\n",
        "    X_encoded, y_tier_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Apply SMOTE to the training data to handle class imbalance\n",
        "print(\"\\nApplying SMOTE to balance the training data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train_tier)\n",
        "\n",
        "print(\"SMOTE applied. Resampled training data shapes:\")\n",
        "print(f\"Features: {X_train_resampled.shape}\")\n",
        "print(f\"Target: {y_train_resampled.shape}\")\n",
        "\n",
        "print(\"\\n2. Training the LightGBM Classifier Model with balanced data...\")\n",
        "# Initialize the LightGBM Classifier\n",
        "lgbm_clf = lgb.LGBMClassifier(\n",
        "    objective='multiclass',\n",
        "    num_class=3,\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgbm_clf.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the new classification model...\")\n",
        "y_pred_tier = lgbm_clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test_tier, y_pred_tier)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with LightGBM Classifier and SMOTE) ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tier, y_pred_tier, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nStage 13: Classification with LightGBM, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_uXSDO_93Gd",
        "outputId": "e235195c-b1b6-4d9d-d13b-db1a4ad76257"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 13 ---\n",
            "\n",
            "1. Preparing data for a classification model with SMOTE...\n",
            "Features processed and new target variable created.\n",
            "Shape of the initial feature matrix: (10093, 327)\n",
            "\n",
            "Applying SMOTE to balance the training data...\n",
            "SMOTE applied. Resampled training data shapes:\n",
            "Features: (14994, 327)\n",
            "Target: (14994,)\n",
            "\n",
            "2. Training the LightGBM Classifier Model with balanced data...\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001844 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 189\n",
            "[LightGBM] [Info] Number of data points in the train set: 14994, number of used features: 92\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training complete.\n",
            "\n",
            "3. Making predictions and evaluating the new classification model...\n",
            "\n",
            "--- New Model Performance (with LightGBM Classifier and SMOTE) ---\n",
            "Accuracy: 0.6399\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.80      0.71      0.75      1210\n",
            "         Low       0.42      0.61      0.50       167\n",
            "      Medium       0.48      0.52      0.50       642\n",
            "\n",
            "    accuracy                           0.64      2019\n",
            "   macro avg       0.56      0.61      0.58      2019\n",
            "weighted avg       0.66      0.64      0.65      2019\n",
            "\n",
            "\n",
            "Stage 13: Classification with LightGBM, Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import category_encoders as ce\n",
        "\n",
        "# --- 14. Target Encoding for LightGBM ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 14 ---\")\n",
        "print(\"\\n1. Preparing data with Target Encoding...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                        'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "X = df[categorical_features + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Define salary bins and create a new target variable\n",
        "bins = [0, 60000, 120000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['salary_tier'] = pd.cut(df['salary_in_usd'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Use LabelEncoder to convert the new salary tiers into integers for LightGBM\n",
        "le = LabelEncoder()\n",
        "y_tier_encoded = le.fit_transform(df['salary_tier'])\n",
        "\n",
        "print(\"Features processed and new target variable created.\")\n",
        "print(f\"Shape of the initial feature matrix: {X.shape}\")\n",
        "\n",
        "# Splitting the data before encoding to prevent data leakage\n",
        "X_train, X_test, y_train_tier, y_test_tier = train_test_split(\n",
        "    X, y_tier_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Apply SMOTE to the training data to handle class imbalance\n",
        "print(\"\\nApplying SMOTE to balance the training data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train_tier)\n",
        "\n",
        "# Apply TargetEncoder to the categorical features on the resampled training data\n",
        "# and transform the test data\n",
        "print(\"\\nApplying TargetEncoder to categorical features...\")\n",
        "encoder = ce.TargetEncoder(cols=categorical_features)\n",
        "X_train_encoded = encoder.fit_transform(X_train_resampled, y_train_resampled)\n",
        "X_test_encoded = encoder.transform(X_test)\n",
        "\n",
        "print(\"Target encoding applied. Resampled and encoded training data shapes:\")\n",
        "print(f\"Features: {X_train_encoded.shape}\")\n",
        "print(f\"Target: {y_train_resampled.shape}\")\n",
        "print(f\"Test features: {X_test_encoded.shape}\")\n",
        "\n",
        "print(\"\\n2. Training the LightGBM Classifier Model with encoded data...\")\n",
        "# Initialize the LightGBM Classifier\n",
        "lgbm_clf = lgb.LGBMClassifier(\n",
        "    objective='multiclass',\n",
        "    num_class=3,\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgbm_clf.fit(X_train_encoded, y_train_resampled)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the new classification model...\")\n",
        "y_pred_tier = lgbm_clf.predict(X_test_encoded)\n",
        "accuracy = accuracy_score(y_test_tier, y_pred_tier)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with LightGBM Classifier and Target Encoding) ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tier, y_pred_tier, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nStage 14: Target Encoding, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "LZd4D5gc-N0V",
        "outputId": "a53624f9-060f-42e0-c005-566ad45448fe"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 14 ---\n",
            "\n",
            "1. Preparing data with Target Encoding...\n",
            "Features processed and new target variable created.\n",
            "Shape of the initial feature matrix: (10093, 8)\n",
            "\n",
            "Applying SMOTE to balance the training data...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "could not convert string to float: 'MI'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3777164530.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nApplying SMOTE to balance the training data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0msmote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0mX_train_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_resampled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_tier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# Apply TargetEncoder to the categorical features on the resampled training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \"\"\"\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0marrays_transformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mArraysTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         self.sampling_strategy_ = check_sampling_strategy(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[0;34m(self, X, y, accept_sparse)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_target_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicate_one_vs_all\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarize_y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2959\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2961\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2962\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1368\u001b[0m     \u001b[0mensure_all_finite\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deprecate_force_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_all_finite\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1370\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1371\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2151\u001b[0m     ) -> np.ndarray:\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'MI'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "851f0706"
      },
      "source": [
        "After the installation is complete, please run the cell again."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import category_encoders as ce\n",
        "\n",
        "# --- 14. Target Encoding for LightGBM ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 14 ---\")\n",
        "print(\"\\n1. Preparing data with Target Encoding...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                        'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "X = df[categorical_features + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Define salary bins and create a new target variable\n",
        "bins = [0, 60000, 120000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['salary_tier'] = pd.cut(df['salary_in_usd'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Use LabelEncoder to convert the new salary tiers into integers for LightGBM\n",
        "le = LabelEncoder()\n",
        "y_tier_encoded = le.fit_transform(df['salary_tier'])\n",
        "\n",
        "print(\"Features processed and new target variable created.\")\n",
        "print(f\"Shape of the initial feature matrix: {X.shape}\")\n",
        "\n",
        "# Splitting the data before encoding to prevent data leakage\n",
        "X_train, X_test, y_train_tier, y_test_tier = train_test_split(\n",
        "    X, y_tier_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Apply TargetEncoder to the categorical features on the training data\n",
        "# and transform the test data\n",
        "print(\"\\nApplying TargetEncoder to categorical features...\")\n",
        "encoder = ce.TargetEncoder(cols=categorical_features)\n",
        "X_train_encoded = encoder.fit_transform(X_train, y_train_tier)\n",
        "X_test_encoded = encoder.transform(X_test)\n",
        "print(\"Target encoding applied.\")\n",
        "print(\"\\nSample of encoded training data:\")\n",
        "print(X_train_encoded.head())\n",
        "\n",
        "# Apply SMOTE to the encoded training data to handle class imbalance\n",
        "print(\"\\nApplying SMOTE to balance the encoded training data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_encoded, y_train_tier)\n",
        "print(\"SMOTE applied. Resampled and encoded training data shapes:\")\n",
        "print(f\"Features: {X_train_resampled.shape}\")\n",
        "print(f\"Target: {y_train_resampled.shape}\")\n",
        "\n",
        "print(\"\\n2. Training the LightGBM Classifier Model with encoded data...\")\n",
        "# Initialize the LightGBM Classifier\n",
        "lgbm_clf = lgb.LGBMClassifier(\n",
        "    objective='multiclass',\n",
        "    num_class=3,\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=5,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgbm_clf.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the new classification model...\")\n",
        "y_pred_tier = lgbm_clf.predict(X_test_encoded)\n",
        "accuracy = accuracy_score(y_test_tier, y_pred_tier)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with LightGBM Classifier and Target Encoding) ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tier, y_pred_tier, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nStage 14: Target Encoding, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UYm3U9Ye-ueR",
        "outputId": "dc6f7eb5-5cdd-45ff-baf3-c4472d7227a0"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 14 ---\n",
            "\n",
            "1. Preparing data with Target Encoding...\n",
            "Features processed and new target variable created.\n",
            "Shape of the initial feature matrix: (10093, 8)\n",
            "\n",
            "Applying TargetEncoder to categorical features...\n",
            "Target encoding applied.\n",
            "\n",
            "Sample of encoded training data:\n",
            "       experience_level  employment_type  job_title  employee_residence  \\\n",
            "1399           0.959294          0.68331   0.685135            0.590132   \n",
            "12894          0.497468          0.68331   0.685135            0.590132   \n",
            "16039          0.497468          0.68331   0.685135            1.262774   \n",
            "11414          0.497468          0.68331   0.619593            0.590132   \n",
            "15981          0.959294          0.68331   0.295148            0.968200   \n",
            "\n",
            "       company_location  company_size  work_year  remote_ratio  \n",
            "1399           0.593736      0.662574       2024             0  \n",
            "12894          0.593736      0.662574       2023             0  \n",
            "16039          1.266187      0.662574       2022             0  \n",
            "11414          0.593736      0.662574       2023             0  \n",
            "15981          0.892553      0.892788       2021            50  \n",
            "\n",
            "Applying SMOTE to balance the encoded training data...\n",
            "SMOTE applied. Resampled and encoded training data shapes:\n",
            "Features: (14994, 8)\n",
            "Target: (14994,)\n",
            "\n",
            "2. Training the LightGBM Classifier Model with encoded data...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000566 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1471\n",
            "[LightGBM] [Info] Number of data points in the train set: 14994, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training complete.\n",
            "\n",
            "3. Making predictions and evaluating the new classification model...\n",
            "\n",
            "--- New Model Performance (with LightGBM Classifier and Target Encoding) ---\n",
            "Accuracy: 0.6538\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.80      0.72      0.76      1210\n",
            "         Low       0.46      0.57      0.51       167\n",
            "      Medium       0.49      0.55      0.52       642\n",
            "\n",
            "    accuracy                           0.65      2019\n",
            "   macro avg       0.58      0.61      0.59      2019\n",
            "weighted avg       0.67      0.65      0.66      2019\n",
            "\n",
            "\n",
            "Stage 14: Target Encoding, Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import category_encoders as ce\n",
        "\n",
        "# --- 15. LightGBM Hyperparameter Tuning ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 15 ---\")\n",
        "print(\"\\n1. Preparing data with Target Encoding...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                        'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "X = df[categorical_features + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Define salary bins and create a new target variable\n",
        "bins = [0, 60000, 120000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['salary_tier'] = pd.cut(df['salary_in_usd'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Use LabelEncoder to convert the new salary tiers into integers for LightGBM\n",
        "le = LabelEncoder()\n",
        "y_tier_encoded = le.fit_transform(df['salary_tier'])\n",
        "\n",
        "print(\"Features processed and new target variable created.\")\n",
        "print(f\"Shape of the initial feature matrix: {X.shape}\")\n",
        "\n",
        "# Splitting the data before encoding to prevent data leakage\n",
        "X_train, X_test, y_train_tier, y_test_tier = train_test_split(\n",
        "    X, y_tier_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Apply TargetEncoder to the categorical features on the training data\n",
        "# and transform the test data\n",
        "print(\"\\nApplying TargetEncoder to categorical features...\")\n",
        "encoder = ce.TargetEncoder(cols=categorical_features)\n",
        "X_train_encoded = encoder.fit_transform(X_train, y_train_tier)\n",
        "X_test_encoded = encoder.transform(X_test)\n",
        "print(\"Target encoding applied.\")\n",
        "print(\"\\nSample of encoded training data:\")\n",
        "print(X_train_encoded.head())\n",
        "\n",
        "# Apply SMOTE to the encoded training data to handle class imbalance\n",
        "print(\"\\nApplying SMOTE to balance the encoded training data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_encoded, y_train_tier)\n",
        "print(\"SMOTE applied. Resampled and encoded training data shapes:\")\n",
        "print(f\"Features: {X_train_resampled.shape}\")\n",
        "print(f\"Target: {y_train_resampled.shape}\")\n",
        "\n",
        "print(\"\\n2. Hyperparameter tuning the LightGBM Classifier Model...\")\n",
        "\n",
        "# Define the parameter grid to search\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 300, 500],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'num_leaves': [31, 50, 100]\n",
        "}\n",
        "\n",
        "# Initialize the LightGBM Classifier\n",
        "lgbm_clf = lgb.LGBMClassifier(\n",
        "    objective='multiclass',\n",
        "    num_class=3,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Use GridSearchCV to find the best parameters\n",
        "grid_search = GridSearchCV(estimator=lgbm_clf, param_grid=param_grid,\n",
        "                           cv=3, n_jobs=-1, verbose=1, scoring='accuracy')\n",
        "\n",
        "# Fit the grid search to the resampled training data\n",
        "grid_search.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Hyperparameter tuning complete.\")\n",
        "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
        "\n",
        "# 3. Making predictions and evaluating the new classification model with best parameters...\n",
        "best_lgbm_clf = grid_search.best_estimator_\n",
        "y_pred_tier = best_lgbm_clf.predict(X_test_encoded)\n",
        "accuracy = accuracy_score(y_test_tier, y_pred_tier)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with Tuned LightGBM Classifier and Target Encoding) ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tier, y_pred_tier, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nStage 15: Hyperparameter Tuning, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75szauJx_Bgt",
        "outputId": "31e8c03b-b04c-4f5e-e785-000fda8e2040"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 15 ---\n",
            "\n",
            "1. Preparing data with Target Encoding...\n",
            "Features processed and new target variable created.\n",
            "Shape of the initial feature matrix: (10093, 8)\n",
            "\n",
            "Applying TargetEncoder to categorical features...\n",
            "Target encoding applied.\n",
            "\n",
            "Sample of encoded training data:\n",
            "       experience_level  employment_type  job_title  employee_residence  \\\n",
            "1399           0.959294          0.68331   0.685135            0.590132   \n",
            "12894          0.497468          0.68331   0.685135            0.590132   \n",
            "16039          0.497468          0.68331   0.685135            1.262774   \n",
            "11414          0.497468          0.68331   0.619593            0.590132   \n",
            "15981          0.959294          0.68331   0.295148            0.968200   \n",
            "\n",
            "       company_location  company_size  work_year  remote_ratio  \n",
            "1399           0.593736      0.662574       2024             0  \n",
            "12894          0.593736      0.662574       2023             0  \n",
            "16039          1.266187      0.662574       2022             0  \n",
            "11414          0.593736      0.662574       2023             0  \n",
            "15981          0.892553      0.892788       2021            50  \n",
            "\n",
            "Applying SMOTE to balance the encoded training data...\n",
            "SMOTE applied. Resampled and encoded training data shapes:\n",
            "Features: (14994, 8)\n",
            "Target: (14994,)\n",
            "\n",
            "2. Hyperparameter tuning the LightGBM Classifier Model...\n",
            "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000522 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1471\n",
            "[LightGBM] [Info] Number of data points in the train set: 14994, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "Hyperparameter tuning complete.\n",
            "Best parameters found: {'learning_rate': 0.1, 'n_estimators': 500, 'num_leaves': 100}\n",
            "\n",
            "--- New Model Performance (with Tuned LightGBM Classifier and Target Encoding) ---\n",
            "Accuracy: 0.6528\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.78      0.74      0.76      1210\n",
            "         Low       0.50      0.51      0.51       167\n",
            "      Medium       0.48      0.52      0.50       642\n",
            "\n",
            "    accuracy                           0.65      2019\n",
            "   macro avg       0.59      0.59      0.59      2019\n",
            "weighted avg       0.66      0.65      0.66      2019\n",
            "\n",
            "\n",
            "Stage 15: Hyperparameter Tuning, Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import category_encoders as ce\n",
        "\n",
        "# --- 16. Feature Engineering and LightGBM ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 16 ---\")\n",
        "print(\"\\n1. Feature Engineering and Data Preparation...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                        'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "# Engineer a new feature: location_difference\n",
        "# Calculate mean salary for company location and employee residence\n",
        "avg_salary_company_loc = df.groupby('company_location')['salary_in_usd'].transform('mean')\n",
        "avg_salary_employee_res = df.groupby('employee_residence')['salary_in_usd'].transform('mean')\n",
        "df['location_difference'] = avg_salary_company_loc - avg_salary_employee_res\n",
        "numeric_features.append('location_difference')\n",
        "\n",
        "# Create the feature matrix X and target vector y\n",
        "X = df[categorical_features + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Define salary bins and create a new target variable\n",
        "bins = [0, 60000, 120000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['salary_tier'] = pd.cut(df['salary_in_usd'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Use LabelEncoder to convert the new salary tiers into integers for LightGBM\n",
        "le = LabelEncoder()\n",
        "y_tier_encoded = le.fit_transform(df['salary_tier'])\n",
        "\n",
        "print(\"Features processed and new target variable created.\")\n",
        "print(f\"Shape of the initial feature matrix: {X.shape}\")\n",
        "\n",
        "# Splitting the data before encoding to prevent data leakage\n",
        "X_train, X_test, y_train_tier, y_test_tier = train_test_split(\n",
        "    X, y_tier_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Apply TargetEncoder to the categorical features on the training data\n",
        "# and transform the test data\n",
        "print(\"\\nApplying TargetEncoder to categorical features...\")\n",
        "encoder = ce.TargetEncoder(cols=categorical_features)\n",
        "X_train_encoded = encoder.fit_transform(X_train, y_train_tier)\n",
        "X_test_encoded = encoder.transform(X_test)\n",
        "print(\"Target encoding applied.\")\n",
        "\n",
        "# Apply SMOTE to the encoded training data to handle class imbalance\n",
        "print(\"\\nApplying SMOTE to balance the encoded training data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_encoded, y_train_tier)\n",
        "print(\"SMOTE applied. Resampled and encoded training data shapes:\")\n",
        "print(f\"Features: {X_train_resampled.shape}\")\n",
        "print(f\"Target: {y_train_resampled.shape}\")\n",
        "\n",
        "print(\"\\n2. Training the LightGBM Classifier Model with new features...\")\n",
        "# Initialize the LightGBM Classifier with the best parameters found previously\n",
        "lgbm_clf = lgb.LGBMClassifier(\n",
        "    objective='multiclass',\n",
        "    num_class=3,\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.1,\n",
        "    num_leaves=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgbm_clf.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the new classification model...\")\n",
        "y_pred_tier = lgbm_clf.predict(X_test_encoded)\n",
        "accuracy = accuracy_score(y_test_tier, y_pred_tier)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with LightGBM and Engineered Features) ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tier, y_pred_tier, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nStage 16: Feature Engineering, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxZzPJq0EL7P",
        "outputId": "2d700ebd-168b-4e6b-cb44-f426606984bb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 16 ---\n",
            "\n",
            "1. Feature Engineering and Data Preparation...\n",
            "Features processed and new target variable created.\n",
            "Shape of the initial feature matrix: (10093, 9)\n",
            "\n",
            "Applying TargetEncoder to categorical features...\n",
            "Target encoding applied.\n",
            "\n",
            "Applying SMOTE to balance the encoded training data...\n",
            "SMOTE applied. Resampled and encoded training data shapes:\n",
            "Features: (14994, 9)\n",
            "Target: (14994,)\n",
            "\n",
            "2. Training the LightGBM Classifier Model with new features...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000567 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1828\n",
            "[LightGBM] [Info] Number of data points in the train set: 14994, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "Training complete.\n",
            "\n",
            "3. Making predictions and evaluating the new classification model...\n",
            "\n",
            "--- New Model Performance (with LightGBM and Engineered Features) ---\n",
            "Accuracy: 0.6478\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.78      0.74      0.75      1210\n",
            "         Low       0.51      0.54      0.52       167\n",
            "      Medium       0.47      0.51      0.49       642\n",
            "\n",
            "    accuracy                           0.65      2019\n",
            "   macro avg       0.58      0.60      0.59      2019\n",
            "weighted avg       0.66      0.65      0.65      2019\n",
            "\n",
            "\n",
            "Stage 16: Feature Engineering, Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import category_encoders as ce\n",
        "\n",
        "# --- 17. Job Title Grouping and LightGBM ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 17 ---\")\n",
        "print(\"\\n1. Feature Engineering and Data Preparation...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                        'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "# Engineer a new feature: location_difference\n",
        "# Calculate mean salary for company location and employee residence\n",
        "avg_salary_company_loc = df.groupby('company_location')['salary_in_usd'].transform('mean')\n",
        "avg_salary_employee_res = df.groupby('employee_residence')['salary_in_usd'].transform('mean')\n",
        "df['location_difference'] = avg_salary_company_loc - avg_salary_employee_res\n",
        "numeric_features.append('location_difference')\n",
        "\n",
        "# Engineer another new feature: Grouping job titles\n",
        "# Create a dictionary to map similar job titles to a general category\n",
        "title_mapping = {\n",
        "    # Data Scientists\n",
        "    'Data Scientist': 'Data Scientist', 'Principal Data Scientist': 'Data Scientist',\n",
        "    'Applied Data Scientist': 'Data Scientist', 'AI Scientist': 'Data Scientist',\n",
        "    'Staff Data Scientist': 'Data Scientist', 'Research Scientist': 'Data Scientist',\n",
        "    'Data Science Consultant': 'Data Scientist', 'Lead Data Scientist': 'Data Scientist',\n",
        "    'Data Science Lead': 'Data Scientist',\n",
        "    # Data Engineers\n",
        "    'Data Engineer': 'Data Engineer', 'Lead Data Engineer': 'Data Engineer',\n",
        "    'Principal Data Engineer': 'Data Engineer', 'Data Engineering Manager': 'Data Engineer',\n",
        "    'Data Engineering Specialist': 'Data Engineer', 'Staff Data Engineer': 'Data Engineer',\n",
        "    'Cloud Data Engineer': 'Data Engineer', 'Director of Data Engineering': 'Data Engineer',\n",
        "    # Data Analysts\n",
        "    'Data Analyst': 'Data Analyst', 'Lead Data Analyst': 'Data Analyst',\n",
        "    'Business Intelligence Analyst': 'Data Analyst', 'Principal Data Analyst': 'Data Analyst',\n",
        "    'Data Analytics Manager': 'Data Analyst', 'Data Analytics Lead': 'Data Analyst',\n",
        "    'Data Analytics Specialist': 'Data Analyst',\n",
        "    # Machine Learning Specialists\n",
        "    'Machine Learning Engineer': 'Machine Learning Engineer', 'ML Engineer': 'Machine Learning Engineer',\n",
        "    'Principal Machine Learning Engineer': 'Machine Learning Engineer', 'Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Machine Learning Manager': 'Machine Learning Engineer', 'Applied Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Head of Machine Learning': 'Machine Learning Engineer',\n",
        "    # Other Roles\n",
        "    'Data Architect': 'Data Architect', 'Head of Data': 'Head of Data',\n",
        "    'Data Science Manager': 'Data Science Manager', 'Director of Data Science': 'Data Science Manager',\n",
        "    'Head of Data Science': 'Data Science Manager', 'Analytics Engineer': 'Analytics Engineer',\n",
        "    'BI Analyst': 'Business Intelligence Analyst', 'BI Developer': 'Business Intelligence Analyst',\n",
        "    'Business Intelligence Engineer': 'Business Intelligence Analyst', 'ETL Developer': 'Data Engineer',\n",
        "    'Computer Vision Engineer': 'Computer Vision Engineer', 'NLP Engineer': 'NLP Engineer',\n",
        "    'Research Engineer': 'Research Engineer', 'Financial Data Analyst': 'Data Analyst'\n",
        "}\n",
        "df['job_title_grouped'] = df['job_title'].apply(\n",
        "    lambda x: title_mapping.get(x, 'Other')\n",
        ")\n",
        "\n",
        "# Replace the original job_title with the new grouped one and update the categorical features list\n",
        "categorical_features.remove('job_title')\n",
        "categorical_features.append('job_title_grouped')\n",
        "\n",
        "# Create the feature matrix X and target vector y\n",
        "X = df[categorical_features + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Define salary bins and create a new target variable\n",
        "bins = [0, 60000, 120000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['salary_tier'] = pd.cut(df['salary_in_usd'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Use LabelEncoder to convert the new salary tiers into integers for LightGBM\n",
        "le = LabelEncoder()\n",
        "y_tier_encoded = le.fit_transform(df['salary_tier'])\n",
        "\n",
        "print(\"Features processed and new target variable created.\")\n",
        "print(f\"Shape of the initial feature matrix: {X.shape}\")\n",
        "\n",
        "# Splitting the data before encoding to prevent data leakage\n",
        "X_train, X_test, y_train_tier, y_test_tier = train_test_split(\n",
        "    X, y_tier_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Apply TargetEncoder to the categorical features on the training data\n",
        "# and transform the test data\n",
        "print(\"\\nApplying TargetEncoder to categorical features...\")\n",
        "encoder = ce.TargetEncoder(cols=categorical_features)\n",
        "X_train_encoded = encoder.fit_transform(X_train, y_train_tier)\n",
        "X_test_encoded = encoder.transform(X_test)\n",
        "print(\"Target encoding applied.\")\n",
        "\n",
        "# Apply SMOTE to the encoded training data to handle class imbalance\n",
        "print(\"\\nApplying SMOTE to balance the encoded training data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_encoded, y_train_tier)\n",
        "print(\"SMOTE applied. Resampled and encoded training data shapes:\")\n",
        "print(f\"Features: {X_train_resampled.shape}\")\n",
        "print(f\"Target: {y_train_resampled.shape}\")\n",
        "\n",
        "print(\"\\n2. Training the LightGBM Classifier Model with new features...\")\n",
        "# Initialize the LightGBM Classifier with the best parameters found previously\n",
        "lgbm_clf = lgb.LGBMClassifier(\n",
        "    objective='multiclass',\n",
        "    num_class=3,\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.1,\n",
        "    num_leaves=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgbm_clf.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the new classification model...\")\n",
        "y_pred_tier = lgbm_clf.predict(X_test_encoded)\n",
        "accuracy = accuracy_score(y_test_tier, y_pred_tier)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with LightGBM and Job Title Grouping) ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tier, y_pred_tier, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nStage 17: Job Title Grouping, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJg0zAuaEdLK",
        "outputId": "68e95bca-2b15-42bb-a64a-9f182e00e811"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 17 ---\n",
            "\n",
            "1. Feature Engineering and Data Preparation...\n",
            "Features processed and new target variable created.\n",
            "Shape of the initial feature matrix: (10093, 9)\n",
            "\n",
            "Applying TargetEncoder to categorical features...\n",
            "Target encoding applied.\n",
            "\n",
            "Applying SMOTE to balance the encoded training data...\n",
            "SMOTE applied. Resampled and encoded training data shapes:\n",
            "Features: (14994, 9)\n",
            "Target: (14994,)\n",
            "\n",
            "2. Training the LightGBM Classifier Model with new features...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000585 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1833\n",
            "[LightGBM] [Info] Number of data points in the train set: 14994, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "Training complete.\n",
            "\n",
            "3. Making predictions and evaluating the new classification model...\n",
            "\n",
            "--- New Model Performance (with LightGBM and Job Title Grouping) ---\n",
            "Accuracy: 0.6409\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.78      0.74      0.76      1210\n",
            "         Low       0.42      0.55      0.48       167\n",
            "      Medium       0.47      0.47      0.47       642\n",
            "\n",
            "    accuracy                           0.64      2019\n",
            "   macro avg       0.56      0.59      0.57      2019\n",
            "weighted avg       0.65      0.64      0.64      2019\n",
            "\n",
            "\n",
            "Stage 17: Job Title Grouping, Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import category_encoders as ce\n",
        "\n",
        "# --- 18. Feature Combination and LightGBM ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 18 ---\")\n",
        "print(\"\\n1. Feature Engineering and Data Preparation...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                        'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "# Engineer a new feature: location_difference\n",
        "# Calculate mean salary for company location and employee residence\n",
        "avg_salary_company_loc = df.groupby('company_location')['salary_in_usd'].transform('mean')\n",
        "avg_salary_employee_res = df.groupby('employee_residence')['salary_in_usd'].transform('mean')\n",
        "df['location_difference'] = avg_salary_company_loc - avg_salary_employee_res\n",
        "# Append 'location_difference' to numeric_features only once\n",
        "numeric_features.append('location_difference')\n",
        "\n",
        "# Engineer another new feature: Grouping job titles\n",
        "# Create a dictionary to map similar job titles to a general category\n",
        "title_mapping = {\n",
        "    # Data Scientists\n",
        "    'Data Scientist': 'Data Scientist', 'Principal Data Scientist': 'Data Scientist',\n",
        "    'Applied Data Scientist': 'Data Scientist', 'AI Scientist': 'Data Scientist',\n",
        "    'Staff Data Scientist': 'Data Scientist', 'Research Scientist': 'Data Scientist',\n",
        "    'Data Science Consultant': 'Data Scientist', 'Lead Data Scientist': 'Data Scientist',\n",
        "    'Data Science Lead': 'Data Scientist',\n",
        "    # Data Engineers\n",
        "    'Data Engineer': 'Data Engineer', 'Lead Data Engineer': 'Data Engineer',\n",
        "    'Principal Data Engineer': 'Data Engineer', 'Data Engineering Manager': 'Data Engineer',\n",
        "    'Data Engineering Specialist': 'Data Engineer', 'Staff Data Engineer': 'Data Engineer',\n",
        "    'Cloud Data Engineer': 'Data Engineer', 'Director of Data Engineering': 'Data Engineer',\n",
        "    # Data Analysts\n",
        "    'Data Analyst': 'Data Analyst', 'Lead Data Analyst': 'Data Analyst',\n",
        "    'Business Intelligence Analyst': 'Data Analyst', 'Principal Data Analyst': 'Data Analyst',\n",
        "    'Data Analytics Manager': 'Data Analyst', 'Data Analytics Lead': 'Data Analyst',\n",
        "    'Data Analytics Specialist': 'Data Analyst',\n",
        "    # Machine Learning Specialists\n",
        "    'Machine Learning Engineer': 'Machine Learning Engineer', 'ML Engineer': 'Machine Learning Engineer',\n",
        "    'Principal Machine Learning Engineer': 'Machine Learning Engineer', 'Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Machine Learning Manager': 'Machine Learning Engineer', 'Applied Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Head of Machine Learning': 'Machine Learning Engineer',\n",
        "    # Other Roles\n",
        "    'Data Architect': 'Data Architect', 'Head of Data': 'Head of Data',\n",
        "    'Data Science Manager': 'Data Science Manager', 'Director of Data Science': 'Data Science Manager',\n",
        "    'Head of Data Science': 'Data Science Manager', 'Analytics Engineer': 'Analytics Engineer',\n",
        "    'BI Analyst': 'Business Intelligence Analyst', 'BI Developer': 'Business Intelligence Analyst',\n",
        "    'Business Intelligence Engineer': 'Business Intelligence Analyst', 'ETL Developer': 'Data Engineer',\n",
        "    'Computer Vision Engineer': 'Computer Vision Engineer', 'NLP Engineer': 'NLP Engineer',\n",
        "    'Research Engineer': 'Research Engineer', 'Financial Data Analyst': 'Data Analyst'\n",
        "}\n",
        "df['job_title_grouped'] = df['job_title'].apply(\n",
        "    lambda x: title_mapping.get(x, 'Other')\n",
        ")\n",
        "df['experience_job_combo'] = df['experience_level'] + '_' + df['job_title_grouped']\n",
        "\n",
        "# Update the categorical features list\n",
        "categorical_features = ['employment_type', 'employee_residence',\n",
        "                        'company_location', 'company_size', 'experience_job_combo'] # Added experience_job_combo\n",
        "\n",
        "# Create the feature matrix X and target vector y\n",
        "X = df[categorical_features + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Define salary bins and create a new target variable\n",
        "bins = [0, 60000, 120000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['salary_tier'] = pd.cut(df['salary_in_usd'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Use LabelEncoder to convert the new salary tiers into integers for LightGBM\n",
        "le = LabelEncoder()\n",
        "y_tier_encoded = le.fit_transform(df['salary_tier'])\n",
        "\n",
        "print(\"Features processed and new target variable created.\")\n",
        "print(f\"Shape of the initial feature matrix: {X.shape}\")\n",
        "\n",
        "# Splitting the data before encoding to prevent data leakage\n",
        "X_train, X_test, y_train_tier, y_test_tier = train_test_split(\n",
        "    X, y_tier_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Apply TargetEncoder to the categorical features on the training data\n",
        "# and transform the test data\n",
        "print(\"\\nApplying TargetEncoder to categorical features...\")\n",
        "encoder = ce.TargetEncoder(cols=categorical_features)\n",
        "X_train_encoded = encoder.fit_transform(X_train, y_train_tier)\n",
        "X_test_encoded = encoder.transform(X_test)\n",
        "print(\"Target encoding applied.\")\n",
        "\n",
        "# Apply SMOTE to the encoded training data to handle class imbalance\n",
        "print(\"\\nApplying SMOTE to balance the encoded training data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_encoded, y_train_tier)\n",
        "print(\"SMOTE applied. Resampled and encoded training data shapes:\")\n",
        "print(f\"Features: {X_train_resampled.shape}\")\n",
        "print(f\"Target: {y_train_resampled.shape}\")\n",
        "\n",
        "print(\"\\n2. Training the LightGBM Classifier Model with new features...\")\n",
        "# Initialize the LightGBM Classifier with the best parameters found previously\n",
        "lgbm_clf = lgb.LGBMClassifier(\n",
        "    objective='multiclass',\n",
        "    num_class=3,\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.1,\n",
        "    num_leaves=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgbm_clf.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the new classification model...\")\n",
        "y_pred_tier = lgbm_clf.predict(X_test_encoded)\n",
        "accuracy = accuracy_score(y_test_tier, y_pred_tier)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with LightGBM and Feature Combination) ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tier, y_pred_tier, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nStage 18: Feature Combination, Training and Evaluation Complete.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FOkUFXJEv-e",
        "outputId": "f3664915-2197-44f0-fa72-b5dd3b3bd32d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 18 ---\n",
            "\n",
            "1. Feature Engineering and Data Preparation...\n",
            "Features processed and new target variable created.\n",
            "Shape of the initial feature matrix: (10093, 8)\n",
            "\n",
            "Applying TargetEncoder to categorical features...\n",
            "Target encoding applied.\n",
            "\n",
            "Applying SMOTE to balance the encoded training data...\n",
            "SMOTE applied. Resampled and encoded training data shapes:\n",
            "Features: (14994, 8)\n",
            "Target: (14994,)\n",
            "\n",
            "2. Training the LightGBM Classifier Model with new features...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.008003 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1576\n",
            "[LightGBM] [Info] Number of data points in the train set: 14994, number of used features: 8\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "Training complete.\n",
            "\n",
            "3. Making predictions and evaluating the new classification model...\n",
            "\n",
            "--- New Model Performance (with LightGBM and Feature Combination) ---\n",
            "Accuracy: 0.6449\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.78      0.75      0.76      1210\n",
            "         Low       0.42      0.55      0.48       167\n",
            "      Medium       0.48      0.48      0.48       642\n",
            "\n",
            "    accuracy                           0.64      2019\n",
            "   macro avg       0.56      0.59      0.57      2019\n",
            "weighted avg       0.65      0.64      0.65      2019\n",
            "\n",
            "\n",
            "Stage 18: Feature Combination, Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import category_encoders as ce\n",
        "\n",
        "# --- 19. Feature Combination with Company Size and LightGBM ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 19 ---\")\n",
        "print(\"\\n1. Feature Engineering and Data Preparation...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                        'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "# Engineer a new feature: location_difference\n",
        "# Calculate mean salary for company location and employee residence\n",
        "avg_salary_company_loc = df.groupby('company_location')['salary_in_usd'].transform('mean')\n",
        "avg_salary_employee_res = df.groupby('employee_residence')['salary_in_usd'].transform('mean')\n",
        "df['location_difference'] = avg_salary_company_loc - avg_salary_employee_res\n",
        "numeric_features.append('location_difference')\n",
        "\n",
        "# Engineer another new feature: Grouping job titles\n",
        "# Create a dictionary to map similar job titles to a general category\n",
        "title_mapping = {\n",
        "    # Data Scientists\n",
        "    'Data Scientist': 'Data Scientist', 'Principal Data Scientist': 'Data Scientist',\n",
        "    'Applied Data Scientist': 'Data Scientist', 'AI Scientist': 'Data Scientist',\n",
        "    'Staff Data Scientist': 'Data Scientist', 'Research Scientist': 'Data Scientist',\n",
        "    'Data Science Consultant': 'Data Scientist', 'Lead Data Scientist': 'Data Scientist',\n",
        "    'Data Science Lead': 'Data Scientist',\n",
        "    # Data Engineers\n",
        "    'Data Engineer': 'Data Engineer', 'Lead Data Engineer': 'Data Engineer',\n",
        "    'Principal Data Engineer': 'Data Engineer', 'Data Engineering Manager': 'Data Engineer',\n",
        "    'Data Engineering Specialist': 'Data Engineer', 'Staff Data Engineer': 'Data Engineer',\n",
        "    'Cloud Data Engineer': 'Data Engineer', 'Director of Data Engineering': 'Data Engineer',\n",
        "    # Data Analysts\n",
        "    'Data Analyst': 'Data Analyst', 'Lead Data Analyst': 'Data Analyst',\n",
        "    'Business Intelligence Analyst': 'Data Analyst', 'Principal Data Analyst': 'Data Analyst',\n",
        "    'Data Analytics Manager': 'Data Analyst', 'Data Analytics Lead': 'Data Analyst',\n",
        "    'Data Analytics Specialist': 'Data Analyst',\n",
        "    # Machine Learning Specialists\n",
        "    'Machine Learning Engineer': 'Machine Learning Engineer', 'ML Engineer': 'Machine Learning Engineer',\n",
        "    'Principal Machine Learning Engineer': 'Machine Learning Engineer', 'Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Machine Learning Manager': 'Machine Learning Engineer', 'Applied Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Head of Machine Learning': 'Machine Learning Engineer',\n",
        "    # Other Roles\n",
        "    'Data Architect': 'Data Architect', 'Head of Data': 'Head of Data',\n",
        "    'Data Science Manager': 'Data Science Manager', 'Director of Data Science': 'Data Science Manager',\n",
        "    'Head of Data Science': 'Data Science Manager', 'Analytics Engineer': 'Analytics Engineer',\n",
        "    'BI Analyst': 'Business Intelligence Analyst', 'BI Developer': 'Business Intelligence Analyst',\n",
        "    'Business Intelligence Engineer': 'Business Intelligence Analyst', 'ETL Developer': 'Data Engineer',\n",
        "    'Computer Vision Engineer': 'Computer Vision Engineer', 'NLP Engineer': 'NLP Engineer',\n",
        "    'Research Engineer': 'Research Engineer', 'Financial Data Analyst': 'Data Analyst'\n",
        "}\n",
        "df['job_title_grouped'] = df['job_title'].apply(\n",
        "    lambda x: title_mapping.get(x, 'Other')\n",
        ")\n",
        "\n",
        "# Engineer new combined feature: experience_job_company_combo\n",
        "df['experience_job_company_combo'] = df['experience_level'] + '_' + df['job_title_grouped'] + '_' + df['company_size']\n",
        "\n",
        "# Replace the original job_title and other features with the new combined feature\n",
        "categorical_features = ['employment_type', 'employee_residence', 'company_location']\n",
        "categorical_features.append('experience_job_company_combo')\n",
        "\n",
        "# Create the feature matrix X and target vector y\n",
        "X = df[categorical_features + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Define salary bins and create a new target variable\n",
        "bins = [0, 60000, 120000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['salary_tier'] = pd.cut(df['salary_in_usd'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Use LabelEncoder to convert the new salary tiers into integers for LightGBM\n",
        "le = LabelEncoder()\n",
        "y_tier_encoded = le.fit_transform(df['salary_tier'])\n",
        "\n",
        "print(\"Features processed and new target variable created.\")\n",
        "print(f\"Shape of the initial feature matrix: {X.shape}\")\n",
        "\n",
        "# Splitting the data before encoding to prevent data leakage\n",
        "X_train, X_test, y_train_tier, y_test_tier = train_test_split(\n",
        "    X, y_tier_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Apply TargetEncoder to the categorical features on the training data\n",
        "# and transform the test data\n",
        "print(\"\\nApplying TargetEncoder to categorical features...\")\n",
        "encoder = ce.TargetEncoder(cols=categorical_features)\n",
        "X_train_encoded = encoder.fit_transform(X_train, y_train_tier)\n",
        "X_test_encoded = encoder.transform(X_test)\n",
        "print(\"Target encoding applied.\")\n",
        "\n",
        "# Apply SMOTE to the encoded training data to handle class imbalance\n",
        "print(\"\\nApplying SMOTE to balance the encoded training data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_encoded, y_train_tier)\n",
        "print(\"SMOTE applied. Resampled and encoded training data shapes:\")\n",
        "print(f\"Features: {X_train_resampled.shape}\")\n",
        "print(f\"Target: {y_train_resampled.shape}\")\n",
        "\n",
        "print(\"\\n2. Training the LightGBM Classifier Model with new features...\")\n",
        "# Initialize the LightGBM Classifier with the best parameters found previously\n",
        "lgbm_clf = lgb.LGBMClassifier(\n",
        "    objective='multiclass',\n",
        "    num_class=3,\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.1,\n",
        "    num_leaves=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgbm_clf.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the new classification model...\")\n",
        "y_pred_tier = lgbm_clf.predict(X_test_encoded)\n",
        "accuracy = accuracy_score(y_test_tier, y_pred_tier)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with LightGBM and Feature Combination) ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tier, y_pred_tier, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nStage 19: Feature Combination with Company Size, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHFfXnmCK0K5",
        "outputId": "11c89776-e63c-4e93-ea37-716d5ab5a172"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 19 ---\n",
            "\n",
            "1. Feature Engineering and Data Preparation...\n",
            "Features processed and new target variable created.\n",
            "Shape of the initial feature matrix: (10093, 7)\n",
            "\n",
            "Applying TargetEncoder to categorical features...\n",
            "Target encoding applied.\n",
            "\n",
            "Applying SMOTE to balance the encoded training data...\n",
            "SMOTE applied. Resampled and encoded training data shapes:\n",
            "Features: (14994, 7)\n",
            "Target: (14994,)\n",
            "\n",
            "2. Training the LightGBM Classifier Model with new features...\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.050540 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1318\n",
            "[LightGBM] [Info] Number of data points in the train set: 14994, number of used features: 7\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "Training complete.\n",
            "\n",
            "3. Making predictions and evaluating the new classification model...\n",
            "\n",
            "--- New Model Performance (with LightGBM and Feature Combination) ---\n",
            "Accuracy: 0.6384\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.78      0.74      0.76      1210\n",
            "         Low       0.41      0.56      0.47       167\n",
            "      Medium       0.47      0.46      0.47       642\n",
            "\n",
            "    accuracy                           0.64      2019\n",
            "   macro avg       0.55      0.59      0.57      2019\n",
            "weighted avg       0.65      0.64      0.64      2019\n",
            "\n",
            "\n",
            "Stage 19: Feature Combination with Company Size, Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, PolynomialFeatures\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import category_encoders as ce\n",
        "\n",
        "# --- 20. Polynomial Features and LightGBM ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 20 ---\")\n",
        "print(\"\\n1. Feature Engineering and Data Preparation...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                        'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "# Engineer a new feature: location_difference\n",
        "# Calculate mean salary for company location and employee residence\n",
        "avg_salary_company_loc = df.groupby('company_location')['salary_in_usd'].transform('mean')\n",
        "avg_salary_employee_res = df.groupby('employee_residence')['salary_in_usd'].transform('mean')\n",
        "df['location_difference'] = avg_salary_company_loc - avg_salary_employee_res\n",
        "numeric_features.append('location_difference')\n",
        "\n",
        "# Engineer another new feature: Grouping job titles\n",
        "# Create a dictionary to map similar job titles to a general category\n",
        "title_mapping = {\n",
        "    # Data Scientists\n",
        "    'Data Scientist': 'Data Scientist', 'Principal Data Scientist': 'Data Scientist',\n",
        "    'Applied Data Scientist': 'Data Scientist', 'AI Scientist': 'Data Scientist',\n",
        "    'Staff Data Scientist': 'Data Scientist', 'Research Scientist': 'Data Scientist',\n",
        "    'Data Science Consultant': 'Data Scientist', 'Lead Data Scientist': 'Data Scientist',\n",
        "    'Data Science Lead': 'Data Scientist',\n",
        "    # Data Engineers\n",
        "    'Data Engineer': 'Data Engineer', 'Lead Data Engineer': 'Data Engineer',\n",
        "    'Principal Data Engineer': 'Data Engineer', 'Data Engineering Manager': 'Data Engineer',\n",
        "    'Data Engineering Specialist': 'Data Engineer', 'Staff Data Engineer': 'Data Engineer',\n",
        "    'Cloud Data Engineer': 'Data Engineer', 'Director of Data Engineering': 'Data Engineer',\n",
        "    # Data Analysts\n",
        "    'Data Analyst': 'Data Analyst', 'Lead Data Analyst': 'Data Analyst',\n",
        "    'Business Intelligence Analyst': 'Data Analyst', 'Principal Data Analyst': 'Data Analyst',\n",
        "    'Data Analytics Manager': 'Data Analyst', 'Data Analytics Lead': 'Data Analyst',\n",
        "    'Data Analytics Specialist': 'Data Analyst',\n",
        "    # Machine Learning Specialists\n",
        "    'Machine Learning Engineer': 'Machine Learning Engineer', 'ML Engineer': 'Machine Learning Engineer',\n",
        "    'Principal Machine Learning Engineer': 'Machine Learning Engineer', 'Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Machine Learning Manager': 'Machine Learning Engineer', 'Applied Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Head of Machine Learning': 'Machine Learning Engineer',\n",
        "    # Other Roles\n",
        "    'Data Architect': 'Data Architect', 'Head of Data': 'Head of Data',\n",
        "    'Data Science Manager': 'Data Science Manager', 'Director of Data Science': 'Data Science Manager',\n",
        "    'Head of Data Science': 'Data Science Manager', 'Analytics Engineer': 'Analytics Engineer',\n",
        "    'BI Analyst': 'Business Intelligence Analyst', 'BI Developer': 'Business Intelligence Analyst',\n",
        "    'Business Intelligence Engineer': 'Business Intelligence Analyst', 'ETL Developer': 'Data Engineer',\n",
        "    'Computer Vision Engineer': 'Computer Vision Engineer', 'NLP Engineer': 'NLP Engineer',\n",
        "    'Research Engineer': 'Research Engineer', 'Financial Data Analyst': 'Data Analyst'\n",
        "}\n",
        "df['job_title_grouped'] = df['job_title'].apply(\n",
        "    lambda x: title_mapping.get(x, 'Other')\n",
        ")\n",
        "\n",
        "# Engineer new combined feature: experience_job_company_combo\n",
        "df['experience_job_company_combo'] = df['experience_level'] + '_' + df['job_title_grouped'] + '_' + df['company_size']\n",
        "\n",
        "# Replace the original job_title and other features with the new combined feature\n",
        "# We will use this list to apply target encoding\n",
        "categorical_features = ['employment_type', 'employee_residence', 'company_location', 'experience_job_company_combo']\n",
        "# And this list for the polynomial features\n",
        "numeric_features = ['work_year', 'remote_ratio', 'location_difference']\n",
        "\n",
        "# Create the feature matrix X and target vector y\n",
        "X = df[categorical_features + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Define salary bins and create a new target variable\n",
        "bins = [0, 60000, 120000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['salary_tier'] = pd.cut(df['salary_in_usd'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Use LabelEncoder to convert the new salary tiers into integers for LightGBM\n",
        "le = LabelEncoder()\n",
        "y_tier_encoded = le.fit_transform(df['salary_tier'])\n",
        "\n",
        "print(\"Features processed and new target variable created.\")\n",
        "print(f\"Shape of the initial feature matrix: {X.shape}\")\n",
        "\n",
        "# Splitting the data before encoding to prevent data leakage\n",
        "X_train, X_test, y_train_tier, y_test_tier = train_test_split(\n",
        "    X, y_tier_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Separate categorical and numeric features\n",
        "X_train_cat = X_train[categorical_features]\n",
        "X_train_num = X_train[numeric_features]\n",
        "X_test_cat = X_test[categorical_features]\n",
        "X_test_num = X_test[numeric_features]\n",
        "\n",
        "# Apply TargetEncoder to the categorical features on the training data\n",
        "# and transform the test data\n",
        "print(\"\\nApplying TargetEncoder to categorical features...\")\n",
        "encoder = ce.TargetEncoder(cols=categorical_features)\n",
        "X_train_cat_encoded = encoder.fit_transform(X_train_cat, y_train_tier)\n",
        "X_test_cat_encoded = encoder.transform(X_test_cat)\n",
        "print(\"Target encoding applied.\")\n",
        "\n",
        "# Generate polynomial features from numeric data\n",
        "print(\"\\nGenerating Polynomial Features...\")\n",
        "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "X_train_poly = poly.fit_transform(X_train_num)\n",
        "X_test_poly = poly.transform(X_test_num)\n",
        "print(f\"Shape of training polynomial features: {X_train_poly.shape}\")\n",
        "\n",
        "# Combine encoded categorical and new polynomial features\n",
        "X_train_combined = np.hstack((X_train_cat_encoded, X_train_poly))\n",
        "X_test_combined = np.hstack((X_test_cat_encoded, X_test_poly))\n",
        "\n",
        "print(f\"Combined training data shape: {X_train_combined.shape}\")\n",
        "\n",
        "# Apply SMOTE to the combined training data to handle class imbalance\n",
        "print(\"\\nApplying SMOTE to balance the combined training data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_combined, y_train_tier)\n",
        "print(\"SMOTE applied. Resampled and encoded training data shapes:\")\n",
        "print(f\"Features: {X_train_resampled.shape}\")\n",
        "print(f\"Target: {y_train_resampled.shape}\")\n",
        "\n",
        "print(\"\\n2. Training the LightGBM Classifier Model with new features...\")\n",
        "# Initialize the LightGBM Classifier with the best parameters found previously\n",
        "lgbm_clf = lgb.LGBMClassifier(\n",
        "    objective='multiclass',\n",
        "    num_class=3,\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.1,\n",
        "    num_leaves=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgbm_clf.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the new classification model...\")\n",
        "y_pred_tier = lgbm_clf.predict(X_test_combined)\n",
        "accuracy = accuracy_score(y_test_tier, y_pred_tier)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with LightGBM and Polynomial Features) ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tier, y_pred_tier, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nStage 20: Polynomial Features, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cx8YAsNALGCa",
        "outputId": "9a290bf5-f669-4568-eb47-7fc3e570d483"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 20 ---\n",
            "\n",
            "1. Feature Engineering and Data Preparation...\n",
            "Features processed and new target variable created.\n",
            "Shape of the initial feature matrix: (10093, 7)\n",
            "\n",
            "Applying TargetEncoder to categorical features...\n",
            "Target encoding applied.\n",
            "\n",
            "Generating Polynomial Features...\n",
            "Shape of training polynomial features: (8074, 9)\n",
            "Combined training data shape: (8074, 13)\n",
            "\n",
            "Applying SMOTE to balance the combined training data...\n",
            "SMOTE applied. Resampled and encoded training data shapes:\n",
            "Features: (14994, 13)\n",
            "Target: (14994,)\n",
            "\n",
            "2. Training the LightGBM Classifier Model with new features...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009673 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3265\n",
            "[LightGBM] [Info] Number of data points in the train set: 14994, number of used features: 13\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "Training complete.\n",
            "\n",
            "3. Making predictions and evaluating the new classification model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- New Model Performance (with LightGBM and Polynomial Features) ---\n",
            "Accuracy: 0.6399\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.78      0.74      0.76      1210\n",
            "         Low       0.41      0.55      0.47       167\n",
            "      Medium       0.47      0.47      0.47       642\n",
            "\n",
            "    accuracy                           0.64      2019\n",
            "   macro avg       0.55      0.59      0.57      2019\n",
            "weighted avg       0.65      0.64      0.64      2019\n",
            "\n",
            "\n",
            "Stage 20: Polynomial Features, Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import category_encoders as ce\n",
        "\n",
        "# --- 21. One-Hot Encoding and Mean Salary Feature ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 21 ---\")\n",
        "print(\"\\n1. Feature Engineering and Data Preparation...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                        'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "# Engineer a new feature: location_difference\n",
        "# Calculate mean salary for company location and employee residence\n",
        "avg_salary_company_loc = df.groupby('company_location')['salary_in_usd'].transform('mean')\n",
        "avg_salary_employee_res = df.groupby('employee_residence')['salary_in_usd'].transform('mean')\n",
        "df['location_difference'] = avg_salary_company_loc - avg_salary_employee_res\n",
        "numeric_features.append('location_difference')\n",
        "\n",
        "# Engineer another new feature: Grouping job titles\n",
        "# Create a dictionary to map similar job titles to a general category\n",
        "title_mapping = {\n",
        "    # Data Scientists\n",
        "    'Data Scientist': 'Data Scientist', 'Principal Data Scientist': 'Data Scientist',\n",
        "    'Applied Data Scientist': 'Data Scientist', 'AI Scientist': 'Data Scientist',\n",
        "    'Staff Data Scientist': 'Data Scientist', 'Research Scientist': 'Data Scientist',\n",
        "    'Data Science Consultant': 'Data Scientist', 'Lead Data Scientist': 'Data Scientist',\n",
        "    'Data Science Lead': 'Data Scientist',\n",
        "    # Data Engineers\n",
        "    'Data Engineer': 'Data Engineer', 'Lead Data Engineer': 'Data Engineer',\n",
        "    'Principal Data Engineer': 'Data Engineer', 'Data Engineering Manager': 'Data Engineer',\n",
        "    'Data Engineering Specialist': 'Data Engineer', 'Staff Data Engineer': 'Data Engineer',\n",
        "    'Cloud Data Engineer': 'Data Engineer', 'Director of Data Engineering': 'Data Engineer',\n",
        "    # Data Analysts\n",
        "    'Data Analyst': 'Data Analyst', 'Lead Data Analyst': 'Data Analyst',\n",
        "    'Business Intelligence Analyst': 'Data Analyst', 'Principal Data Analyst': 'Data Analyst',\n",
        "    'Data Analytics Manager': 'Data Analyst', 'Data Analytics Lead': 'Data Analyst',\n",
        "    'Data Analytics Specialist': 'Data Analyst',\n",
        "    # Machine Learning Specialists\n",
        "    'Machine Learning Engineer': 'Machine Learning Engineer', 'ML Engineer': 'Machine Learning Engineer',\n",
        "    'Principal Machine Learning Engineer': 'Machine Learning Engineer', 'Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Machine Learning Manager': 'Machine Learning Engineer', 'Applied Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Head of Machine Learning': 'Machine Learning Engineer',\n",
        "    # Other Roles\n",
        "    'Data Architect': 'Data Architect', 'Head of Data': 'Head of Data',\n",
        "    'Data Science Manager': 'Data Science Manager', 'Director of Data Science': 'Data Science Manager',\n",
        "    'Head of Data Science': 'Data Science Manager', 'Analytics Engineer': 'Analytics Engineer',\n",
        "    'BI Analyst': 'Business Intelligence Analyst', 'BI Developer': 'Business Intelligence Analyst',\n",
        "    'Business Intelligence Engineer': 'Business Intelligence Analyst', 'ETL Developer': 'Data Engineer',\n",
        "    'Computer Vision Engineer': 'Computer Vision Engineer', 'NLP Engineer': 'NLP Engineer',\n",
        "    'Research Engineer': 'Research Engineer', 'Financial Data Analyst': 'Data Analyst'\n",
        "}\n",
        "df['job_title_grouped'] = df['job_title'].apply(\n",
        "    lambda x: title_mapping.get(x, 'Other')\n",
        ")\n",
        "\n",
        "# Engineer new combined feature: experience_job_company_combo\n",
        "df['experience_job_company_combo'] = df['experience_level'] + '_' + df['job_title_grouped'] + '_' + df['company_size']\n",
        "\n",
        "# Calculate the mean salary for each grouped job title\n",
        "job_title_mean_salary = df.groupby('job_title_grouped')['salary_in_usd'].transform('mean')\n",
        "df['job_title_mean_salary'] = job_title_mean_salary\n",
        "numeric_features.append('job_title_mean_salary')\n",
        "\n",
        "# Replace the original job_title and other features with the new combined feature\n",
        "# We will use this list to apply One-Hot encoding\n",
        "categorical_features = ['employment_type', 'employee_residence', 'company_location', 'experience_job_company_combo']\n",
        "\n",
        "# Create the feature matrix X and target vector y\n",
        "X = df[categorical_features + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Define salary bins and create a new target variable\n",
        "bins = [0, 60000, 120000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['salary_tier'] = pd.cut(df['salary_in_usd'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Use LabelEncoder to convert the new salary tiers into integers for LightGBM\n",
        "le = LabelEncoder()\n",
        "y_tier_encoded = le.fit_transform(df['salary_tier'])\n",
        "\n",
        "print(\"Features processed and new target variable created.\")\n",
        "print(f\"Shape of the initial feature matrix: {X.shape}\")\n",
        "\n",
        "# Splitting the data before encoding to prevent data leakage\n",
        "X_train, X_test, y_train_tier, y_test_tier = train_test_split(\n",
        "    X, y_tier_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Separate categorical and numeric features\n",
        "X_train_cat = X_train[categorical_features]\n",
        "X_train_num = X_train[numeric_features]\n",
        "X_test_cat = X_test[categorical_features]\n",
        "X_test_num = X_test[numeric_features]\n",
        "\n",
        "# Use ColumnTransformer to apply OneHotEncoder to categorical features\n",
        "# and leave numeric features untouched\n",
        "print(\"\\nApplying OneHotEncoder to categorical features...\")\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "# Transform the test data\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "print(\"One-Hot encoding applied.\")\n",
        "\n",
        "print(f\"Preprocessed training data shape: {X_train_preprocessed.shape}\")\n",
        "\n",
        "# Apply SMOTE to the preprocessed training data to handle class imbalance\n",
        "print(\"\\nApplying SMOTE to balance the preprocessed training data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_preprocessed, y_train_tier)\n",
        "print(\"SMOTE applied. Resampled and encoded training data shapes:\")\n",
        "print(f\"Features: {X_train_resampled.shape}\")\n",
        "print(f\"Target: {y_train_resampled.shape}\")\n",
        "\n",
        "print(\"\\n2. Training the LightGBM Classifier Model with new features...\")\n",
        "# Initialize the LightGBM Classifier with the best parameters found previously\n",
        "lgbm_clf = lgb.LGBMClassifier(\n",
        "    objective='multiclass',\n",
        "    num_class=3,\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.1,\n",
        "    num_leaves=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgbm_clf.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the new classification model...\")\n",
        "y_pred_tier = lgbm_clf.predict(X_test_preprocessed)\n",
        "accuracy = accuracy_score(y_test_tier, y_pred_tier)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with LightGBM and One-Hot Encoding) ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tier, y_pred_tier, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nStage 21: One-Hot Encoding and Mean Salary Feature, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFPj26ryLaG_",
        "outputId": "6fd4d608-3a5b-48c2-fa94-686a38d2fb1a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 21 ---\n",
            "\n",
            "1. Feature Engineering and Data Preparation...\n",
            "Features processed and new target variable created.\n",
            "Shape of the initial feature matrix: (10093, 8)\n",
            "\n",
            "Applying OneHotEncoder to categorical features...\n",
            "One-Hot encoding applied.\n",
            "Preprocessed training data shape: (8074, 269)\n",
            "\n",
            "Applying SMOTE to balance the preprocessed training data...\n",
            "SMOTE applied. Resampled and encoded training data shapes:\n",
            "Features: (14994, 269)\n",
            "Target: (14994,)\n",
            "\n",
            "2. Training the LightGBM Classifier Model with new features...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.137474 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 6087\n",
            "[LightGBM] [Info] Number of data points in the train set: 14994, number of used features: 162\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "Training complete.\n",
            "\n",
            "3. Making predictions and evaluating the new classification model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- New Model Performance (with LightGBM and One-Hot Encoding) ---\n",
            "Accuracy: 0.6394\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.78      0.74      0.76      1210\n",
            "         Low       0.43      0.52      0.47       167\n",
            "      Medium       0.46      0.48      0.47       642\n",
            "\n",
            "    accuracy                           0.64      2019\n",
            "   macro avg       0.56      0.58      0.57      2019\n",
            "weighted avg       0.65      0.64      0.64      2019\n",
            "\n",
            "\n",
            "Stage 21: One-Hot Encoding and Mean Salary Feature, Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import category_encoders as ce\n",
        "\n",
        "# --- 22. New Feature Engineering and LightGBM ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 22 ---\")\n",
        "print(\"\\n1. Feature Engineering and Data Preparation...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                        'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "# Engineer a new feature: Grouping job titles\n",
        "# Create a dictionary to map similar job titles to a general category\n",
        "title_mapping = {\n",
        "    # Data Scientists\n",
        "    'Data Scientist': 'Data Scientist', 'Principal Data Scientist': 'Data Scientist',\n",
        "    'Applied Data Scientist': 'Data Scientist', 'AI Scientist': 'Data Scientist',\n",
        "    'Staff Data Scientist': 'Data Scientist', 'Research Scientist': 'Data Scientist',\n",
        "    'Data Science Consultant': 'Data Scientist', 'Lead Data Scientist': 'Data Scientist',\n",
        "    'Data Science Lead': 'Data Scientist',\n",
        "    # Data Engineers\n",
        "    'Data Engineer': 'Data Engineer', 'Lead Data Engineer': 'Data Engineer',\n",
        "    'Principal Data Engineer': 'Data Engineer', 'Data Engineering Manager': 'Data Engineer',\n",
        "    'Data Engineering Specialist': 'Data Engineer', 'Staff Data Engineer': 'Data Engineer',\n",
        "    'Cloud Data Engineer': 'Data Engineer', 'Director of Data Engineering': 'Data Engineer',\n",
        "    # Data Analysts\n",
        "    'Data Analyst': 'Data Analyst', 'Lead Data Analyst': 'Data Analyst',\n",
        "    'Business Intelligence Analyst': 'Data Analyst', 'Principal Data Analyst': 'Data Analyst',\n",
        "    'Data Analytics Manager': 'Data Analyst', 'Data Analytics Lead': 'Data Analyst',\n",
        "    'Data Analytics Specialist': 'Data Analyst',\n",
        "    # Machine Learning Specialists\n",
        "    'Machine Learning Engineer': 'Machine Learning Engineer', 'ML Engineer': 'Machine Learning Engineer',\n",
        "    'Principal Machine Learning Engineer': 'Machine Learning Engineer', 'Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Machine Learning Manager': 'Machine Learning Engineer', 'Applied Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Head of Machine Learning': 'Machine Learning Engineer',\n",
        "    # Other Roles\n",
        "    'Data Architect': 'Data Architect', 'Head of Data': 'Head of Data',\n",
        "    'Data Science Manager': 'Data Science Manager', 'Director of Data Science': 'Data Science Manager',\n",
        "    'Head of Data Science': 'Data Science Manager', 'Analytics Engineer': 'Analytics Engineer',\n",
        "    'BI Analyst': 'Business Intelligence Analyst', 'BI Developer': 'Business Intelligence Analyst',\n",
        "    'Business Intelligence Engineer': 'Business Intelligence Analyst', 'ETL Developer': 'Data Engineer',\n",
        "    'Computer Vision Engineer': 'Computer Vision Engineer', 'NLP Engineer': 'NLP Engineer',\n",
        "    'Research Engineer': 'Research Engineer', 'Financial Data Analyst': 'Data Analyst'\n",
        "}\n",
        "df['job_title_grouped'] = df['job_title'].apply(\n",
        "    lambda x: title_mapping.get(x, 'Other')\n",
        ")\n",
        "\n",
        "# Engineer new numeric features based on location mean salaries\n",
        "df['avg_salary_company_loc'] = df.groupby('company_location')['salary_in_usd'].transform('mean')\n",
        "df['avg_salary_employee_res'] = df.groupby('employee_residence')['salary_in_usd'].transform('mean')\n",
        "numeric_features.extend(['avg_salary_company_loc', 'avg_salary_employee_res'])\n",
        "\n",
        "# Engineer a new categorical feature: job_location_combo\n",
        "df['job_location_combo'] = df['job_title_grouped'] + '_' + df['company_location']\n",
        "\n",
        "# Update the feature lists for preprocessing\n",
        "categorical_features = ['experience_level', 'employment_type', 'company_size', 'job_location_combo']\n",
        "numeric_features = ['work_year', 'remote_ratio', 'avg_salary_company_loc', 'avg_salary_employee_res']\n",
        "\n",
        "# Create the feature matrix X and target vector y\n",
        "X = df[categorical_features + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Define salary bins and create a new target variable\n",
        "bins = [0, 60000, 120000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['salary_tier'] = pd.cut(df['salary_in_usd'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Use LabelEncoder to convert the new salary tiers into integers for LightGBM\n",
        "le = LabelEncoder()\n",
        "y_tier_encoded = le.fit_transform(df['salary_tier'])\n",
        "\n",
        "print(\"Features processed and new target variable created.\")\n",
        "print(f\"Shape of the initial feature matrix: {X.shape}\")\n",
        "\n",
        "# Splitting the data before encoding to prevent data leakage\n",
        "X_train, X_test, y_train_tier, y_test_tier = train_test_split(\n",
        "    X, y_tier_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Use ColumnTransformer to apply OneHotEncoder to categorical features\n",
        "# and leave numeric features untouched\n",
        "print(\"\\nApplying OneHotEncoder to categorical features...\")\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "# Transform the test data\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "print(\"One-Hot encoding applied.\")\n",
        "\n",
        "print(f\"Preprocessed training data shape: {X_train_preprocessed.shape}\")\n",
        "\n",
        "# Apply SMOTE to the preprocessed training data to handle class imbalance\n",
        "print(\"\\nApplying SMOTE to balance the preprocessed training data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_preprocessed, y_train_tier)\n",
        "print(\"SMOTE applied. Resampled and encoded training data shapes:\")\n",
        "print(f\"Features: {X_train_resampled.shape}\")\n",
        "print(f\"Target: {y_train_resampled.shape}\")\n",
        "\n",
        "print(\"\\n2. Training the LightGBM Classifier Model with new features...\")\n",
        "# Initialize the LightGBM Classifier with the best parameters found previously\n",
        "lgbm_clf = lgb.LGBMClassifier(\n",
        "    objective='multiclass',\n",
        "    num_class=3,\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.1,\n",
        "    num_leaves=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgbm_clf.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the new classification model...\")\n",
        "y_pred_tier = lgbm_clf.predict(X_test_preprocessed)\n",
        "accuracy = accuracy_score(y_test_tier, y_pred_tier)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with LightGBM and New Feature Engineering) ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tier, y_pred_tier, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nStage 22: New Feature Engineering, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIS26I-qMCAb",
        "outputId": "5e947492-e88d-463d-bac9-bfe5886f6701"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 22 ---\n",
            "\n",
            "1. Feature Engineering and Data Preparation...\n",
            "Features processed and new target variable created.\n",
            "Shape of the initial feature matrix: (10093, 8)\n",
            "\n",
            "Applying OneHotEncoder to categorical features...\n",
            "One-Hot encoding applied.\n",
            "Preprocessed training data shape: (8074, 259)\n",
            "\n",
            "Applying SMOTE to balance the preprocessed training data...\n",
            "SMOTE applied. Resampled and encoded training data shapes:\n",
            "Features: (14994, 259)\n",
            "Target: (14994,)\n",
            "\n",
            "2. Training the LightGBM Classifier Model with new features...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014431 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4314\n",
            "[LightGBM] [Info] Number of data points in the train set: 14994, number of used features: 109\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "Training complete.\n",
            "\n",
            "3. Making predictions and evaluating the new classification model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- New Model Performance (with LightGBM and New Feature Engineering) ---\n",
            "Accuracy: 0.6469\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.78      0.75      0.76      1210\n",
            "         Low       0.45      0.53      0.49       167\n",
            "      Medium       0.48      0.49      0.48       642\n",
            "\n",
            "    accuracy                           0.65      2019\n",
            "   macro avg       0.57      0.59      0.58      2019\n",
            "weighted avg       0.65      0.65      0.65      2019\n",
            "\n",
            "\n",
            "Stage 22: New Feature Engineering, Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import category_encoders as ce\n",
        "\n",
        "# --- 23. Remote Work and Company Size Combo and LightGBM ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 23 ---\")\n",
        "print(\"\\n1. Feature Engineering and Data Preparation...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                        'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "# Engineer a new feature: Grouping job titles\n",
        "# Create a dictionary to map similar job titles to a general category\n",
        "title_mapping = {\n",
        "    # Data Scientists\n",
        "    'Data Scientist': 'Data Scientist', 'Principal Data Scientist': 'Data Scientist',\n",
        "    'Applied Data Scientist': 'Data Scientist', 'AI Scientist': 'Data Scientist',\n",
        "    'Staff Data Scientist': 'Data Scientist', 'Research Scientist': 'Data Scientist',\n",
        "    'Data Science Consultant': 'Data Scientist', 'Lead Data Scientist': 'Data Scientist',\n",
        "    'Data Science Lead': 'Data Scientist',\n",
        "    # Data Engineers\n",
        "    'Data Engineer': 'Data Engineer', 'Lead Data Engineer': 'Data Engineer',\n",
        "    'Principal Data Engineer': 'Data Engineer', 'Data Engineering Manager': 'Data Engineer',\n",
        "    'Data Engineering Specialist': 'Data Engineer', 'Staff Data Engineer': 'Data Engineer',\n",
        "    'Cloud Data Engineer': 'Data Engineer', 'Director of Data Engineering': 'Data Engineer',\n",
        "    # Data Analysts\n",
        "    'Data Analyst': 'Data Analyst', 'Lead Data Analyst': 'Data Analyst',\n",
        "    'Business Intelligence Analyst': 'Data Analyst', 'Principal Data Analyst': 'Data Analyst',\n",
        "    'Data Analytics Manager': 'Data Analyst', 'Data Analytics Lead': 'Data Analyst',\n",
        "    'Data Analytics Specialist': 'Data Analyst',\n",
        "    # Machine Learning Specialists\n",
        "    'Machine Learning Engineer': 'Machine Learning Engineer', 'ML Engineer': 'Machine Learning Engineer',\n",
        "    'Principal Machine Learning Engineer': 'Machine Learning Engineer', 'Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Machine Learning Manager': 'Machine Learning Engineer', 'Applied Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Head of Machine Learning': 'Machine Learning Engineer',\n",
        "    # Other Roles\n",
        "    'Data Architect': 'Data Architect', 'Head of Data': 'Head of Data',\n",
        "    'Data Science Manager': 'Data Science Manager', 'Director of Data Science': 'Data Science Manager',\n",
        "    'Head of Data Science': 'Data Science Manager', 'Analytics Engineer': 'Analytics Engineer',\n",
        "    'BI Analyst': 'Business Intelligence Analyst', 'BI Developer': 'Business Intelligence Analyst',\n",
        "    'Business Intelligence Engineer': 'Business Intelligence Analyst', 'ETL Developer': 'Data Engineer',\n",
        "    'Computer Vision Engineer': 'Computer Vision Engineer', 'NLP Engineer': 'NLP Engineer',\n",
        "    'Research Engineer': 'Research Engineer', 'Financial Data Analyst': 'Data Analyst'\n",
        "}\n",
        "df['job_title_grouped'] = df['job_title'].apply(\n",
        "    lambda x: title_mapping.get(x, 'Other')\n",
        ")\n",
        "\n",
        "# Engineer new numeric features based on location mean salaries\n",
        "df['avg_salary_company_loc'] = df.groupby('company_location')['salary_in_usd'].transform('mean')\n",
        "df['avg_salary_employee_res'] = df.groupby('employee_residence')['salary_in_usd'].transform('mean')\n",
        "numeric_features = ['work_year', 'avg_salary_company_loc', 'avg_salary_employee_res']\n",
        "\n",
        "# Engineer a new categorical feature: job_location_combo\n",
        "df['job_location_combo'] = df['job_title_grouped'] + '_' + df['company_location']\n",
        "\n",
        "# Engineer a new categorical feature: remote_company_size_combo\n",
        "df['remote_company_size_combo'] = df['remote_ratio'].astype(str) + '_' + df['company_size']\n",
        "\n",
        "# Update the feature lists for preprocessing\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_location_combo', 'remote_company_size_combo']\n",
        "numeric_features = ['work_year', 'avg_salary_company_loc', 'avg_salary_employee_res']\n",
        "\n",
        "# Create the feature matrix X and target vector y\n",
        "X = df[categorical_features + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Define salary bins and create a new target variable\n",
        "bins = [0, 60000, 120000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['salary_tier'] = pd.cut(df['salary_in_usd'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Use LabelEncoder to convert the new salary tiers into integers for LightGBM\n",
        "le = LabelEncoder()\n",
        "y_tier_encoded = le.fit_transform(df['salary_tier'])\n",
        "\n",
        "print(\"Features processed and new target variable created.\")\n",
        "print(f\"Shape of the initial feature matrix: {X.shape}\")\n",
        "\n",
        "# Splitting the data before encoding to prevent data leakage\n",
        "X_train, X_test, y_train_tier, y_test_tier = train_test_split(\n",
        "    X, y_tier_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Use ColumnTransformer to apply OneHotEncoder to categorical features\n",
        "# and leave numeric features untouched\n",
        "print(\"\\nApplying OneHotEncoder to categorical features...\")\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "# Transform the test data\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "print(\"One-Hot encoding applied.\")\n",
        "\n",
        "print(f\"Preprocessed training data shape: {X_train_preprocessed.shape}\")\n",
        "\n",
        "# Apply SMOTE to the preprocessed training data to handle class imbalance\n",
        "print(\"\\nApplying SMOTE to balance the preprocessed training data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_preprocessed, y_train_tier)\n",
        "print(\"SMOTE applied. Resampled and encoded training data shapes:\")\n",
        "print(f\"Features: {X_train_resampled.shape}\")\n",
        "print(f\"Target: {y_train_resampled.shape}\")\n",
        "\n",
        "print(\"\\n2. Training the LightGBM Classifier Model with new features...\")\n",
        "# Initialize the LightGBM Classifier with the best parameters found previously\n",
        "lgbm_clf = lgb.LGBMClassifier(\n",
        "    objective='multiclass',\n",
        "    num_class=3,\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.1,\n",
        "    num_leaves=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgbm_clf.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the new classification model...\")\n",
        "y_pred_tier = lgbm_clf.predict(X_test_preprocessed)\n",
        "accuracy = accuracy_score(y_test_tier, y_pred_tier)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with LightGBM and New Feature Engineering) ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tier, y_pred_tier, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nStage 23: Remote Work and Company Size Combo, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQjaR2QUMvjC",
        "outputId": "72e92a26-0562-4772-bad2-958f7d710433"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 23 ---\n",
            "\n",
            "1. Feature Engineering and Data Preparation...\n",
            "Features processed and new target variable created.\n",
            "Shape of the initial feature matrix: (10093, 7)\n",
            "\n",
            "Applying OneHotEncoder to categorical features...\n",
            "One-Hot encoding applied.\n",
            "Preprocessed training data shape: (8074, 264)\n",
            "\n",
            "Applying SMOTE to balance the preprocessed training data...\n",
            "SMOTE applied. Resampled and encoded training data shapes:\n",
            "Features: (14994, 264)\n",
            "Target: (14994,)\n",
            "\n",
            "2. Training the LightGBM Classifier Model with new features...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.189361 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4658\n",
            "[LightGBM] [Info] Number of data points in the train set: 14994, number of used features: 114\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "Training complete.\n",
            "\n",
            "3. Making predictions and evaluating the new classification model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- New Model Performance (with LightGBM and New Feature Engineering) ---\n",
            "Accuracy: 0.6498\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.78      0.75      0.76      1210\n",
            "         Low       0.45      0.55      0.50       167\n",
            "      Medium       0.48      0.49      0.48       642\n",
            "\n",
            "    accuracy                           0.65      2019\n",
            "   macro avg       0.57      0.60      0.58      2019\n",
            "weighted avg       0.66      0.65      0.65      2019\n",
            "\n",
            "\n",
            "Stage 23: Remote Work and Company Size Combo, Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import category_encoders as ce\n",
        "\n",
        "# --- 24. Years of Experience Proxy and LightGBM ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 24 ---\")\n",
        "print(\"\\n1. Feature Engineering and Data Preparation...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                        'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "# Engineer a new feature: Grouping job titles\n",
        "# Create a dictionary to map similar job titles to a general category\n",
        "title_mapping = {\n",
        "    # Data Scientists\n",
        "    'Data Scientist': 'Data Scientist', 'Principal Data Scientist': 'Data Scientist',\n",
        "    'Applied Data Scientist': 'Data Scientist', 'AI Scientist': 'Data Scientist',\n",
        "    'Staff Data Scientist': 'Data Scientist', 'Research Scientist': 'Data Scientist',\n",
        "    'Data Science Consultant': 'Data Scientist', 'Lead Data Scientist': 'Data Scientist',\n",
        "    'Data Science Lead': 'Data Scientist',\n",
        "    # Data Engineers\n",
        "    'Data Engineer': 'Data Engineer', 'Lead Data Engineer': 'Data Engineer',\n",
        "    'Principal Data Engineer': 'Data Engineer', 'Data Engineering Manager': 'Data Engineer',\n",
        "    'Data Engineering Specialist': 'Data Engineer', 'Staff Data Engineer': 'Data Engineer',\n",
        "    'Cloud Data Engineer': 'Data Engineer', 'Director of Data Engineering': 'Data Engineer',\n",
        "    # Data Analysts\n",
        "    'Data Analyst': 'Data Analyst', 'Lead Data Analyst': 'Data Analyst',\n",
        "    'Business Intelligence Analyst': 'Data Analyst', 'Principal Data Analyst': 'Data Analyst',\n",
        "    'Data Analytics Manager': 'Data Analyst', 'Data Analytics Lead': 'Data Analyst',\n",
        "    'Data Analytics Specialist': 'Data Analyst',\n",
        "    # Machine Learning Specialists\n",
        "    'Machine Learning Engineer': 'Machine Learning Engineer', 'ML Engineer': 'Machine Learning Engineer',\n",
        "    'Principal Machine Learning Engineer': 'Machine Learning Engineer', 'Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Machine Learning Manager': 'Machine Learning Engineer', 'Applied Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Head of Machine Learning': 'Machine Learning Engineer',\n",
        "    # Other Roles\n",
        "    'Data Architect': 'Data Architect', 'Head of Data': 'Head of Data',\n",
        "    'Data Science Manager': 'Data Science Manager', 'Director of Data Science': 'Data Science Manager',\n",
        "    'Head of Data Science': 'Data Science Manager', 'Analytics Engineer': 'Analytics Engineer',\n",
        "    'BI Analyst': 'Business Intelligence Analyst', 'BI Developer': 'Business Intelligence Analyst',\n",
        "    'Business Intelligence Engineer': 'Business Intelligence Analyst', 'ETL Developer': 'Data Engineer',\n",
        "    'Computer Vision Engineer': 'Computer Vision Engineer', 'NLP Engineer': 'NLP Engineer',\n",
        "    'Research Engineer': 'Research Engineer', 'Financial Data Analyst': 'Data Analyst'\n",
        "}\n",
        "df['job_title_grouped'] = df['job_title'].apply(\n",
        "    lambda x: title_mapping.get(x, 'Other')\n",
        ")\n",
        "\n",
        "# Engineer new numeric features based on location mean salaries\n",
        "df['avg_salary_company_loc'] = df.groupby('company_location')['salary_in_usd'].transform('mean')\n",
        "df['avg_salary_employee_res'] = df.groupby('employee_residence')['salary_in_usd'].transform('mean')\n",
        "\n",
        "# Engineer a new categorical feature: job_location_combo\n",
        "df['job_location_combo'] = df['job_title_grouped'] + '_' + df['company_location']\n",
        "\n",
        "# Engineer a new categorical feature: remote_company_size_combo\n",
        "df['remote_company_size_combo'] = df['remote_ratio'].astype(str) + '_' + df['company_size']\n",
        "\n",
        "# Engineer a new numeric feature: years_of_experience_proxy\n",
        "df['years_of_experience_proxy'] = 2024 - df['work_year']\n",
        "\n",
        "# Update the feature lists for preprocessing\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_location_combo', 'remote_company_size_combo']\n",
        "numeric_features = ['avg_salary_company_loc', 'avg_salary_employee_res', 'years_of_experience_proxy']\n",
        "\n",
        "# Create the feature matrix X and target vector y\n",
        "X = df[categorical_features + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Define salary bins and create a new target variable\n",
        "bins = [0, 60000, 120000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['salary_tier'] = pd.cut(df['salary_in_usd'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Use LabelEncoder to convert the new salary tiers into integers for LightGBM\n",
        "le = LabelEncoder()\n",
        "y_tier_encoded = le.fit_transform(df['salary_tier'])\n",
        "\n",
        "print(\"Features processed and new target variable created.\")\n",
        "print(f\"Shape of the initial feature matrix: {X.shape}\")\n",
        "\n",
        "# Splitting the data before encoding to prevent data leakage\n",
        "X_train, X_test, y_train_tier, y_test_tier = train_test_split(\n",
        "    X, y_tier_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Use ColumnTransformer to apply OneHotEncoder to categorical features\n",
        "# and leave numeric features untouched\n",
        "print(\"\\nApplying OneHotEncoder to categorical features...\")\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "# Transform the test data\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "print(\"One-Hot encoding applied.\")\n",
        "\n",
        "print(f\"Preprocessed training data shape: {X_train_preprocessed.shape}\")\n",
        "\n",
        "# Apply SMOTE to the preprocessed training data to handle class imbalance\n",
        "print(\"\\nApplying SMOTE to balance the preprocessed training data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_preprocessed, y_train_tier)\n",
        "print(\"SMOTE applied. Resampled and encoded training data shapes:\")\n",
        "print(f\"Features: {X_train_resampled.shape}\")\n",
        "print(f\"Target: {y_train_resampled.shape}\")\n",
        "\n",
        "print(\"\\n2. Training the LightGBM Classifier Model with new features...\")\n",
        "# Initialize the LightGBM Classifier with the best parameters found previously\n",
        "lgbm_clf = lgb.LGBMClassifier(\n",
        "    objective='multiclass',\n",
        "    num_class=3,\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.1,\n",
        "    num_leaves=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgbm_clf.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the new classification model...\")\n",
        "y_pred_tier = lgbm_clf.predict(X_test_preprocessed)\n",
        "accuracy = accuracy_score(y_test_tier, y_pred_tier)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with LightGBM and New Feature Engineering) ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tier, y_pred_tier, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nStage 24: Years of Experience Proxy, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDeXKHQDNhNW",
        "outputId": "0b8e6dba-dee0-448a-f8b1-bf85c0f20e4a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 24 ---\n",
            "\n",
            "1. Feature Engineering and Data Preparation...\n",
            "Features processed and new target variable created.\n",
            "Shape of the initial feature matrix: (10093, 7)\n",
            "\n",
            "Applying OneHotEncoder to categorical features...\n",
            "One-Hot encoding applied.\n",
            "Preprocessed training data shape: (8074, 264)\n",
            "\n",
            "Applying SMOTE to balance the preprocessed training data...\n",
            "SMOTE applied. Resampled and encoded training data shapes:\n",
            "Features: (14994, 264)\n",
            "Target: (14994,)\n",
            "\n",
            "2. Training the LightGBM Classifier Model with new features...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096430 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4658\n",
            "[LightGBM] [Info] Number of data points in the train set: 14994, number of used features: 114\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "Training complete.\n",
            "\n",
            "3. Making predictions and evaluating the new classification model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- New Model Performance (with LightGBM and New Feature Engineering) ---\n",
            "Accuracy: 0.6498\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.78      0.75      0.76      1210\n",
            "         Low       0.45      0.55      0.50       167\n",
            "      Medium       0.48      0.49      0.48       642\n",
            "\n",
            "    accuracy                           0.65      2019\n",
            "   macro avg       0.57      0.60      0.58      2019\n",
            "weighted avg       0.66      0.65      0.65      2019\n",
            "\n",
            "\n",
            "Stage 24: Years of Experience Proxy, Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import category_encoders as ce\n",
        "\n",
        "# --- 25. Targeted Encoding on Job Titles and LightGBM ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 25 ---\")\n",
        "print(\"\\n1. Feature Engineering and Data Preparation...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                        'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "# Engineer a new feature: Grouping job titles\n",
        "# Create a dictionary to map similar job titles to a general category\n",
        "title_mapping = {\n",
        "    # Data Scientists\n",
        "    'Data Scientist': 'Data Scientist', 'Principal Data Scientist': 'Data Scientist',\n",
        "    'Applied Data Scientist': 'Data Scientist', 'AI Scientist': 'Data Scientist',\n",
        "    'Staff Data Scientist': 'Data Scientist', 'Research Scientist': 'Data Scientist',\n",
        "    'Data Science Consultant': 'Data Scientist', 'Lead Data Scientist': 'Data Scientist',\n",
        "    'Data Science Lead': 'Data Scientist',\n",
        "    # Data Engineers\n",
        "    'Data Engineer': 'Data Engineer', 'Lead Data Engineer': 'Data Engineer',\n",
        "    'Principal Data Engineer': 'Data Engineer', 'Data Engineering Manager': 'Data Engineer',\n",
        "    'Data Engineering Specialist': 'Data Engineer', 'Staff Data Engineer': 'Data Engineer',\n",
        "    'Cloud Data Engineer': 'Data Engineer', 'Director of Data Engineering': 'Data Engineer',\n",
        "    # Data Analysts\n",
        "    'Data Analyst': 'Data Analyst', 'Lead Data Analyst': 'Data Analyst',\n",
        "    'Business Intelligence Analyst': 'Data Analyst', 'Principal Data Analyst': 'Data Analyst',\n",
        "    'Data Analytics Manager': 'Data Analyst', 'Data Analytics Lead': 'Data Analyst',\n",
        "    'Data Analytics Specialist': 'Data Analyst',\n",
        "    # Machine Learning Specialists\n",
        "    'Machine Learning Engineer': 'Machine Learning Engineer', 'ML Engineer': 'Machine Learning Engineer',\n",
        "    'Principal Machine Learning Engineer': 'Machine Learning Engineer', 'Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Machine Learning Manager': 'Machine Learning Engineer', 'Applied Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Head of Machine Learning': 'Machine Learning Engineer',\n",
        "    # Other Roles\n",
        "    'Data Architect': 'Data Architect', 'Head of Data': 'Head of Data',\n",
        "    'Data Science Manager': 'Data Science Manager', 'Director of Data Science': 'Data Science Manager',\n",
        "    'Head of Data Science': 'Data Science Manager', 'Analytics Engineer': 'Analytics Engineer',\n",
        "    'BI Analyst': 'Business Intelligence Analyst', 'BI Developer': 'Business Intelligence Analyst',\n",
        "    'Business Intelligence Engineer': 'Business Intelligence Analyst', 'ETL Developer': 'Data Engineer',\n",
        "    'Computer Vision Engineer': 'Computer Vision Engineer', 'NLP Engineer': 'NLP Engineer',\n",
        "    'Research Engineer': 'Research Engineer', 'Financial Data Analyst': 'Data Analyst'\n",
        "}\n",
        "df['job_title_grouped'] = df['job_title'].apply(\n",
        "    lambda x: title_mapping.get(x, 'Other')\n",
        ")\n",
        "\n",
        "# Engineer a new numeric feature: years_of_experience_proxy\n",
        "df['years_of_experience_proxy'] = 2024 - df['work_year']\n",
        "\n",
        "# Update the feature lists for preprocessing\n",
        "categorical_features_ohe = ['experience_level', 'employment_type', 'company_size', 'employee_residence', 'company_location']\n",
        "categorical_features_target_enc = ['job_title_grouped']\n",
        "numeric_features = ['remote_ratio', 'years_of_experience_proxy']\n",
        "\n",
        "# Create the feature matrix X and target vector y\n",
        "X = df[categorical_features_ohe + categorical_features_target_enc + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Define salary bins and create a new target variable\n",
        "bins = [0, 60000, 120000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['salary_tier'] = pd.cut(df['salary_in_usd'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Use LabelEncoder to convert the new salary tiers into integers for LightGBM\n",
        "le = LabelEncoder()\n",
        "y_tier_encoded = le.fit_transform(df['salary_tier'])\n",
        "\n",
        "print(\"Features processed and new target variable created.\")\n",
        "print(f\"Shape of the initial feature matrix: {X.shape}\")\n",
        "\n",
        "# Splitting the data before encoding to prevent data leakage\n",
        "X_train, X_test, y_train_tier, y_test_tier = train_test_split(\n",
        "    X, y_tier_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Use ColumnTransformer to apply different encoders to different columns\n",
        "print(\"\\nApplying One-Hot and Target Encoding to features...\")\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'), categorical_features_ohe),\n",
        "        ('target_encoder', ce.TargetEncoder(cols=categorical_features_target_enc), categorical_features_target_enc)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train, y_train_tier)\n",
        "# Transform the test data\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "print(\"Encoding applied.\")\n",
        "\n",
        "print(f\"Preprocessed training data shape: {X_train_preprocessed.shape}\")\n",
        "\n",
        "# Apply SMOTE to the preprocessed training data to handle class imbalance\n",
        "print(\"\\nApplying SMOTE to balance the preprocessed training data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_preprocessed, y_train_tier)\n",
        "print(\"SMOTE applied. Resampled and encoded training data shapes:\")\n",
        "print(f\"Features: {X_train_resampled.shape}\")\n",
        "print(f\"Target: {y_train_resampled.shape}\")\n",
        "\n",
        "print(\"\\n2. Training the LightGBM Classifier Model with new features...\")\n",
        "# Initialize the LightGBM Classifier with the best parameters found previously\n",
        "lgbm_clf = lgb.LGBMClassifier(\n",
        "    objective='multiclass',\n",
        "    num_class=3,\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.1,\n",
        "    num_leaves=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgbm_clf.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the new classification model...\")\n",
        "y_pred_tier = lgbm_clf.predict(X_test_preprocessed)\n",
        "accuracy = accuracy_score(y_test_tier, y_pred_tier)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with LightGBM and Targeted Encoding) ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tier, y_pred_tier, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nStage 25: Targeted Encoding on Job Titles, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaoThLb0N6L1",
        "outputId": "80c9f73a-fc1c-4af5-ef81-9893d660c091"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 25 ---\n",
            "\n",
            "1. Feature Engineering and Data Preparation...\n",
            "Features processed and new target variable created.\n",
            "Shape of the initial feature matrix: (10093, 8)\n",
            "\n",
            "Applying One-Hot and Target Encoding to features...\n",
            "Encoding applied.\n",
            "Preprocessed training data shape: (8074, 171)\n",
            "\n",
            "Applying SMOTE to balance the preprocessed training data...\n",
            "SMOTE applied. Resampled and encoded training data shapes:\n",
            "Features: (14994, 171)\n",
            "Target: (14994,)\n",
            "\n",
            "2. Training the LightGBM Classifier Model with new features...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.048847 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 4126\n",
            "[LightGBM] [Info] Number of data points in the train set: 14994, number of used features: 93\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "Training complete.\n",
            "\n",
            "3. Making predictions and evaluating the new classification model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- New Model Performance (with LightGBM and Targeted Encoding) ---\n",
            "Accuracy: 0.6374\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.78      0.74      0.76      1210\n",
            "         Low       0.41      0.50      0.45       167\n",
            "      Medium       0.46      0.48      0.47       642\n",
            "\n",
            "    accuracy                           0.64      2019\n",
            "   macro avg       0.55      0.57      0.56      2019\n",
            "weighted avg       0.65      0.64      0.64      2019\n",
            "\n",
            "\n",
            "Stage 25: Targeted Encoding on Job Titles, Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import category_encoders as ce\n",
        "from scipy.stats import randint as sp_randint, uniform as sp_uniform\n",
        "\n",
        "# --- 26. Hyperparameter Tuning on LightGBM ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 26 ---\")\n",
        "print(\"\\n1. Feature Engineering and Data Preparation...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                        'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "# Engineer a new feature: Grouping job titles\n",
        "# Create a dictionary to map similar job titles to a general category\n",
        "title_mapping = {\n",
        "    # Data Scientists\n",
        "    'Data Scientist': 'Data Scientist', 'Principal Data Scientist': 'Data Scientist',\n",
        "    'Applied Data Scientist': 'Data Scientist', 'AI Scientist': 'Data Scientist',\n",
        "    'Staff Data Scientist': 'Data Scientist', 'Research Scientist': 'Data Scientist',\n",
        "    'Data Science Consultant': 'Data Scientist', 'Lead Data Scientist': 'Data Scientist',\n",
        "    'Data Science Lead': 'Data Scientist',\n",
        "    # Data Engineers\n",
        "    'Data Engineer': 'Data Engineer', 'Lead Data Engineer': 'Data Engineer',\n",
        "    'Principal Data Engineer': 'Data Engineer', 'Data Engineering Manager': 'Data Engineer',\n",
        "    'Data Engineering Specialist': 'Data Engineer', 'Staff Data Engineer': 'Data Engineer',\n",
        "    'Cloud Data Engineer': 'Data Engineer', 'Director of Data Engineering': 'Data Engineer',\n",
        "    # Data Analysts\n",
        "    'Data Analyst': 'Data Analyst', 'Lead Data Analyst': 'Data Analyst',\n",
        "    'Business Intelligence Analyst': 'Data Analyst', 'Principal Data Analyst': 'Data Analyst',\n",
        "    'Data Analytics Manager': 'Data Analyst', 'Data Analytics Lead': 'Data Analyst',\n",
        "    'Data Analytics Specialist': 'Data Analyst',\n",
        "    # Machine Learning Specialists\n",
        "    'Machine Learning Engineer': 'Machine Learning Engineer', 'ML Engineer': 'Machine Learning Engineer',\n",
        "    'Principal Machine Learning Engineer': 'Machine Learning Engineer', 'Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Machine Learning Manager': 'Machine Learning Engineer', 'Applied Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Head of Machine Learning': 'Machine Learning Engineer',\n",
        "    # Other Roles\n",
        "    'Data Architect': 'Data Architect', 'Head of Data': 'Head of Data',\n",
        "    'Data Science Manager': 'Data Science Manager', 'Director of Data Science': 'Data Science Manager',\n",
        "    'Head of Data Science': 'Data Science Manager', 'Analytics Engineer': 'Analytics Engineer',\n",
        "    'BI Analyst': 'Business Intelligence Analyst', 'BI Developer': 'Business Intelligence Analyst',\n",
        "    'Business Intelligence Engineer': 'Business Intelligence Analyst', 'ETL Developer': 'Data Engineer',\n",
        "    'Computer Vision Engineer': 'Computer Vision Engineer', 'NLP Engineer': 'NLP Engineer',\n",
        "    'Research Engineer': 'Research Engineer', 'Financial Data Analyst': 'Data Analyst'\n",
        "}\n",
        "df['job_title_grouped'] = df['job_title'].apply(\n",
        "    lambda x: title_mapping.get(x, 'Other')\n",
        ")\n",
        "\n",
        "# Engineer a new numeric feature: years_of_experience_proxy\n",
        "df['years_of_experience_proxy'] = 2024 - df['work_year']\n",
        "\n",
        "# Update the feature lists for preprocessing\n",
        "categorical_features_ohe = ['experience_level', 'employment_type', 'company_size', 'employee_residence', 'company_location']\n",
        "categorical_features_target_enc = ['job_title_grouped']\n",
        "numeric_features = ['remote_ratio', 'years_of_experience_proxy']\n",
        "\n",
        "# Create the feature matrix X and target vector y\n",
        "X = df[categorical_features_ohe + categorical_features_target_enc + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Define salary bins and create a new target variable\n",
        "bins = [0, 60000, 120000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['salary_tier'] = pd.cut(df['salary_in_usd'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Use LabelEncoder to convert the new salary tiers into integers for LightGBM\n",
        "le = LabelEncoder()\n",
        "y_tier_encoded = le.fit_transform(df['salary_tier'])\n",
        "\n",
        "print(\"Features processed and new target variable created.\")\n",
        "print(f\"Shape of the initial feature matrix: {X.shape}\")\n",
        "\n",
        "# Splitting the data before encoding to prevent data leakage\n",
        "X_train, X_test, y_train_tier, y_test_tier = train_test_split(\n",
        "    X, y_tier_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Use ColumnTransformer to apply different encoders to different columns\n",
        "print(\"\\nApplying One-Hot and Target Encoding to features...\")\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'), categorical_features_ohe),\n",
        "        ('target_encoder', ce.TargetEncoder(cols=categorical_features_target_enc), categorical_features_target_enc)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train, y_train_tier)\n",
        "# Transform the test data\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "print(\"Encoding applied.\")\n",
        "\n",
        "print(f\"Preprocessed training data shape: {X_train_preprocessed.shape}\")\n",
        "\n",
        "# Apply SMOTE to the preprocessed training data to handle class imbalance\n",
        "print(\"\\nApplying SMOTE to balance the preprocessed training data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_preprocessed, y_train_tier)\n",
        "print(\"SMOTE applied. Resampled and encoded training data shapes:\")\n",
        "print(f\"Features: {X_train_resampled.shape}\")\n",
        "print(f\"Target: {y_train_resampled.shape}\")\n",
        "\n",
        "print(\"\\n2. Hyperparameter Tuning for the LightGBM Classifier Model...\")\n",
        "\n",
        "# Define the parameter distribution for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': sp_randint(100, 1000),\n",
        "    'learning_rate': sp_uniform(0.01, 0.2),\n",
        "    'num_leaves': sp_randint(20, 150)\n",
        "}\n",
        "\n",
        "# Initialize the LightGBM Classifier\n",
        "lgbm_clf = lgb.LGBMClassifier(objective='multiclass', num_class=3, random_state=42, n_jobs=-1)\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=lgbm_clf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=50,  # Number of parameter settings that are sampled\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1,\n",
        "    cv=5,\n",
        "    random_state=42,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Fit RandomizedSearchCV to the resampled training data\n",
        "random_search.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Hyperparameter tuning complete.\")\n",
        "print(f\"Best parameters found: {random_search.best_params_}\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the tuned classification model...\")\n",
        "# Use the best estimator found by the search to make predictions\n",
        "best_lgbm_clf = random_search.best_estimator_\n",
        "y_pred_tier = best_lgbm_clf.predict(X_test_preprocessed)\n",
        "accuracy = accuracy_score(y_test_tier, y_pred_tier)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with Hyperparameter Tuning) ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tier, y_pred_tier, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nStage 26: Hyperparameter Tuning, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "4cN9mxnCOXw5",
        "outputId": "d1860d7a-d5c5-456b-a2c8-262b23c9faa9"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 26 ---\n",
            "\n",
            "1. Feature Engineering and Data Preparation...\n",
            "Features processed and new target variable created.\n",
            "Shape of the initial feature matrix: (10093, 8)\n",
            "\n",
            "Applying One-Hot and Target Encoding to features...\n",
            "Encoding applied.\n",
            "Preprocessed training data shape: (8074, 171)\n",
            "\n",
            "Applying SMOTE to balance the preprocessed training data...\n",
            "SMOTE applied. Resampled and encoded training data shapes:\n",
            "Features: (14994, 171)\n",
            "Target: (14994,)\n",
            "\n",
            "2. Hyperparameter Tuning for the LightGBM Classifier Model...\n",
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4267480646.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;31m# Fit RandomizedSearchCV to the resampled training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_resampled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_resampled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hyperparameter tuning complete.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Best parameters found: {random_search.best_params_}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1949\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1950\u001b[0m         \u001b[0;34m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1951\u001b[0;31m         evaluate_candidates(\n\u001b[0m\u001b[1;32m   1952\u001b[0m             ParameterSampler(\n\u001b[1;32m   1953\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2070\u001b[0m         \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2072\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1681\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1682\u001b[0;31m                 \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1684\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1798\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTASK_PENDING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1799\u001b[0m                 ):\n\u001b[0;32m-> 1800\u001b[0;31m                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1801\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1802\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import category_encoders as ce\n",
        "\n",
        "# --- 27. Regression to Classification Approach with LightGBM ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 27 ---\")\n",
        "print(\"\\n1. Feature Engineering and Data Preparation...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                        'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "# Engineer a new feature: Grouping job titles\n",
        "# Create a dictionary to map similar job titles to a general category\n",
        "title_mapping = {\n",
        "    # Data Scientists\n",
        "    'Data Scientist': 'Data Scientist', 'Principal Data Scientist': 'Data Scientist',\n",
        "    'Applied Data Scientist': 'Data Scientist', 'AI Scientist': 'Data Scientist',\n",
        "    'Staff Data Scientist': 'Data Scientist', 'Research Scientist': 'Data Scientist',\n",
        "    'Data Science Consultant': 'Data Scientist', 'Lead Data Scientist': 'Data Scientist',\n",
        "    'Data Science Lead': 'Data Scientist',\n",
        "    # Data Engineers\n",
        "    'Data Engineer': 'Data Engineer', 'Lead Data Engineer': 'Data Engineer',\n",
        "    'Principal Data Engineer': 'Data Engineer', 'Data Engineering Manager': 'Data Engineer',\n",
        "    'Data Engineering Specialist': 'Data Engineer', 'Staff Data Engineer': 'Data Engineer',\n",
        "    'Cloud Data Engineer': 'Data Engineer', 'Director of Data Engineering': 'Data Engineer',\n",
        "    # Data Analysts\n",
        "    'Data Analyst': 'Data Analyst', 'Lead Data Analyst': 'Data Analyst',\n",
        "    'Business Intelligence Analyst': 'Data Analyst', 'Principal Data Analyst': 'Data Analyst',\n",
        "    'Data Analytics Manager': 'Data Analyst', 'Data Analytics Lead': 'Data Analyst',\n",
        "    'Data Analytics Specialist': 'Data Analyst',\n",
        "    # Machine Learning Specialists\n",
        "    'Machine Learning Engineer': 'Machine Learning Engineer', 'ML Engineer': 'Machine Learning Engineer',\n",
        "    'Principal Machine Learning Engineer': 'Machine Learning Engineer', 'Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Machine Learning Manager': 'Machine Learning Engineer', 'Applied Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Head of Machine Learning': 'Machine Learning Engineer',\n",
        "    # Other Roles\n",
        "    'Data Architect': 'Data Architect', 'Head of Data': 'Head of Data',\n",
        "    'Data Science Manager': 'Data Science Manager', 'Director of Data Science': 'Data Science Manager',\n",
        "    'Head of Data Science': 'Data Science Manager', 'Analytics Engineer': 'Analytics Engineer',\n",
        "    'BI Analyst': 'Business Intelligence Analyst', 'BI Developer': 'Business Intelligence Analyst',\n",
        "    'Business Intelligence Engineer': 'Business Intelligence Analyst', 'ETL Developer': 'Data Engineer',\n",
        "    'Computer Vision Engineer': 'Computer Vision Engineer', 'NLP Engineer': 'NLP Engineer',\n",
        "    'Research Engineer': 'Research Engineer', 'Financial Data Analyst': 'Data Analyst'\n",
        "}\n",
        "df['job_title_grouped'] = df['job_title'].apply(\n",
        "    lambda x: title_mapping.get(x, 'Other')\n",
        ")\n",
        "\n",
        "# Engineer a new numeric feature: years_of_experience_proxy\n",
        "df['years_of_experience_proxy'] = 2024 - df['work_year']\n",
        "\n",
        "# Update the feature lists for preprocessing\n",
        "categorical_features_ohe = ['experience_level', 'employment_type', 'company_size', 'employee_residence', 'company_location']\n",
        "categorical_features_target_enc = ['job_title_grouped']\n",
        "numeric_features = ['remote_ratio', 'years_of_experience_proxy']\n",
        "\n",
        "# Create the feature matrix X and target vector y\n",
        "X = df[categorical_features_ohe + categorical_features_target_enc + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Define salary bins and create a new target variable\n",
        "bins = [0, 60000, 120000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['salary_tier'] = pd.cut(df['salary_in_usd'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Use LabelEncoder to convert the new salary tiers into integers for LightGBM\n",
        "le = LabelEncoder()\n",
        "y_tier_encoded = le.fit_transform(df['salary_tier'])\n",
        "\n",
        "print(\"Features processed and new target variable created.\")\n",
        "print(f\"Shape of the initial feature matrix: {X.shape}\")\n",
        "\n",
        "# Splitting the data before encoding to prevent data leakage\n",
        "# Note: For regression, we split on the original continuous target `y`\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Use ColumnTransformer to apply different encoders to different columns\n",
        "print(\"\\nApplying One-Hot and Target Encoding to features...\")\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'), categorical_features_ohe),\n",
        "        ('target_encoder', ce.TargetEncoder(cols=categorical_features_target_enc), categorical_features_target_enc)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train, y_train)\n",
        "# Transform the test data\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "print(\"Encoding applied.\")\n",
        "\n",
        "print(f\"Preprocessed training data shape: {X_train_preprocessed.shape}\")\n",
        "\n",
        "# --- Since this is a regression problem, we don't use SMOTE to oversample the target. ---\n",
        "\n",
        "print(\"\\n2. Training the LightGBM Regressor Model...\")\n",
        "# Initialize the LightGBM Regressor\n",
        "lgbm_reg = lgb.LGBMRegressor(\n",
        "    objective='regression_l1', # Use L1 objective for robustness to outliers\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.1,\n",
        "    num_leaves=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgbm_reg.fit(X_train_preprocessed, y_train)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the new regression model...\")\n",
        "# Make predictions on the test set\n",
        "y_pred_reg = lgbm_reg.predict(X_test_preprocessed)\n",
        "\n",
        "# Now, we convert the regression predictions into our salary tiers for classification evaluation\n",
        "# We use the same bins as before\n",
        "y_pred_tier_reg = pd.cut(y_pred_reg, bins=bins, labels=labels, right=False)\n",
        "y_test_tier = pd.cut(y_test, bins=bins, labels=labels, right=False)\n",
        "y_pred_tier_encoded = le.fit_transform(y_pred_tier_reg)\n",
        "y_test_tier_encoded = le.transform(y_test_tier)\n",
        "\n",
        "# Evaluate the performance using classification metrics\n",
        "accuracy = accuracy_score(y_test_tier_encoded, y_pred_tier_encoded)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with Regression to Classification Approach) ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tier_encoded, y_pred_tier_encoded, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nStage 27: Regression to Classification, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyK9CymBgGKo",
        "outputId": "68f64b1b-2f2d-4ba2-d650-a28bf5f59771"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 27 ---\n",
            "\n",
            "1. Feature Engineering and Data Preparation...\n",
            "Features processed and new target variable created.\n",
            "Shape of the initial feature matrix: (10093, 8)\n",
            "\n",
            "Applying One-Hot and Target Encoding to features...\n",
            "Encoding applied.\n",
            "Preprocessed training data shape: (8074, 171)\n",
            "\n",
            "2. Training the LightGBM Regressor Model...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001800 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 82\n",
            "[LightGBM] [Info] Number of data points in the train set: 8074, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 138900.000000\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "Training complete.\n",
            "\n",
            "3. Making predictions and evaluating the new regression model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- New Model Performance (with Regression to Classification Approach) ---\n",
            "Accuracy: 0.6919\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.74      0.88      0.80      1210\n",
            "         Low       0.66      0.47      0.55       167\n",
            "      Medium       0.56      0.39      0.46       642\n",
            "\n",
            "    accuracy                           0.69      2019\n",
            "   macro avg       0.65      0.58      0.60      2019\n",
            "weighted avg       0.67      0.69      0.67      2019\n",
            "\n",
            "\n",
            "Stage 27: Regression to Classification, Training and Evaluation Complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import category_encoders as ce\n",
        "\n",
        "# --- 28. Weighted Regression to Classification Approach with LightGBM ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 28 ---\")\n",
        "print(\"\\n1. Feature Engineering and Data Preparation...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                        'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "# Engineer a new feature: Grouping job titles\n",
        "# Create a dictionary to map similar job titles to a general category\n",
        "title_mapping = {\n",
        "    # Data Scientists\n",
        "    'Data Scientist': 'Data Scientist', 'Principal Data Scientist': 'Data Scientist',\n",
        "    'Applied Data Scientist': 'Data Scientist', 'AI Scientist': 'Data Scientist',\n",
        "    'Staff Data Scientist': 'Data Scientist', 'Research Scientist': 'Data Scientist',\n",
        "    'Data Science Consultant': 'Data Scientist', 'Lead Data Scientist': 'Data Scientist',\n",
        "    'Data Science Lead': 'Data Scientist',\n",
        "    # Data Engineers\n",
        "    'Data Engineer': 'Data Engineer', 'Lead Data Engineer': 'Data Engineer',\n",
        "    'Principal Data Engineer': 'Data Engineer', 'Data Engineering Manager': 'Data Engineer',\n",
        "    'Data Engineering Specialist': 'Data Engineer', 'Staff Data Engineer': 'Data Engineer',\n",
        "    'Cloud Data Engineer': 'Data Engineer', 'Director of Data Engineering': 'Data Engineer',\n",
        "    # Data Analysts\n",
        "    'Data Analyst': 'Data Analyst', 'Lead Data Analyst': 'Data Analyst',\n",
        "    'Business Intelligence Analyst': 'Data Analyst', 'Principal Data Analyst': 'Data Analyst',\n",
        "    'Data Analytics Manager': 'Data Analyst', 'Data Analytics Lead': 'Data Analyst',\n",
        "    'Data Analytics Specialist': 'Data Analyst',\n",
        "    # Machine Learning Specialists\n",
        "    'Machine Learning Engineer': 'Machine Learning Engineer', 'ML Engineer': 'Machine Learning Engineer',\n",
        "    'Principal Machine Learning Engineer': 'Machine Learning Engineer', 'Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Machine Learning Manager': 'Machine Learning Engineer', 'Applied Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Head of Machine Learning': 'Machine Learning Engineer',\n",
        "    # Other Roles\n",
        "    'Data Architect': 'Data Architect', 'Head of Data': 'Head of Data',\n",
        "    'Data Science Manager': 'Data Science Manager', 'Director of Data Science': 'Data Science Manager',\n",
        "    'Head of Data Science': 'Data Science Manager', 'Analytics Engineer': 'Analytics Engineer',\n",
        "    'BI Analyst': 'Business Intelligence Analyst', 'BI Developer': 'Business Intelligence Analyst',\n",
        "    'Business Intelligence Engineer': 'Business Intelligence Analyst', 'ETL Developer': 'Data Engineer',\n",
        "    'Computer Vision Engineer': 'Computer Vision Engineer', 'NLP Engineer': 'NLP Engineer',\n",
        "    'Research Engineer': 'Research Engineer', 'Financial Data Analyst': 'Data Analyst'\n",
        "}\n",
        "df['job_title_grouped'] = df['job_title'].apply(\n",
        "    lambda x: title_mapping.get(x, 'Other')\n",
        ")\n",
        "\n",
        "# Engineer a new numeric feature: years_of_experience_proxy\n",
        "df['years_of_experience_proxy'] = 2024 - df['work_year']\n",
        "\n",
        "# Update the feature lists for preprocessing\n",
        "categorical_features_ohe = ['experience_level', 'employment_type', 'company_size', 'employee_residence', 'company_location']\n",
        "categorical_features_target_enc = ['job_title_grouped']\n",
        "numeric_features = ['remote_ratio', 'years_of_experience_proxy']\n",
        "\n",
        "# Create the feature matrix X and target vector y\n",
        "X = df[categorical_features_ohe + categorical_features_target_enc + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Define salary bins and create a new target variable for weighting\n",
        "bins = [0, 60000, 120000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['salary_tier'] = pd.cut(df['salary_in_usd'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Use LabelEncoder to convert the new salary tiers into integers for LightGBM\n",
        "le = LabelEncoder()\n",
        "y_tier_encoded = le.fit_transform(df['salary_tier'])\n",
        "\n",
        "print(\"Features processed and new target variable created.\")\n",
        "print(f\"Shape of the initial feature matrix: {X.shape}\")\n",
        "\n",
        "# Splitting the data before encoding to prevent data leakage\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "_, _, y_train_tier, _ = train_test_split(\n",
        "    X, y_tier_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Use ColumnTransformer to apply different encoders to different columns\n",
        "print(\"\\nApplying One-Hot and Target Encoding to features...\")\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'), categorical_features_ohe),\n",
        "        ('target_encoder', ce.TargetEncoder(cols=categorical_features_target_enc), categorical_features_target_enc)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train, y_train)\n",
        "# Transform the test data\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "print(\"Encoding applied.\")\n",
        "\n",
        "print(f\"Preprocessed training data shape: {X_train_preprocessed.shape}\")\n",
        "\n",
        "# --- Creating a sample weight array to address class imbalance ---\n",
        "print(\"\\nCreating sample weights to address class imbalance...\")\n",
        "class_counts = pd.Series(y_train_tier).value_counts()\n",
        "total_samples = len(y_train_tier)\n",
        "class_weights = total_samples / (len(class_counts) * class_counts)\n",
        "\n",
        "# Map the weights to the training data\n",
        "sample_weights = np.array([class_weights[tier] for tier in y_train_tier])\n",
        "\n",
        "print(\"\\n2. Training the LightGBM Regressor Model with sample weights...\")\n",
        "# Initialize the LightGBM Regressor\n",
        "lgbm_reg = lgb.LGBMRegressor(\n",
        "    objective='regression_l1',\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.1,\n",
        "    num_leaves=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the model with the sample weights\n",
        "lgbm_reg.fit(X_train_preprocessed, y_train, sample_weight=sample_weights)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the new regression model...\")\n",
        "# Make predictions on the test set\n",
        "y_pred_reg = lgbm_reg.predict(X_test_preprocessed)\n",
        "\n",
        "# Now, we convert the regression predictions into our salary tiers for classification evaluation\n",
        "# We use the same bins as before\n",
        "y_pred_tier_reg = pd.cut(y_pred_reg, bins=bins, labels=labels, right=False)\n",
        "y_test_tier = pd.cut(y_test, bins=bins, labels=labels, right=False)\n",
        "y_pred_tier_encoded = le.fit_transform(y_pred_tier_reg)\n",
        "y_test_tier_encoded = le.transform(y_test_tier)\n",
        "\n",
        "# Evaluate the performance using classification metrics\n",
        "accuracy = accuracy_score(y_test_tier_encoded, y_pred_tier_encoded)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with Weighted Regression) ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tier_encoded, y_pred_tier_encoded, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nStage 28: Weighted Regression, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGE-h_J1geAe",
        "outputId": "467e8202-4971-4810-9e4a-5910eba43d92"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 28 ---\n",
            "\n",
            "1. Feature Engineering and Data Preparation...\n",
            "Features processed and new target variable created.\n",
            "Shape of the initial feature matrix: (10093, 8)\n",
            "\n",
            "Applying One-Hot and Target Encoding to features...\n",
            "Encoding applied.\n",
            "Preprocessed training data shape: (8074, 171)\n",
            "\n",
            "Creating sample weights to address class imbalance...\n",
            "\n",
            "2. Training the LightGBM Regressor Model with sample weights...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025333 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 82\n",
            "[LightGBM] [Info] Number of data points in the train set: 8074, number of used features: 33\n",
            "[LightGBM] [Info] Start training from score 92280.000000\n",
            "Training complete.\n",
            "\n",
            "3. Making predictions and evaluating the new regression model...\n",
            "\n",
            "--- New Model Performance (with Weighted Regression) ---\n",
            "Accuracy: 0.6231\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.80      0.68      0.74      1210\n",
            "         Low       0.42      0.71      0.52       167\n",
            "      Medium       0.45      0.50      0.47       642\n",
            "\n",
            "    accuracy                           0.62      2019\n",
            "   macro avg       0.56      0.63      0.58      2019\n",
            "weighted avg       0.66      0.62      0.63      2019\n",
            "\n",
            "\n",
            "Stage 28: Weighted Regression, Training and Evaluation Complete.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries for this stage\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import category_encoders as ce\n",
        "\n",
        "# --- 29. Statistical Feature Engineering and LightGBM Classifier ---\n",
        "print(\"--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 29 ---\")\n",
        "print(\"\\n1. Feature Engineering and Data Preparation...\")\n",
        "\n",
        "# Re-create the data preparation steps for a self-contained example\n",
        "df = pd.read_csv('salaries.csv')\n",
        "df.dropna(inplace=True)\n",
        "df.drop_duplicates(inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "categorical_features = ['experience_level', 'employment_type', 'job_title', 'employee_residence',\n",
        "                        'company_location', 'company_size']\n",
        "numeric_features = ['work_year', 'remote_ratio']\n",
        "target = 'salary_in_usd'\n",
        "\n",
        "# Check if all required features are in the DataFrame before proceeding\n",
        "all_features = categorical_features + numeric_features + [target]\n",
        "missing_features = [col for col in all_features if col not in df.columns]\n",
        "if missing_features:\n",
        "    print(f\"Error: The following required features are missing from the dataset: {missing_features}\")\n",
        "    print(\"Please check your 'salaries.csv' file.\")\n",
        "    raise KeyError(\"Missing required features in the DataFrame.\")\n",
        "\n",
        "# Engineer a new feature: Grouping job titles\n",
        "# Create a dictionary to map similar job titles to a general category\n",
        "title_mapping = {\n",
        "    # Data Scientists\n",
        "    'Data Scientist': 'Data Scientist', 'Principal Data Scientist': 'Data Scientist',\n",
        "    'Applied Data Scientist': 'Data Scientist', 'AI Scientist': 'Data Scientist',\n",
        "    'Staff Data Scientist': 'Data Scientist', 'Research Scientist': 'Data Scientist',\n",
        "    'Data Science Consultant': 'Data Scientist', 'Lead Data Scientist': 'Data Scientist',\n",
        "    'Data Science Lead': 'Data Scientist',\n",
        "    # Data Engineers\n",
        "    'Data Engineer': 'Data Engineer', 'Lead Data Engineer': 'Data Engineer',\n",
        "    'Principal Data Engineer': 'Data Engineer', 'Data Engineering Manager': 'Data Engineer',\n",
        "    'Data Engineering Specialist': 'Data Engineer', 'Staff Data Engineer': 'Data Engineer',\n",
        "    'Cloud Data Engineer': 'Data Engineer', 'Director of Data Engineering': 'Data Engineer',\n",
        "    # Data Analysts\n",
        "    'Data Analyst': 'Data Analyst', 'Lead Data Analyst': 'Data Analyst',\n",
        "    'Business Intelligence Analyst': 'Data Analyst', 'Principal Data Analyst': 'Data Analyst',\n",
        "    'Data Analytics Manager': 'Data Analyst', 'Data Analytics Lead': 'Data Analyst',\n",
        "    'Data Analytics Specialist': 'Data Analyst',\n",
        "    # Machine Learning Specialists\n",
        "    'Machine Learning Engineer': 'Machine Learning Engineer', 'ML Engineer': 'Machine Learning Engineer',\n",
        "    'Principal Machine Learning Engineer': 'Machine Learning Engineer', 'Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Machine Learning Manager': 'Machine Learning Engineer', 'Applied Machine Learning Scientist': 'Machine Learning Engineer',\n",
        "    'Head of Machine Learning': 'Machine Learning Engineer',\n",
        "    # Other Roles\n",
        "    'Data Architect': 'Data Architect', 'Head of Data': 'Head of Data',\n",
        "    'Data Science Manager': 'Data Science Manager', 'Director of Data Science': 'Data Science Manager',\n",
        "    'Head of Data Science': 'Data Science Manager', 'Analytics Engineer': 'Analytics Engineer',\n",
        "    'BI Analyst': 'Business Intelligence Analyst', 'BI Developer': 'Business Intelligence Analyst',\n",
        "    'Business Intelligence Engineer': 'Business Intelligence Analyst', 'ETL Developer': 'Data Engineer',\n",
        "    'Computer Vision Engineer': 'Computer Vision Engineer', 'NLP Engineer': 'NLP Engineer',\n",
        "    'Research Engineer': 'Research Engineer', 'Financial Data Analyst': 'Data Analyst'\n",
        "}\n",
        "df['job_title_grouped'] = df['job_title'].apply(\n",
        "    lambda x: title_mapping.get(x, 'Other')\n",
        ")\n",
        "\n",
        "# Engineer a new numeric feature: years_of_experience_proxy\n",
        "df['years_of_experience_proxy'] = 2024 - df['work_year']\n",
        "\n",
        "# Engineer new binary features for top locations\n",
        "df['is_us_company'] = (df['company_location'] == 'US').astype(int)\n",
        "df['is_gb_company'] = (df['company_location'] == 'GB').astype(int)\n",
        "df['is_us_residence'] = (df['employee_residence'] == 'US').astype(int)\n",
        "df['is_gb_residence'] = (df['employee_residence'] == 'GB').astype(int)\n",
        "\n",
        "# Update the feature lists for preprocessing\n",
        "categorical_features_ohe = ['experience_level', 'employment_type', 'company_size']\n",
        "categorical_features_target_enc = ['job_title_grouped']\n",
        "numeric_features = ['remote_ratio', 'years_of_experience_proxy', 'is_us_company',\n",
        "                    'is_gb_company', 'is_us_residence', 'is_gb_residence']\n",
        "\n",
        "# Create the feature matrix X and target vector y\n",
        "X = df[categorical_features_ohe + categorical_features_target_enc + numeric_features]\n",
        "y = df[target]\n",
        "\n",
        "# Define salary bins and create a new target variable\n",
        "bins = [0, 60000, 120000, np.inf]\n",
        "labels = ['Low', 'Medium', 'High']\n",
        "df['salary_tier'] = pd.cut(df['salary_in_usd'], bins=bins, labels=labels, right=False)\n",
        "\n",
        "# Use LabelEncoder to convert the new salary tiers into integers for LightGBM\n",
        "le = LabelEncoder()\n",
        "y_tier_encoded = le.fit_transform(df['salary_tier'])\n",
        "\n",
        "print(\"Features processed and new target variable created.\")\n",
        "print(f\"Shape of the initial feature matrix: {X.shape}\")\n",
        "\n",
        "# Splitting the data before encoding to prevent data leakage\n",
        "X_train, X_test, y_train_tier, y_test_tier = train_test_split(\n",
        "    X, y_tier_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "_, _, y_train_continuous, _ = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# Use ColumnTransformer to apply different encoders to different columns\n",
        "print(\"\\nApplying One-Hot and Target Encoding to features...\")\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'), categorical_features_ohe),\n",
        "        ('target_encoder', ce.TargetEncoder(cols=categorical_features_target_enc), categorical_features_target_enc)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train, y_train_continuous)\n",
        "# Transform the test data\n",
        "X_test_preprocessed = preprocessor.transform(X_test)\n",
        "print(\"Encoding applied.\")\n",
        "\n",
        "print(f\"Preprocessed training data shape: {X_train_preprocessed.shape}\")\n",
        "\n",
        "# Apply SMOTE to the preprocessed training data to handle class imbalance\n",
        "print(\"\\nApplying SMOTE to balance the preprocessed training data...\")\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_preprocessed, y_train_tier)\n",
        "print(\"SMOTE applied. Resampled and encoded training data shapes:\")\n",
        "print(f\"Features: {X_train_resampled.shape}\")\n",
        "print(f\"Target: {y_train_resampled.shape}\")\n",
        "\n",
        "print(\"\\n2. Training the LightGBM Classifier Model with new statistical features...\")\n",
        "# Initialize the LightGBM Classifier\n",
        "lgbm_clf = lgb.LGBMClassifier(\n",
        "    objective='multiclass',\n",
        "    num_class=3,\n",
        "    n_estimators=500,\n",
        "    learning_rate=0.1,\n",
        "    num_leaves=100,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "lgbm_clf.fit(X_train_resampled, y_train_resampled)\n",
        "print(\"Training complete.\")\n",
        "\n",
        "print(\"\\n3. Making predictions and evaluating the new classification model...\")\n",
        "y_pred_tier = lgbm_clf.predict(X_test_preprocessed)\n",
        "accuracy = accuracy_score(y_test_tier, y_pred_tier)\n",
        "\n",
        "print(\"\\n--- New Model Performance (with Statistical Feature Engineering) ---\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_tier, y_pred_tier, target_names=le.classes_))\n",
        "\n",
        "print(\"\\nStage 29: Statistical Feature Engineering, Training and Evaluation Complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oxe5T9O8hPxD",
        "outputId": "6f36ce39-2d3a-4512-8b27-767a22e6303f"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- MLPayGrade Advanced Track: Cleaned Notebook Code - Stage 29 ---\n",
            "\n",
            "1. Feature Engineering and Data Preparation...\n",
            "Features processed and new target variable created.\n",
            "Shape of the initial feature matrix: (10093, 10)\n",
            "\n",
            "Applying One-Hot and Target Encoding to features...\n",
            "Encoding applied.\n",
            "Preprocessed training data shape: (8074, 18)\n",
            "\n",
            "Applying SMOTE to balance the preprocessed training data...\n",
            "SMOTE applied. Resampled and encoded training data shapes:\n",
            "Features: (14994, 18)\n",
            "Target: (14994,)\n",
            "\n",
            "2. Training the LightGBM Classifier Model with new statistical features...\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.025987 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3239\n",
            "[LightGBM] [Info] Number of data points in the train set: 14994, number of used features: 18\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "[LightGBM] [Info] Start training from score -1.098612\n",
            "Training complete.\n",
            "\n",
            "3. Making predictions and evaluating the new classification model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- New Model Performance (with Statistical Feature Engineering) ---\n",
            "Accuracy: 0.6340\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       0.78      0.74      0.76      1210\n",
            "         Low       0.38      0.43      0.40       167\n",
            "      Medium       0.46      0.48      0.47       642\n",
            "\n",
            "    accuracy                           0.63      2019\n",
            "   macro avg       0.54      0.55      0.54      2019\n",
            "weighted avg       0.64      0.63      0.64      2019\n",
            "\n",
            "\n",
            "Stage 29: Statistical Feature Engineering, Training and Evaluation Complete.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}