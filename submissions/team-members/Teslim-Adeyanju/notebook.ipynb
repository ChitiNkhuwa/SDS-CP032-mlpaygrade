{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51f49d63",
   "metadata": {},
   "source": [
    "# ⚖️ DeepCompNet: ML Salary Prediction & SHAP Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcc84c0",
   "metadata": {},
   "source": [
    "───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────    \n",
    "📘 **Author:** Teslim Uthman Adeyanju  \n",
    "📫 **Email:** [info@adeyanjuteslim.co.uk](mailto:info@adeyanjuteslim.co.uk)  \n",
    "🔗 **LinkedIn:** [linkedin.com/in/adeyanjuteslimuthman](https://www.linkedin.com/in/adeyanjuteslimuthman)  \n",
    "🌐 **Website & Blog:** [adeyanjuteslim.co.uk](https://adeyanjuteslim.co.uk)  \n",
    "───────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3652b1",
   "metadata": {},
   "source": [
    "### Table of Contents\n",
    "\n",
    "By following this roadmap, readers can gain a comprehensive understanding of the DeepCompNet project. The roadmap is divided into the following sections:\n",
    "\n",
    "1. [Introduction](#1-introduction)  \n",
    "   - 1.1 [Project Overview](#11-project-overview)  \n",
    "   - 1.2 [Project Objectives](#12-project-objectives)  \n",
    "   - 1.3 [Business Value](#13-business-value)  \n",
    "   - 1.4 [Tools and Technologies](#14-tools-and-technologies)\n",
    "\n",
    "2. [Data Collection & Understanding](#2-data-collection--understanding)  \n",
    "   - 2.1 [Dataset Overview](#21-dataset-overview)  \n",
    "   - 2.2 [Data Fields and Definitions](#22-data-fields-and-definitions)  \n",
    "   - 2.3 [Initial Exploration](#23-initial-exploration)  \n",
    "   - 2.4 [Assumptions and Limitations](#24-assumptions-and-limitations)\n",
    "\n",
    "3. [Exploratory Data Analysis (EDA)](#3-exploratory-data-analysis-eda)  \n",
    "   - 3.1 [Salary Distribution Analysis](#31-salary-distribution-analysis)  \n",
    "   - 3.2 [Categorical Feature Breakdown](#32-categorical-feature-breakdown)  \n",
    "   - 3.3 [Geographical and Remote Work Trends](#33-geographical-and-remote-work-trends)  \n",
    "   - 3.4 [Outlier Detection and Decisions](#34-outlier-detection-and-decisions)  \n",
    "   - 3.5 [Variance and Correlation Analysis](#35-variance-and-correlation-analysis)\n",
    "\n",
    "4. [Feature Engineering](#4-feature-engineering)  \n",
    "   - 4.1 [Categorical Embeddings for High-Cardinality Variables](#41-categorical-embeddings-for-high-cardinality-variables)  \n",
    "   - 4.2 [Statistical Feature Creation](#42-statistical-feature-creation)  \n",
    "   - 4.3 [Interaction Terms and Cross Features](#43-interaction-terms-and-cross-features)  \n",
    "   - 4.4 [Feature Scaling and Transformation](#44-feature-scaling-and-transformation)  \n",
    "   - 4.5 [Final Feature Set for Modeling](#45-final-feature-set-for-modeling)\n",
    "\n",
    "5. [Model Development: Deep Learning](#5-model-development-deep-learning)  \n",
    "   - 5.1 [Neural Network Architecture](#51-neural-network-architecture)  \n",
    "   - 5.2 [Embedding Layers and Dense Connections](#52-embedding-layers-and-dense-connections)  \n",
    "   - 5.3 [Regularization: Dropout & Batch Normalization](#53-regularization-dropout--batch-normalization)  \n",
    "   - 5.4 [Training Strategy and Early Stopping](#54-training-strategy-and-early-stopping)  \n",
    "   - 5.5 [Baseline Comparison with LightGBM or CatBoost](#55-baseline-comparison-with-lightgbm-or-catboost)\n",
    "\n",
    "6. [Model Evaluation](#6-model-evaluation)  \n",
    "   - 6.1 [Performance Metrics: MAE, RMSE, R²](#61-performance-metrics-mae-rmse-r²)  \n",
    "   - 6.2 [Residual Analysis and Interpretation](#62-residual-analysis-and-interpretation)  \n",
    "   - 6.3 [Error Analysis Across Job Segments](#63-error-analysis-across-job-segments)\n",
    "\n",
    "7. [Model Explainability](#7-model-explainability)  \n",
    "   - 7.1 [Global SHAP Summary Analysis](#71-global-shap-summary-analysis)  \n",
    "   - 7.2 [Local SHAP Interpretations (Case Studies)](#72-local-shap-interpretations-case-studies)  \n",
    "   - 7.3 [Feature Importance and Insights](#73-feature-importance-and-insights)\n",
    "\n",
    "8. [Model Deployment](#8-model-deployment)  \n",
    "   - 8.1 [Prepare Model for Inference](#81-prepare-model-for-inference)  \n",
    "   - 8.2 [Designing Streamlit Interface](#82-designing-streamlit-interface)  \n",
    "   - 8.3 [Integrating SHAP in Streamlit App](#83-integrating-shap-in-streamlit-app)  \n",
    "   - 8.4 [Hosting: Streamlit Cloud / Hugging Face Spaces](#84-hosting-streamlit-cloud--hugging-face-spaces)\n",
    "\n",
    "9. [MLflow Tracking](#9-mlflow-tracking)  \n",
    "   - 9.1 [Tracking Experiments](#91-tracking-experiments)  \n",
    "   - 9.2 [Logging Parameters and Artifacts](#92-logging-parameters-and-artifacts)  \n",
    "   - 9.3 [Model Registry and Version Control](#93-model-registry-and-version-control)\n",
    "\n",
    "10. [Conclusion and Recommendations](#10-conclusion-and-recommendations)  \n",
    "    - 10.1 [Summary of Findings](#101-summary-of-findings)  \n",
    "    - 10.2 [Business Implications](#102-business-implications)  \n",
    "    - 10.3 [Lim]()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d885885d",
   "metadata": {},
   "source": [
    "## 📚 1.0 Introduction\n",
    "\n",
    "\n",
    "<div style=\"font-family: Avenir, sans-serif; font-size: 16px; line-height: 1.6; color: white; background-color: #333; padding: 10px; border-radius: 5px;\">\n",
    "This section provides an overview of the dataset and the problem we are trying to solve. We will also discuss the data overview, project objective, methodology and the tools (libaries) we will use to solve the problem.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d5b4ca",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 1.1 Project Overview\n",
    "This project, **DeepCompNet**, aims to build an advanced salary prediction model for machine learning roles using deep learning techniques. The dataset consists of global compensation data for ML professionals and captures various features like job title, experience, location, remote work ratio, and company size.\n",
    "\n",
    "We leverage neural networks for modeling, embedding layers for categorical variables, and SHAP for explainability. The final solution is deployed via a Streamlit app to enable real-time salary prediction and interpretation.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2 Project Objectives\n",
    "- Predict salary compensation (`salary_in_usd`) for ML-related job roles.\n",
    "- Identify and rank key features influencing salary outcomes.\n",
    "- Build a deep learning model with categorical embeddings.\n",
    "- Compare deep learning model performance with LightGBM/CatBoost baselines.\n",
    "- Apply SHAP for global and local feature explainability.\n",
    "- Deploy the model using Streamlit for public access and interaction.\n",
    "- Track all experiments and hyperparameters using MLflow.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3 Business Value\n",
    "This project provides a practical solution for:\n",
    "- **HR and Recruitment** teams: To set competitive salary benchmarks.\n",
    "- **Job Seekers**: To assess fair compensation expectations based on job attributes.\n",
    "- **Compensation Analysts**: To gain insights into salary drivers across roles and regions.\n",
    "- **Executives and Policy Makers**: To support equitable compensation frameworks in tech hiring.\n",
    "\n",
    "---\n",
    "\n",
    "### 1.4 Tools and Technologies\n",
    "Below are the key tools and libraries used throughout this project:\n",
    "\n",
    "- **Data Handling & Visualization**:  \n",
    "  `pandas`, `numpy`, `matplotlib`, `seaborn`\n",
    "\n",
    "- **Deep Learning**:  \n",
    "  `PyTorch` *(or TensorFlow)*, `scikit-learn`\n",
    "\n",
    "- **Explainability**:  \n",
    "  `SHAP`, `PermutationImportance`\n",
    "\n",
    "- **Experiment Tracking**:  \n",
    "  `MLflow`\n",
    "\n",
    "- **Deployment**:  \n",
    "  `Streamlit`, optionally `Hugging Face Spaces`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08a63de",
   "metadata": {},
   "source": [
    "### 🔍 Library Tools\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b92e6efe",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 38\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtree\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeRegressor\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestRegressor, VotingRegressor\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LGBMRegressor\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostRegressor\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "# Core Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.cm import ScalarMappable, coolwarm\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Data Preprocessing\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler, OneHotEncoder, LabelEncoder, OrdinalEncoder,\n",
    "    PolynomialFeatures, PowerTransformer\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Model Selection and Evaluation\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, GridSearchCV, cross_val_score, learning_curve\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_squared_error, r2_score, mean_absolute_error\n",
    ")\n",
    "\n",
    "# Regression Models\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, VotingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Pipeline Components\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Statistical Tools\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.stats import chi2_contingency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeed65c5",
   "metadata": {},
   "source": [
    "## 📚 2.0 Data Collection & Understanding\n",
    "\n",
    "\n",
    "<div style=\"font-family: Avenir, sans-serif; font-size: 16px; line-height: 1.6; color: white; background-color: #333; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "This section focuses on loading the dataset and performing data preprocessing tasks such as handling missing values, changing data types, and confirming the absence of duplicates. This will make our dataset ready for exploratory data analysis and model development.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89841f9a",
   "metadata": {},
   "source": [
    "\n",
    "### 2.1 Dataset Overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be1826e",
   "metadata": {},
   "source": [
    "The dataset used in this project is sourced from Kaggle and includes machine learning-related salary records for the year 2024. Each row represents an individual job role with attributes such as job title, location, experience level, employment type, company size, and more.\n",
    "\n",
    "- **Source**: [Kaggle – ML Engineer Salary (2024)](https://www.kaggle.com/datasets/chopper53/machine-learning-engineer-salary-in-2024)  \n",
    "- **Observations**: ~16000+ records  \n",
    "- **Format**: CSV  \n",
    "- **Target Variable**: `salary_in_usd`  \n",
    "\n",
    "This dataset provides a strong foundation for understanding salary distributions and building predictive models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dd5f57",
   "metadata": {},
   "source": [
    "### 2.2 Data Fields and Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e66c6ca",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "| Column Name         | Description                                                                 |\n",
    "|---------------------|-----------------------------------------------------------------------------|\n",
    "| `job_title`         | Title of the job (e.g., Data Scientist, ML Engineer)                        |\n",
    "| `salary_in_usd`     | Annual salary in USD (standardized across all countries)                    |\n",
    "| `employee_residence`| Country of the employee's primary residence                                 |\n",
    "| `experience_level`  | Seniority level (EN = Entry, MI = Mid, SE = Senior, EX = Executive)         |\n",
    "| `employment_type`   | Full-time, Part-time, Freelance, or Contract                                |\n",
    "| `company_size`      | Size of the company (S = Small, M = Medium, L = Large)                      |\n",
    "| `remote_ratio`      | % of remote work (0 = Onsite, 50 = Hybrid, 100 = Fully Remote)              |\n",
    "| `company_location`  | Country where the company is headquartered                                  |\n",
    "| `work_year`         | Year the salary was paid (should be 2024 for all entries)                   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a621ba6c",
   "metadata": {},
   "source": [
    "### 2.3 Assumptions and Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403a2845",
   "metadata": {},
   "source": [
    "**Assumptions**\n",
    "- `salary_in_usd` is assumed to be standardized across all countries regardless of local currency.\n",
    "- The dataset is considered representative of the global ML job market for the year 2024.\n",
    "- High-cardinality categorical features such as `job_title` can be effectively captured using embedding layers in a deep learning model.\n",
    "\n",
    "**Limitations**\n",
    "- Potential **regional bias** due to overrepresentation from countries like the USA and India.\n",
    "- The dataset lacks **industry/sector information** (e.g., tech, finance, healthcare), which may impact salary variance.\n",
    "- **Total compensation** may be underestimated due to missing data on bonuses, equity, or benefits.\n",
    "- **Temporal limitation**: The dataset only covers the year 2024 and does not account for salary trends over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26332e03",
   "metadata": {},
   "source": [
    "### 2.4 Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a52ec5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', engine = 'pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a019426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "work_year",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "experience_level",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "employment_type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "job_title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "salary",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "salary_currency",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "salary_in_usd",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "employee_residence",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "remote_ratio",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "company_location",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "company_size",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "28e23066-2d24-463d-be72-362150adf8f2",
       "rows": [
        [
         "0",
         "2024",
         "MI",
         "FT",
         "Data Scientist",
         "120000",
         "USD",
         "120000",
         "AU",
         "0",
         "AU",
         "S"
        ],
        [
         "1",
         "2024",
         "MI",
         "FT",
         "Data Scientist",
         "70000",
         "USD",
         "70000",
         "AU",
         "0",
         "AU",
         "S"
        ],
        [
         "2",
         "2024",
         "MI",
         "CT",
         "Data Scientist",
         "130000",
         "USD",
         "130000",
         "US",
         "0",
         "US",
         "M"
        ],
        [
         "3",
         "2024",
         "MI",
         "CT",
         "Data Scientist",
         "110000",
         "USD",
         "110000",
         "US",
         "0",
         "US",
         "M"
        ],
        [
         "4",
         "2024",
         "MI",
         "FT",
         "Data Science Manager",
         "240000",
         "USD",
         "240000",
         "US",
         "0",
         "US",
         "M"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>work_year</th>\n",
       "      <th>experience_level</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>job_title</th>\n",
       "      <th>salary</th>\n",
       "      <th>salary_currency</th>\n",
       "      <th>salary_in_usd</th>\n",
       "      <th>employee_residence</th>\n",
       "      <th>remote_ratio</th>\n",
       "      <th>company_location</th>\n",
       "      <th>company_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>120000</td>\n",
       "      <td>USD</td>\n",
       "      <td>120000</td>\n",
       "      <td>AU</td>\n",
       "      <td>0</td>\n",
       "      <td>AU</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>70000</td>\n",
       "      <td>USD</td>\n",
       "      <td>70000</td>\n",
       "      <td>AU</td>\n",
       "      <td>0</td>\n",
       "      <td>AU</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024</td>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>130000</td>\n",
       "      <td>USD</td>\n",
       "      <td>130000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024</td>\n",
       "      <td>MI</td>\n",
       "      <td>CT</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>110000</td>\n",
       "      <td>USD</td>\n",
       "      <td>110000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024</td>\n",
       "      <td>MI</td>\n",
       "      <td>FT</td>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>240000</td>\n",
       "      <td>USD</td>\n",
       "      <td>240000</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   work_year experience_level employment_type             job_title  salary  \\\n",
       "0       2024               MI              FT        Data Scientist  120000   \n",
       "1       2024               MI              FT        Data Scientist   70000   \n",
       "2       2024               MI              CT        Data Scientist  130000   \n",
       "3       2024               MI              CT        Data Scientist  110000   \n",
       "4       2024               MI              FT  Data Science Manager  240000   \n",
       "\n",
       "  salary_currency  salary_in_usd employee_residence  remote_ratio  \\\n",
       "0             USD         120000                 AU             0   \n",
       "1             USD          70000                 AU             0   \n",
       "2             USD         130000                 US             0   \n",
       "3             USD         110000                 US             0   \n",
       "4             USD         240000                 US             0   \n",
       "\n",
       "  company_location company_size  \n",
       "0               AU            S  \n",
       "1               AU            S  \n",
       "2               US            M  \n",
       "3               US            M  \n",
       "4               US            M  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1295639c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16494 entries, 0 to 16493\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   work_year           16494 non-null  int64 \n",
      " 1   experience_level    16494 non-null  object\n",
      " 2   employment_type     16494 non-null  object\n",
      " 3   job_title           16494 non-null  object\n",
      " 4   salary              16494 non-null  int64 \n",
      " 5   salary_currency     16494 non-null  object\n",
      " 6   salary_in_usd       16494 non-null  int64 \n",
      " 7   employee_residence  16494 non-null  object\n",
      " 8   remote_ratio        16494 non-null  int64 \n",
      " 9   company_location    16494 non-null  object\n",
      " 10  company_size        16494 non-null  object\n",
      "dtypes: int64(4), object(7)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2cf9898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16494, 11)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the dataframe shape\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "102f42aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "cd73b15a-ad10-476a-815b-d20ab19a9b14",
       "rows": [
        [
         "work_year",
         "0.0"
        ],
        [
         "experience_level",
         "0.0"
        ],
        [
         "employment_type",
         "0.0"
        ],
        [
         "job_title",
         "0.0"
        ],
        [
         "salary",
         "0.0"
        ],
        [
         "salary_currency",
         "0.0"
        ],
        [
         "salary_in_usd",
         "0.0"
        ],
        [
         "employee_residence",
         "0.0"
        ],
        [
         "remote_ratio",
         "0.0"
        ],
        [
         "company_location",
         "0.0"
        ],
        [
         "company_size",
         "0.0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 11
       }
      },
      "text/plain": [
       "work_year             0.0\n",
       "experience_level      0.0\n",
       "employment_type       0.0\n",
       "job_title             0.0\n",
       "salary                0.0\n",
       "salary_currency       0.0\n",
       "salary_in_usd         0.0\n",
       "employee_residence    0.0\n",
       "remote_ratio          0.0\n",
       "company_location      0.0\n",
       "company_size          0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for the missing values\n",
    "df.isnull().sum() / df.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ab2fb22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_data = df.select_dtypes(include=['object', 'category']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e3d4930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique values in experience_level column:  4\n",
      "Number of unique values in employment_type column:  4\n",
      "Number of unique values in job_title column:  155\n",
      "Number of unique values in salary_currency column:  23\n",
      "Number of unique values in employee_residence column:  88\n",
      "Number of unique values in company_location column:  77\n",
      "Number of unique values in company_size column:  3\n"
     ]
    }
   ],
   "source": [
    "# It is importance to check for the unique values in the categorical data\n",
    "# Loop through columns\n",
    "for col in categorical_data:\n",
    "  \n",
    "  # Print the number of unique values\n",
    "  print(f\"Number of unique values in {col} column: \", df[col].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a937b8",
   "metadata": {},
   "source": [
    "# 📚 3.0 Exploratory Data Analysis (EDA)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
